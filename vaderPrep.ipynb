{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) <2022>, <Regina Nockerts>\n",
    "All rights reserved.\n",
    "\n",
    "This source code is licensed under the BSD-style license found in the\n",
    "LICENSE file in the root directory of this source tree. \n",
    "\n",
    "__NOTE__ to the user: In first use, this notebook cannot be run top to bottom. It assumes that you have a bunch of csv files that are created at different points in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle \n",
    "from nlpUtils import aardvark as aa \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "# sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Assumes that you have completed dataSplitBalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"data/change_lex.pkl\", \"rb\")\n",
    "change_lex = pickle.load(a_file)\n",
    "a_file.close()\n",
    "print(change_lex['red_heart_e'])\n",
    "\n",
    "sid.lexicon.update(change_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced:\n",
      "x-train: (823, 3) x-val: (206, 3) y-train: (823, 5) y-val: (206, 5)\n",
      "Undersampled\n",
      "x-train: (574, 3) x-val: (144, 3) y-train: (574, 5) y-val: (144, 5)\n",
      "Under-Oversampled\n",
      "x-train: (982, 3) x-val: (247, 3) y-train: (982, 5) y-val: (247, 5)\n",
      "TEST DATA\n",
      "x-TEST: (182, 3) y-TEST: (182, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "      <th>emojiScore</th>\n",
       "      <th>analog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>don't care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>don't care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji                    demoji  VaderEmojiScore  emosentScore  emojiScore  \\\n",
       "0     üö®        :police_car_light:           0.0000         0.673      0.6730   \n",
       "1     üôè            :folded_hands:           0.0000         0.418      0.4180   \n",
       "2     ü§∑        :person_shrugging:           0.0000           NaN     -0.3875   \n",
       "3     üôÑ  :face_with_rolling_eyes:           0.0000           NaN     -0.3875   \n",
       "4     üòÇ  :face_with_tears_of_joy:           0.4404         0.221      0.2210   \n",
       "\n",
       "       analog  \n",
       "0        TEST  \n",
       "1         NaN  \n",
       "2  don't care  \n",
       "3  don't care  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the files that result from dataSplitBalance\n",
    "\n",
    "unbal_x_train = pd.read_csv(\"dataBalancedSets/unbal_x_train.csv\", header=0, index_col=0)\n",
    "unbal_x_val = pd.read_csv(\"dataBalancedSets/unbal_x_val.csv\", header=0, index_col=0)\n",
    "unbal_y_train = pd.read_csv(\"dataBalancedSets/unbal_y_train.csv\", header=0, index_col=0)\n",
    "unbal_y_val = pd.read_csv(\"dataBalancedSets/unbal_y_val.csv\", header=0, index_col=0)\n",
    "\n",
    "under_x_train = pd.read_csv(\"dataBalancedSets/under_x_train.csv\", header=0, index_col=0)\n",
    "under_x_val = pd.read_csv(\"dataBalancedSets/under_x_val.csv\", header=0, index_col=0)\n",
    "under_y_train = pd.read_csv(\"dataBalancedSets/under_y_train.csv\", header=0, index_col=0)\n",
    "under_y_val = pd.read_csv(\"dataBalancedSets/under_y_val.csv\", header=0, index_col=0)\n",
    "\n",
    "underOver_y_train = pd.read_csv(\"dataBalancedSets/underOver_y_train.csv\", header=0, index_col=0)\n",
    "underOver_x_train = pd.read_csv(\"dataBalancedSets/underOver_x_train.csv\", header=0, index_col=0)\n",
    "underOver_y_val = pd.read_csv(\"dataBalancedSets/underOver_y_val.csv\", header=0, index_col=0)\n",
    "underOver_x_val = pd.read_csv(\"dataBalancedSets/underOver_x_val.csv\", header=0, index_col=0)\n",
    "\n",
    "# And the test dataset\n",
    "x_test = pd.read_csv(\"dataBalancedSets/x_test.csv\", header=0, index_col=0)\n",
    "y_test = pd.read_csv(\"dataBalancedSets/y_test_sent.csv\", header=0, index_col=0)\n",
    "\n",
    "# And some odds and ends\n",
    "tweets_clean  = pd.read_csv(\"archiveData/cleanB_tweets_clean.csv\", header=0, index_col=0) \n",
    "emoji_df_full = pd.read_csv(\"data/emoji_full.csv\", header=0, index_col=0)\n",
    "all_unlabeled_tweets = pd.read_csv(\"data/all_unlabeled_tweets.csv\", header=0, index_col=0)\n",
    "\n",
    "print(\"Unbalanced:\")\n",
    "print(\"x-train:\", unbal_x_train.shape, \"x-val:\", unbal_x_val.shape, \"y-train:\", unbal_y_train.shape, \"y-val:\", unbal_y_val.shape)\n",
    "print(\"Undersampled\")\n",
    "print(\"x-train:\", under_x_train.shape, \"x-val:\", under_x_val.shape, \"y-train:\", under_y_train.shape, \"y-val:\", under_y_val.shape)\n",
    "print(\"Under-Oversampled\")\n",
    "print(\"x-train:\", underOver_x_train.shape, \"x-val:\", underOver_x_val.shape, \"y-train:\", underOver_y_train.shape, \"y-val:\", underOver_y_val.shape)\n",
    "print(\"TEST DATA\")\n",
    "print(\"x-TEST:\", x_test.shape, \"y-TEST:\", y_test.shape)\n",
    "emoji_df_full.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>y_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170314</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192623</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106982</td>\n",
       "      <td>Not only did Trump stop processing asylum &amp; re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31609</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152666</td>\n",
       "      <td>One moment you hate refugees and the next you ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_stable                                       ContentClean  y_sent\n",
       "0     170314  Per a White House official: Biden and Harris m...       1\n",
       "1     192623  Afghan Refugee kid educated in Iran wins this ...       2\n",
       "2     106982  Not only did Trump stop processing asylum & re...       0\n",
       "3      31609  An Afghan refugee demands the US not forget he...       0\n",
       "4     152666  One moment you hate refugees and the next you ...       2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = ['Date', 'Content', 'Labels', 'label_sent', 'label_stance', 'y_stance', 'Flag']\n",
    "tweets_clean.drop(drop_cols, inplace=True, axis=1 )\n",
    "print(tweets_clean.shape)\n",
    "tweets_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "* the tweet_clean is the full, unsplit set - NOT for model development, only for finding emojis.\n",
    "* the unbalanced, and testing sets can be used for VADER model development\n",
    "\n",
    "_____________ FUNCTIONS ____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sentiment intensity dictionary object\n",
    "# sid = SentimentIntensityAnalyzer()  #NOTE: this NEEDS to stay outside of the functions. I will be modifying it.\n",
    "\n",
    "# FROM aardvark\n",
    "# creates the sentiment intensity dictionary: aa.vader_sid(tweet)\n",
    "# gets the compound score: aa.vader_sent_compound(tweet)\n",
    "# gets the classification of the compund score using the authors' suggested cutoff points: aa.vader_pred(tweet, pos_cut, neg_cut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "VADER should do better if we get the input into better shape.\n",
    "\n",
    "### What if we use the Content v. ContentClean column that we used for labeling?\n",
    "Remember that VADER has its own way of dealing with punctuation, capitalization, modifiers, negations, stopwords, tokenization and lemmatization. Earlier cleaning was done to try not to mess with that. I tested to make sure that was done correctly. The scores are the same, either set. This code has been moved to the graveyard.\n",
    "\n",
    "(A nice tutorial explaining this: https://towardsdatascience.com/are-you-scared-vader-understanding-how-nlp-pre-processing-impacts-vader-scoring-4f4edadbc91d)\n",
    "\n",
    "\n",
    "### What abou the demoji?\n",
    "For VADER, I will have to create a dictionary of these codes as \"words\" that can be added to the lexicon. We started this by finding all the emoji and saving them to a dataframe: emoji_df_full\n",
    "* keep the scores from the emosent library as the prioirity\n",
    "* Use the VADER score as a backup\n",
    "* Manually check the results to make sure they are reasonable and identify ones to customize.\n",
    "\n",
    "# Emoji\n",
    "ref: vaderEmoji.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "      <th>emojiScore</th>\n",
       "      <th>analog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>don't care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>don't care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>ü¶æ</td>\n",
       "      <td>:mechanical_arm:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5560</td>\n",
       "      <td>üí™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>üèÉüèæ‚Äç‚ôÇÔ∏è</td>\n",
       "      <td>:man_running_medium-dark_skin_tone:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>üöë</td>\n",
       "      <td>:ambulance:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>üéÉ</td>\n",
       "      <td>:jack-o-lantern:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>¬ÆÔ∏è</td>\n",
       "      <td>:registered:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1106 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emoji                               demoji  VaderEmojiScore  \\\n",
       "0         üö®                   :police_car_light:           0.0000   \n",
       "1         üôè                       :folded_hands:           0.0000   \n",
       "2         ü§∑                   :person_shrugging:           0.0000   \n",
       "3         üôÑ             :face_with_rolling_eyes:           0.0000   \n",
       "4         üòÇ             :face_with_tears_of_joy:           0.4404   \n",
       "...     ...                                  ...              ...   \n",
       "1101      ü¶æ                     :mechanical_arm:           0.0000   \n",
       "1102  üèÉüèæ‚Äç‚ôÇÔ∏è  :man_running_medium-dark_skin_tone:           0.0000   \n",
       "1103      üöë                          :ambulance:           0.0000   \n",
       "1104      üéÉ                     :jack-o-lantern:           0.0000   \n",
       "1105     ¬ÆÔ∏è                         :registered:           0.0000   \n",
       "\n",
       "      emosentScore  emojiScore      analog  \n",
       "0            0.673      0.6730        TEST  \n",
       "1            0.418      0.4180         NaN  \n",
       "2              NaN     -0.3875  don't care  \n",
       "3              NaN     -0.3875  don't care  \n",
       "4            0.221      0.2210         NaN  \n",
       "...            ...         ...         ...  \n",
       "1101           NaN      0.5560           üí™  \n",
       "1102           NaN      0.0000         NaN  \n",
       "1103         0.091      0.0910         NaN  \n",
       "1104         0.617      0.6170         NaN  \n",
       "1105           NaN      0.0000         NaN  \n",
       "\n",
       "[1106 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emosent\n",
    "Will the emosent package work for me?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.000    21\n",
      " 1.000    18\n",
      " 0.333    16\n",
      " 0.500     9\n",
      " 0.400     7\n",
      "          ..\n",
      " 0.063     1\n",
      " 0.179     1\n",
      " 0.581     1\n",
      "-0.314     1\n",
      " 0.617     1\n",
      "Name: emosentScore, Length: 282, dtype: int64\n",
      "True     638\n",
      "False    468\n",
      "Name: emosentScore, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(emoji_df_full[\"emosentScore\"].value_counts())\n",
    "print(emoji_df_full[\"emosentScore\"].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kinda. It has about half (missing 638) . But it seems to miss some of the important ones that I need. \n",
    "* ü§∑, ü§Æ, etc.\n",
    "\n",
    "And for the symbols where they overlap, the VADER and emosent scores do necessarilly agree and are sometimes very far off:\n",
    "* üíî (broken_heart): 0.2732 v. -0.122\n",
    "* üò≠ (loudly_crying_face): -0.4767 v. -0.093\n",
    "\n",
    "In these cases, the emosent score (2nd) seems more appropriate\n",
    "\n",
    "And some of the values are just off for __this__ dataset. For example, the stack of dollars (üíµ) has a emosent score of 0.423 - very high. Which makes sense normally: money is good. But in this dataset, it shows up when people are stressing the overly high cost of refugee or ilitary operations, or are talking about corruption. \n",
    "\n",
    "As this tool has been validated, I'll consider the values they have. But I'll still have to assign my own values to the remaining half. So: first emosent; if not, then VADER; if not, then my ranking; and my own ranking for emojis that are used differently than normal in my dataset.\n",
    "\n",
    "NOTE: I will have to add the emosent and my emojis to the dictionary. \n",
    "* For more insight on ranking: http://kt.ijs.si/data/Emoji_sentiment_ranking/\n",
    "\n",
    "### Get final sentiment value for each emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "      <th>emojiScore</th>\n",
       "      <th>analog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>don't care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>don't care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji                    demoji  VaderEmojiScore  emosentScore  emojiScore  \\\n",
       "0     üö®        :police_car_light:           0.0000         0.673         NaN   \n",
       "1     üôè            :folded_hands:           0.0000         0.418         NaN   \n",
       "2     ü§∑        :person_shrugging:           0.0000           NaN         NaN   \n",
       "3     üôÑ  :face_with_rolling_eyes:           0.0000           NaN         NaN   \n",
       "4     üòÇ  :face_with_tears_of_joy:           0.4404         0.221         NaN   \n",
       "\n",
       "       analog  \n",
       "0        TEST  \n",
       "1         NaN  \n",
       "2  don't care  \n",
       "3  don't care  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add column for the final value\n",
    "emoji_df_full['emojiScore'] = np.NaN\n",
    "emoji_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rnocker\\AppData\\Local\\Temp\\ipykernel_10840\\2091278290.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emoji_df_full['emojiScore'].iloc[i] = e\n",
      "C:\\Users\\rnocker\\AppData\\Local\\Temp\\ipykernel_10840\\2091278290.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emoji_df_full['emojiScore'].iloc[i] = v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NANs after filling: \n",
      " False    1085\n",
      "True       21\n",
      "Name: emojiScore, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "      <th>emojiScore</th>\n",
       "      <th>analog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.673</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.418</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>don't care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>don't care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.221</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji                    demoji  VaderEmojiScore  emosentScore  emojiScore  \\\n",
       "0     üö®        :police_car_light:           0.0000         0.673       0.673   \n",
       "1     üôè            :folded_hands:           0.0000         0.418       0.418   \n",
       "2     ü§∑        :person_shrugging:           0.0000           NaN       0.000   \n",
       "3     üôÑ  :face_with_rolling_eyes:           0.0000           NaN       0.000   \n",
       "4     üòÇ  :face_with_tears_of_joy:           0.4404         0.221       0.221   \n",
       "\n",
       "       analog  \n",
       "0        TEST  \n",
       "1         NaN  \n",
       "2  don't care  \n",
       "3  don't care  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, v, e, s in zip(emoji_df_full.index, emoji_df_full[\"VaderEmojiScore\"], emoji_df_full['emosentScore'], emoji_df_full[\"emojiScore\"]):\n",
    "    if pd.isnull(e) == True:\n",
    "        if pd.isnull(v) == False:\n",
    "            emoji_df_full['emojiScore'].iloc[i] = v\n",
    "    elif e != 0:\n",
    "        emoji_df_full['emojiScore'].iloc[i] = e\n",
    "print(\"NANs after filling: \\n\", emoji_df_full[\"emojiScore\"].isnull().value_counts())\n",
    "emoji_df_full['emojiScore'] = emoji_df_full['emojiScore'].copy()\n",
    "emoji_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: don't run if you don't need to:\n",
    "# emoji_df_full.to_csv(\"archiveData/emoji_full_temp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --> open the csv and edit\n",
    "Only look at the entire database, not the labeled tweets, when deciding what to do with these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('üîµ', 10)\n"
     ]
    }
   ],
   "source": [
    "# How often does the emoji appear?\n",
    "print(aa.term_check(\"üîµ\", all_unlabeled_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is the emoji generally used?\n",
    "for i in all_unlabeled_tweets[\"ContentClean\"]:\n",
    "    if \"üôã\" in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emonsent: -0.093\n",
      "VADER -0.4767\n"
     ]
    }
   ],
   "source": [
    "# What is the score of clearly analagous emoji or text?\n",
    "term = \"üò≠\"\n",
    "print(\"emonsent:\", aa.emosent_score(term))  # works for emoji\n",
    "print(\"VADER\", aa.vader_sent_compound(term))  # works for text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list of emojis gathered in the entire dataset. Scoring based on expert knowledge and without reference to the data or labels.\n",
    "\n",
    "I changed values for emojis that:\n",
    "* have clear analogs in other emojis - eg. different color or skin tones.\n",
    "  * When this was done, I made a note of the analog in a new column, \"analog\"\n",
    "* the most direct text translation is an emotion (eg. heart, thumbs-up) or action (eg. facepalming, dancing), and not a noun\n",
    "* the emoji is a generally know sign or symbol, eg. biohazard sign, peace symbol\n",
    "* reference money - will have a different meaning when talking about government actions/programs\n",
    "  \n",
    "I changed the following categoreis to 0.0:\n",
    "* means of communication (eg. microphone, television, telephone) - tend to be associated with news media or CTAs\n",
    "* simple geometric forms, other than hearts - tend to be used as special bullet points\n",
    "* government bodies - will have different meaning when talking about legalistic situations\n",
    "* pointers and arrows - used to spatially indicate a reference or emphasize\n",
    "  \n",
    "I did not atempt to find substitutes for all emojis. \n",
    "* occupations\n",
    "* objects\n",
    "\n",
    "### NOTES\n",
    "There are clearly better ways to deal with skin tones and emoji: searching for one \"hands raised\" person returns all. This method works for this project, but is not ideal. Future work, I guess.\n",
    "\n",
    "Some interesting emojis to look at with the training data:  \n",
    "* ü¶ç\t:gorilla:\n",
    "* ‚ùÑÔ∏è\t:snowflake:\n",
    "* üõÉ\t:customs:\n",
    "* üõÇ\t:passport_control:\n",
    "* üè≥Ô∏è‚Äç‚ößÔ∏è\t:transgender_flag:\n",
    "* ü¶†\t:microbe:\n",
    "* ‚öñ\t:balance_scale:\n",
    "* üó≥Ô∏è\t:ballot_box_with_ballot:\n",
    "* ‚åõ\t:hourglass_done:\n",
    "* üë™\t:family:\t0.0\t-0.018\n",
    "  \n",
    "### --> reload the new, modified emoji_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "      <th>emojiScore</th>\n",
       "      <th>analog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.4180</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>don't care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3875</td>\n",
       "      <td>don't care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji                    demoji  VaderEmojiScore  emosentScore  emojiScore  \\\n",
       "0     üö®        :police_car_light:           0.0000         0.673      0.6730   \n",
       "1     üôè            :folded_hands:           0.0000         0.418      0.4180   \n",
       "2     ü§∑        :person_shrugging:           0.0000           NaN     -0.3875   \n",
       "3     üôÑ  :face_with_rolling_eyes:           0.0000           NaN     -0.3875   \n",
       "4     üòÇ  :face_with_tears_of_joy:           0.4404         0.221      0.2210   \n",
       "\n",
       "       analog  \n",
       "0        TEST  \n",
       "1         NaN  \n",
       "2  don't care  \n",
       "3  don't care  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_df_full = pd.read_csv(\"data/emoji_full_mod1.csv\", header=0, index_col=0)  ## there is a copy in archiveData: emoji_full_Copy)\n",
    "emoji_df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update the VADER dictionary\n",
    "Now that we have the new wordcodes and associated values, we need to put them in the VADER dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emoji', 'demoji', 'VaderEmojiScore', 'emosentScore', 'emojiScore', 'analog']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rnocker\\AppData\\Local\\Temp\\ipykernel_10840\\2604716947.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  change_lex['demoji'].iloc[i] = re.sub(\":\", \"\", d) + \"_e\"\n",
      "C:\\Users\\rnocker\\AppData\\Local\\Temp\\ipykernel_10840\\2604716947.py:10: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  change_lex = change_lex.set_index('demoji').T.to_dict('list')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.3875"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the sid change lexicon\n",
    "print(list(emoji_df_full.columns))\n",
    "change_lex = emoji_df_full[['demoji', 'emojiScore']].copy()\n",
    "\n",
    "# Change the demoji format so that VADER sid can use it\n",
    "for i, d in enumerate(change_lex['demoji']):\n",
    "    change_lex['demoji'].iloc[i] = re.sub(\":\", \"\", d) + \"_e\"\n",
    "\n",
    "# Change the change_lex to a dictionary\n",
    "change_lex = change_lex.set_index('demoji').T.to_dict('list')\n",
    "for key, value in change_lex.items():\n",
    "    change_lex.update({key: float(value[0])})\n",
    "\n",
    "change_lex['person_shrugging_e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save change_lex as a dictionary that can be loaded in other files\n",
    "a_file = open(\"data/change_lex.pkl\", \"wb\")\n",
    "pickle.dump(change_lex, a_file)\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1891\n",
      "0.746\n"
     ]
    }
   ],
   "source": [
    "#update the lexicon and make sure that it works\n",
    "sid.lexicon.update(change_lex)\n",
    "print(sid.polarity_scores(\"red_heart_e\")[\"compound\"]) # Note that the aa. functions don't use the updated lexicon.\n",
    "print(change_lex['red_heart_e'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change the demoji codes\n",
    "Way back in dataEmoji, we demojized with the standare :word_word: format. So we are going to have to go through all of the datasets that we created and change that now to the word_word_e format. This sucks. But I *think* it's more reliable than going back and changing the earlier code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1894, 168, 1762, 168, 174, 102]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that BERT can also handle the new format\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "tokenizer.encode('red_heart_e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "ÿÆÿ¥ŸàŸÜÿ™ ÿπŸÑ€åŸá ÿ≤ŸÜÿßŸÜÿå ŸÖŸÖŸÜŸàÿπ! Two Afghan immigrant women ask a Swedish journalist to photograph their bodies from undercover history to show what it means when violence against women speaks out. The deformed bodies of these two women, continued in comment:backhand_index_pointing_down::backhand_index_pointing_down:\n"
     ]
    }
   ],
   "source": [
    "# Make a dev df\n",
    "test_df = unbal_x_train.copy()\n",
    "\n",
    "# Check what the starting number of \":\" is\n",
    "counter = 0\n",
    "i_nums = []\n",
    "for i, text in enumerate(test_df[\"ContentClean\"]):\n",
    "    if \":\" in text:\n",
    "        counter += 1\n",
    "        i_nums.append(i)\n",
    "print(counter)\n",
    "print(test_df[\"ContentClean\"].iloc[i_nums[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I heart_emoji_e my blue_e lady_bike_e ! love: it.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a regex function to recognize \":word_word:\" and sub for \"word_word_e\"\n",
    "\n",
    "tweet = \"I:heart_emoji: my :blue::lady_bike:! love: it.\"\n",
    "#tweet = \"I heart_emoji my lady_bike! love: it.\"\n",
    "\n",
    "def change_e_codes(text):\n",
    "    new_text = text\n",
    "    b_list = []\n",
    "    c_list = []\n",
    "\n",
    "    # find the desired strings\n",
    "    a_list = re.findall(r\":\\b\\w+\\b:\", new_text)   #(\"I\", \"CODE\", text)\n",
    "    \n",
    "    # change the strings to desired format\n",
    "    for i in a_list:\n",
    "        b_list.append(re.sub(r\":\\b\", \" \", i))\n",
    "    for i in b_list:\n",
    "        c_list.append(re.sub(r\"\\b:\", \"_e \", i))\n",
    "    \n",
    "    # replace them in the text\n",
    "    for i, old_code in enumerate(a_list):\n",
    "        new_text = new_text.replace(old_code, c_list[i])\n",
    "\n",
    "    new_text = re.sub(r\"  \", \" \", new_text)\n",
    "\n",
    "    if len(c_list) != 0: \n",
    "        return new_text\n",
    "    else: \n",
    "        return text\n",
    "\n",
    "change_e_codes(tweet)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"ContentClean\"] = test_df[\"ContentClean\"].apply(change_e_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "ÿÆÿ¥ŸàŸÜÿ™ ÿπŸÑ€åŸá ÿ≤ŸÜÿßŸÜÿå ŸÖŸÖŸÜŸàÿπ! Two Afghan immigrant women ask a Swedish journalist to photograph their bodies from undercover history to show what it means when violence against women speaks out. The deformed bodies of these two women, continued in comment backhand_index_pointing_down_e backhand_index_pointing_down_e \n",
      "At the moment, that would be Mexican, Colombian, Venezuelan, Afghan, Russian, and Ukraine seeking relocation. should be the last place they will call because who wants to pay taxes to a state that hated their presence from the get-go?\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in test_df[\"ContentClean\"]:\n",
    "    if \":\" in i:\n",
    "        counter += 1\n",
    "print(counter)\n",
    "\n",
    "print(test_df[\"ContentClean\"].iloc[i_nums[0]])\n",
    "print(test_df[\"ContentClean\"].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply it to all of the dataframes\n",
    "unbal_x_train[\"ContentClean\"] = unbal_x_train[\"ContentClean\"].apply(change_e_codes)\n",
    "unbal_x_val[\"ContentClean\"] = unbal_x_val[\"ContentClean\"].apply(change_e_codes)\n",
    "under_x_train[\"ContentClean\"] = under_x_train[\"ContentClean\"].apply(change_e_codes)\n",
    "under_x_val[\"ContentClean\"] = under_x_val[\"ContentClean\"].apply(change_e_codes)\n",
    "underOver_x_train[\"ContentClean\"] = underOver_x_train[\"ContentClean\"].apply(change_e_codes)\n",
    "underOver_x_val[\"ContentClean\"] = underOver_x_val[\"ContentClean\"].apply(change_e_codes)\n",
    "x_test[\"ContentClean\"] = x_test[\"ContentClean\"].apply(change_e_codes)\n",
    "\n",
    "# And some odds and ends\n",
    "tweets_clean[\"ContentClean\"] = tweets_clean[\"ContentClean\"].apply(change_e_codes)\n",
    "all_unlabeled_tweets[\"ContentClean\"] = all_unlabeled_tweets[\"ContentClean\"].apply(change_e_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save them somewhere new\n",
    "unbal_x_train.to_csv('dataBalSetsEcodes/unbal_x_train.csv')\n",
    "unbal_x_val.to_csv('dataBalSetsEcodes/unbal_x_val.csv')\n",
    "under_x_train.to_csv('dataBalSetsEcodes/under_x_train.csv')\n",
    "under_x_val.to_csv('dataBalSetsEcodes/under_x_val.csv')\n",
    "underOver_x_train.to_csv('dataBalSetsEcodes/underOver_x_train.csv')\n",
    "underOver_x_val.to_csv('dataBalSetsEcodes/underOver_x_val.csv')\n",
    "x_test.to_csv('dataBalSetsEcodes/x_test.csv')\n",
    "tweets_clean.to_csv('dataBalSetsEcodes/tweets_clean.csv')\n",
    "all_unlabeled_tweets.to_csv('archiveData/all_unlabeled_tweets_ecodes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sid.polarity_scores(\"red_heart_e\")[\"compound\"]) # Note that the aa. functions don't use the updated lexicon."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2522cab69aef9135531abc74cfe3f2456cb406a72442e0865122b8d4f66eb9dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
