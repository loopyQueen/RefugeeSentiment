{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) <2022>, <Regina Nockerts>\n",
    "All rights reserved.\n",
    "\n",
    "This source code is licensed under the BSD-style license found in the\n",
    "LICENSE file in the root directory of this source tree. \n",
    "\n",
    "__NOTE__ to the user: In first use, this notebook cannot be run top to bottom. It assumes that you have a bunch of csv files that are created at different points in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from nlpUtils import aardvark as aa \n",
    "\n",
    "from sklearn.metrics import f1_score # auc if I get embeddings\n",
    "\n",
    "\n",
    "#import emoji  # https://pypi.org/project/emoji/\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "# sns.set(font_scale=1.5)\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltkStop\n",
    "from nltk import ngrams\n",
    "#from nltk.tokenize import sent_tokenize  # Creates a list of sentences\n",
    "#from nltk.tokenize import TweetTokenizer  # Prefered: tokenizes a text, with extra controls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Assumes that you have completed dataCleaningB and dataSplitBalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbalanced:\n",
      "x-train: (823, 3) x-val: (206, 3) y-train: (823, 5) y-val: (206, 5)\n",
      "TEST DATA\n",
      "x-TEST: (182, 3) y-TEST: (182, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji                    demoji  VaderEmojiScore  emosentScore\n",
       "0     üö®        :police_car_light:           0.0000         0.673\n",
       "1     üôè            :folded_hands:           0.0000         0.418\n",
       "2     ü§∑        :person_shrugging:           0.0000           NaN\n",
       "3     üôÑ  :face_with_rolling_eyes:           0.0000           NaN\n",
       "4     üòÇ  :face_with_tears_of_joy:           0.4404         0.221"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the files that result from dataSplitBalance\n",
    "\n",
    "unbal_x_train = pd.read_csv(\"dataBalancedSets/unbal_x_train.csv\", header=0, index_col=0)\n",
    "unbal_x_val = pd.read_csv(\"dataBalancedSets/unbal_x_val.csv\", header=0, index_col=0)\n",
    "unbal_y_train = pd.read_csv(\"dataBalancedSets/unbal_y_train.csv\", header=0, index_col=0)\n",
    "unbal_y_val = pd.read_csv(\"dataBalancedSets/unbal_y_val.csv\", header=0, index_col=0)\n",
    "\n",
    "# under_x_train = pd.read_csv(\"dataBalancedSets/under_x_train.csv\", header=0, index_col=0)\n",
    "# under_x_val = pd.read_csv(\"dataBalancedSets/under_x_val.csv\", header=0, index_col=0)\n",
    "# under_y_train = pd.read_csv(\"dataBalancedSets/under_y_train.csv\", header=0, index_col=0)\n",
    "# under_y_val = pd.read_csv(\"dataBalancedSets/under_y_val.csv\", header=0, index_col=0)\n",
    "\n",
    "# underOver_y_train = pd.read_csv(\"dataBalancedSets/underOver_y_train.csv\", header=0, index_col=0)\n",
    "# underOver_x_train = pd.read_csv(\"dataBalancedSets/underOver_x_train.csv\", header=0, index_col=0)\n",
    "# underOver_y_val = pd.read_csv(\"dataBalancedSets/underOver_y_val.csv\", header=0, index_col=0)\n",
    "# underOver_x_val = pd.read_csv(\"dataBalancedSets/underOver_x_val.csv\", header=0, index_col=0)\n",
    "\n",
    "# And the test dataset\n",
    "x_test = pd.read_csv(\"dataBalancedSets/x_test.csv\", header=0, index_col=0)\n",
    "y_test = pd.read_csv(\"dataBalancedSets/y_test_sent.csv\", header=0, index_col=0)\n",
    "\n",
    "# And some odds and ends\n",
    "tweets_clean  = pd.read_csv(\"archiveData/cleanB_tweets_clean.csv\", header=0, index_col=0) \n",
    "emoji_df_full = pd.read_csv(\"data/emoji_full.csv\", header=0, index_col=0)\n",
    "all_unlabeled_tweets = pd.read_csv(\"data/all_unlabeled_tweets.csv\", header=0, index_col=0)\n",
    "\n",
    "print(\"Unbalanced:\")\n",
    "print(\"x-train:\", unbal_x_train.shape, \"x-val:\", unbal_x_val.shape, \"y-train:\", unbal_y_train.shape, \"y-val:\", unbal_y_val.shape)\n",
    "# print(\"Undersampled\")\n",
    "# print(\"x-train:\", under_x_train.shape, \"x-val:\", under_x_val.shape, \"y-train:\", under_y_train.shape, \"y-val:\", under_y_val.shape)\n",
    "# print(\"Under-Oversampled\")\n",
    "# print(\"x-train:\", underOver_x_train.shape, \"x-val:\", underOver_x_val.shape, \"y-train:\", underOver_y_train.shape, \"y-val:\", underOver_y_val.shape)\n",
    "print(\"TEST DATA\")\n",
    "print(\"x-TEST:\", x_test.shape, \"y-TEST:\", y_test.shape)\n",
    "emoji_df_full.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1211, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>y_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170314</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192623</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106982</td>\n",
       "      <td>@pfrpeppermint @CawthornforNC Not only did Tru...</td>\n",
       "      <td>Not only did Trump stop processing asylum &amp; re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31609</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152666</td>\n",
       "      <td>@RepHerrell One moment you hate refugees and t...</td>\n",
       "      <td>One moment you hate refugees and the next you ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_stable                                            Content  \\\n",
       "0     170314  Per a White House official: Biden and Harris m...   \n",
       "1     192623  Afghan Refugee kid educated in Iran wins this ...   \n",
       "2     106982  @pfrpeppermint @CawthornforNC Not only did Tru...   \n",
       "3      31609  An Afghan refugee demands the US not forget he...   \n",
       "4     152666  @RepHerrell One moment you hate refugees and t...   \n",
       "\n",
       "                                        ContentClean  y_sent  \n",
       "0  Per a White House official: Biden and Harris m...       1  \n",
       "1  Afghan Refugee kid educated in Iran wins this ...       2  \n",
       "2  Not only did Trump stop processing asylum & re...       0  \n",
       "3  An Afghan refugee demands the US not forget he...       0  \n",
       "4  One moment you hate refugees and the next you ...       2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = ['Date', 'Labels', 'label_sent', 'label_stance', 'y_stance', 'Flag']\n",
    "tweets_clean.drop(drop_cols, inplace=True, axis=1 )\n",
    "print(tweets_clean.shape)\n",
    "tweets_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "* the tweet_clean is the full, unsplit set - NOT for model development, only for finding emojis.\n",
    "* the unbalanced, and testing sets can be used for VADER model development\n",
    "\n",
    "_____________ FUNCTIONS ____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sentiment intensity dictionary object\n",
    "# sid = SentimentIntensityAnalyzer()  #NOTE: this NEEDS to stay outside of the functions. I will be modifying it.\n",
    "\n",
    "# FROM aardvark\n",
    "# creates the sentiment intensity dictionary: aa.vader_sid(tweet)\n",
    "# gets the compound score: aa.vader_sent_compound(tweet)\n",
    "# gets the classification of the compund score using the authors' suggested cutoff points: aa.vader_pred(tweet, pos_cut, neg_cut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n",
    "VADER should do better if we get the input into better shape.\n",
    "\n",
    "### What if we use the Content v. ContentClean column that we used for labeling?\n",
    "Remember that VADER has its own way of dealing with punctuation, capitalization, modifiers, negations, stopwords, tokenization and lemmatization. Earlier cleaning was done to try not to mess with that. I tested to make sure that was done correctly. The scores are the same, either set. This code has been moved to the graveyard.\n",
    "\n",
    "(A nice tutorial explaining this: https://towardsdatascience.com/are-you-scared-vader-understanding-how-nlp-pre-processing-impacts-vader-scoring-4f4edadbc91d)\n",
    "\n",
    "\n",
    "### What abou the demoji?\n",
    "For VADER, I will have to create a dictionary of these codes as \"words\" that can be added to the lexicon. We started this by finding all the emoji and saving them to a dataframe: emoji_df_full\n",
    "* keep the scores from the emosent library as the prioirity\n",
    "* Use the VADER score as a backup\n",
    "* Manually check the results to make sure they are reasonable and identify ones to customize.\n",
    "\n",
    "# Emoji\n",
    "ref: vaderEmoji.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>ü¶æ</td>\n",
       "      <td>:mechanical_arm:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>üèÉüèæ‚Äç‚ôÇÔ∏è</td>\n",
       "      <td>:man_running_medium-dark_skin_tone:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>üöë</td>\n",
       "      <td>:ambulance:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>üéÉ</td>\n",
       "      <td>:jack-o-lantern:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>¬ÆÔ∏è</td>\n",
       "      <td>:registered:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1106 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emoji                               demoji  VaderEmojiScore  \\\n",
       "0         üö®                   :police_car_light:           0.0000   \n",
       "1         üôè                       :folded_hands:           0.0000   \n",
       "2         ü§∑                   :person_shrugging:           0.0000   \n",
       "3         üôÑ             :face_with_rolling_eyes:           0.0000   \n",
       "4         üòÇ             :face_with_tears_of_joy:           0.4404   \n",
       "...     ...                                  ...              ...   \n",
       "1101      ü¶æ                     :mechanical_arm:           0.0000   \n",
       "1102  üèÉüèæ‚Äç‚ôÇÔ∏è  :man_running_medium-dark_skin_tone:           0.0000   \n",
       "1103      üöë                          :ambulance:           0.0000   \n",
       "1104      üéÉ                     :jack-o-lantern:           0.0000   \n",
       "1105     ¬ÆÔ∏è                         :registered:           0.0000   \n",
       "\n",
       "      emosentScore  \n",
       "0            0.673  \n",
       "1            0.418  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4            0.221  \n",
       "...            ...  \n",
       "1101           NaN  \n",
       "1102           NaN  \n",
       "1103         0.091  \n",
       "1104         0.617  \n",
       "1105           NaN  \n",
       "\n",
       "[1106 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emosent\n",
    "Will the emosent package work for me?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.000    21\n",
      " 1.000    18\n",
      " 0.333    16\n",
      " 0.500     9\n",
      " 0.400     7\n",
      "          ..\n",
      " 0.063     1\n",
      " 0.179     1\n",
      " 0.581     1\n",
      "-0.314     1\n",
      " 0.617     1\n",
      "Name: emosentScore, Length: 282, dtype: int64\n",
      "True     638\n",
      "False    468\n",
      "Name: emosentScore, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(emoji_df_full[\"emosentScore\"].value_counts())\n",
    "print(emoji_df_full[\"emosentScore\"].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kinda. It has about half (missing 638) . But it seems to miss some of the important ones that I need. \n",
    "* ü§∑, ü§Æ, etc.\n",
    "\n",
    "And for the symbols where they overlap, the VADER and emosent scores do necessarilly agree and are sometimes very far off:\n",
    "* üíî (broken_heart): 0.2732 v. -0.122\n",
    "* üò≠ (loudly_crying_face): -0.4767 v. -0.093\n",
    "\n",
    "And some of the values are just off for __this__ dataset. For example, the stack of dollars (üíµ) has a emosent score of 0.423 - very high. Which makes sense normally: money is good. But in this dataset, it shows up when people are stressing the overly high cost of refugee or ilitary operations, or are talking about corruption. \n",
    "\n",
    "As this tool has been validated, I'll consider the values they have. But I'll still have to assign my own values to the remaining half. So: first emosent; if not, then VADER; if not, then my ranking; and my own ranking for emojis that are used differently than normal in my dataset.\n",
    "\n",
    "NOTE: I will have to add the emosent and my emojis to the dictionary. \n",
    "* For more insight on ranking: http://kt.ijs.si/data/Emoji_sentiment_ranking/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "      <th>emojiScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji                    demoji  VaderEmojiScore  emosentScore  emojiScore\n",
       "0     üö®        :police_car_light:           0.0000         0.673         NaN\n",
       "1     üôè            :folded_hands:           0.0000         0.418         NaN\n",
       "2     ü§∑        :person_shrugging:           0.0000           NaN         NaN\n",
       "3     üôÑ  :face_with_rolling_eyes:           0.0000           NaN         NaN\n",
       "4     üòÇ  :face_with_tears_of_joy:           0.4404         0.221         NaN"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_df_full['emojiScore'] = np.NaN\n",
    "emoji_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rnocker\\AppData\\Local\\Temp\\ipykernel_19536\\2091278290.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emoji_df_full['emojiScore'].iloc[i] = e\n",
      "C:\\Users\\rnocker\\AppData\\Local\\Temp\\ipykernel_19536\\2091278290.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  emoji_df_full['emojiScore'].iloc[i] = v\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NANs after filling: \n",
      " False    1085\n",
      "True       21\n",
      "Name: emojiScore, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "      <th>emojiScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji                    demoji  VaderEmojiScore  emosentScore  emojiScore\n",
       "0     üö®        :police_car_light:           0.0000         0.673       0.673\n",
       "1     üôè            :folded_hands:           0.0000         0.418       0.418\n",
       "2     ü§∑        :person_shrugging:           0.0000           NaN       0.000\n",
       "3     üôÑ  :face_with_rolling_eyes:           0.0000           NaN       0.000\n",
       "4     üòÇ  :face_with_tears_of_joy:           0.4404         0.221       0.221"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, v, e, s in zip(emoji_df_full.index, emoji_df_full[\"VaderEmojiScore\"], emoji_df_full['emosentScore'], emoji_df_full[\"emojiScore\"]):\n",
    "    if pd.isnull(e) == True:\n",
    "        if pd.isnull(v) == False:\n",
    "            emoji_df_full['emojiScore'].iloc[i] = v\n",
    "    elif e != 0:\n",
    "        emoji_df_full['emojiScore'].iloc[i] = e\n",
    "print(\"NANs after filling: \\n\", emoji_df_full[\"emojiScore\"].isnull().value_counts())\n",
    "emoji_df_full['emojiScore'] = emoji_df_full['emojiScore'].copy()\n",
    "emoji_df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: DO NOT RUN THIS: now that the dictionary has been modified  (there is a copy in archiveData)\n",
    "# emoji_df_full.to_csv(\"data/emoji_full.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --> open the csv and edit\n",
    "Only look at the entire database, not the labeled tweets, when deciding what to do with these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('üîµ', 10)\n",
      "('üîµ', 0)\n"
     ]
    }
   ],
   "source": [
    "# How often does the emoji appear?\n",
    "print(aa.term_check(\"üîµ\", all_unlabeled_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is the emoji generally used?\n",
    "for i in all_unlabeled_tweets[\"ContentClean\"]:\n",
    "    if \"üôã\" in i:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emonsent: \n",
      "VADER -0.296\n"
     ]
    }
   ],
   "source": [
    "# What is the score of clearly analagous emoji or text?\n",
    "term = \"stop\"\n",
    "print(\"emonsent:\", aa.emosent_score(term))  # works for emoji\n",
    "print(\"VADER\", aa.vader_sent_compound(term))  # works for text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I changed values for emojis that:\n",
    "* have clear analogs in other emojis - eg. different skin tones.\n",
    "  * When this was done, I made a note of the analog in a new column, \"analog\"\n",
    "* the most direct text translation is an emotion (eg. heart, thumbs-up) or action (eg. facepalming, dancing), and not a noun\n",
    "* the emoji is a generally know sign or symbol, eg. biohazard sign, peace symbol\n",
    "\n",
    "I changed the following categoreis to 0.0:\n",
    "* means of communication (eg. microphone, television, telephone) - tend to be associated with news media or CTAs\n",
    "* simple geometric forms, other than hearts - tend to be used as special bullet points\n",
    "* government bodies - will have different meaning when talking about legalistic situations\n",
    "* pointers and arrows - used to indicate a reference or emphasize\n",
    "  \n",
    "I did not atempt to find substitutes for all emojis. \n",
    "* occupations\n",
    "* objects\n",
    "\n",
    "### NOTE\n",
    "Some interesting emojis to look at with the training data:  \n",
    "* ü¶ç\t:gorilla:\n",
    "* ‚ùÑÔ∏è\t:snowflake:\n",
    "* üõÉ\t:customs:\n",
    "* üõÇ\t:passport_control:\n",
    "* üè≥Ô∏è‚Äç‚ößÔ∏è\t:transgender_flag:\n",
    "* ü¶†\t:microbe:\n",
    "* ‚öñ\t:balance_scale:\n",
    "* üó≥Ô∏è\t:ballot_box_with_ballot:\n",
    "* ‚åõ\t:hourglass_done:\n",
    "* üë™\t:family:\t0.0\t-0.018\n",
    "  \n",
    "### --> reload the new, modified emoji_df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_df_full = pd.read_csv(\"data/emoji_full_mod1.csv\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update the VADER dictionary\n",
    "Now that we have the new wordcodes and associated values, we need to put them in the VADER dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Clouds\n",
    "__NOTE: There is a lot of preprocessing below that is ONLY used to make the wordclouds. VADER has it's own way of dealing with things like punctuation, capitalization, stopwords, tokenization, lemmatization. And we don't necessarilly want to mass with / override that without validating.__\n",
    "\n",
    "In order to refine the dictionaries, I need to know what words and bigrams/trigrams are common in which datasets. So let's make word clouds.\n",
    "\n",
    "First I need to create a single text per pos, neg, and neutral. Then I can feed them into wordcloud. I think I'll use the full dataset to generate one, too.\n",
    "\n",
    "I don't have a preexisting df for this, so I'm going to have to rebuild it. Sigh.\n",
    "\n",
    "First just all the ContentClean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP\n",
    "\n",
    "# changes to tokenizer and lemmatizer --> UPDATE in aardvark, too.\n",
    "w_tokenizer = nltk.tokenize.TweetTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#stopwords = list(STOPWORDS) + [\"Afghan\", \"Afghans\", \"Afghanistan\", \"refugee\", \"refugees\", \"U\", \"S\", \"US\", \"people\", \"will\", \"now\"]\n",
    "stopwords = nltkStop.words('english') + [\"Afghan\", \"Afghans\", \"Afghanistan\", \"refugee\", \"refugees\", \"U\", \"S\", \"US\", \"people\", \"will\", \"now\", \"UK\", \"wa\", \"say\", \"like\", \"via\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from the two sets - unlabeled and labeled - that were created in dataCleaningB\n",
    "all_l = pd.read_csv(\"all_labeled_tweets.csv\", header=0, index_col=0)\n",
    "all_u = pd.read_csv(\"all_unlabeled_tweets.csv\", header=0, index_col=0)\n",
    "print(list(all_l.columns))\n",
    "print(list(all_u.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_list = ['Content','Labels', 'label_sent', 'y_sent', 'label_stance', 'y_stance', 'Flag', 'n_CapLetters', 'CapsRatio', 'AllCapWords', 'https', 'Mentions', 'Location', 'ReplyCount', 'RetweetCount', 'LikeCount', 'QuoteCount', 'Hashtags']\n",
    "all_l.drop(l_list, axis=1, inplace=True)\n",
    "print(list(all_l.columns))\n",
    "\n",
    "u_list = ['Content', 'Flag']\n",
    "all_u.drop(u_list, axis=1, inplace=True)\n",
    "print(list(all_u.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE that I'm ordering here by date. Not sure why...\n",
    "\n",
    "frames = [all_l, all_u]\n",
    "master_tweets = pd.concat(frames)\n",
    "master_tweets.sort_values(by=['Date'], inplace=True)\n",
    "master_tweets.reset_index(drop=True, inplace=True)\n",
    "print(master_tweets.shape)\n",
    "master_tweets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAUSE / UNPAUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pause\n",
    "master_tweets.to_csv(os.path.join('dataVader', \"master_tweets.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpause\n",
    "master_tweets = pd.read_csv(os.path.join('dataVader', \"master_tweets.csv\"), header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Data Wordcloud\n",
    "from the full dataset, stopwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to: https://jackmckew.dev/sentiment-analysis-text-cleaning-in-python-with-vader.html\n",
    "train_words = ' '.join(master_tweets[\"ContentClean\"])\n",
    "a = aa.lemmatize_text(train_words)\n",
    "lem_words = ' '.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CITE: https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html\n",
    "wc = WordCloud(stopwords=stopwords, width=900, height=500, max_words=30).generate(lem_words)\n",
    "all_wc = wc.words_  # dictionary of the words used to make the cloud\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word cloud by label\n",
    "Now the labeled data, divied up by label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_xy = pd.read_csv(os.path.join('data', \"all_labeled_tweets.csv\"), header=0, index_col=0)\n",
    "print(list(all_xy.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ['Content', 'Labels', 'label_sent', 'label_stance', 'y_stance', 'n_CapLetters', 'CapsRatio', 'AllCapWords', 'https', 'Mentions', 'Location', 'ReplyCount', 'RetweetCount', 'LikeCount', 'QuoteCount', 'Hashtags', 'Flag']\n",
    "master_labeled = all_xy.drop(d, axis=1)\n",
    "master_labeled.sort_values(by=['Date'], inplace=True)\n",
    "master_labeled.reset_index(drop=True, inplace=True)\n",
    "print(master_labeled.shape)\n",
    "master_labeled.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_zero = master_labeled[master_labeled[\"y_sent\"]==0].copy()  # neu\n",
    "labeled_one = master_labeled[master_labeled[\"y_sent\"]==1].copy()  # neg\n",
    "labeled_two = master_labeled[master_labeled[\"y_sent\"]==2].copy()  # pos\n",
    "print(labeled_zero.shape)\n",
    "print(labeled_one.shape)\n",
    "print(labeled_two.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAUSE / UNPAUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pause\n",
    "master_labeled.to_csv(os.path.join('dataVader', \"master_labelel.csv\"))\n",
    "labeled_zero.to_csv(os.path.join('dataVader', \"labeled_zero.csv\"))\n",
    "labeled_one.to_csv(os.path.join('dataVader', \"labeled_one.csv\"))\n",
    "labeled_two.to_csv(os.path.join('dataVader', \"labeled_two.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess for wordcloud: Tokenize and Lemmatize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_words = ' '.join(labeled_zero[\"ContentClean\"])\n",
    "zero_lem = aa.lemmatize_text(zero_words)\n",
    "zero_lem = ' '.join(zero_lem)\n",
    "\n",
    "one_words = ' '.join(labeled_one[\"ContentClean\"])\n",
    "one_lem = aa.lemmatize_text(one_words)\n",
    "one_lem = ' '.join(one_lem)\n",
    "\n",
    "two_words = ' '.join(labeled_two[\"ContentClean\"])\n",
    "two_lem = aa.lemmatize_text(two_words)\n",
    "two_lem = ' '.join(two_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neutral\n",
    "wc = WordCloud(stopwords=stopwords, width=900, height=500, max_words=30).generate(zero_lem)\n",
    "neu_wc = wc.words_  # dictionary of the words used to make the cloud\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative\n",
    "wc = WordCloud(stopwords=stopwords, width=900, height=500, max_words=30).generate(one_lem)\n",
    "neg_wc = wc.words_  # dictionary of the words used to make the cloud\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive\n",
    "wc = WordCloud(stopwords=stopwords, width=900, height=500, max_words=30).generate(two_lem)\n",
    "pos_wc = wc.words_  # dictionary of the words used to make the cloud\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant in all three:\n",
    "* asylum (this is surprising)\n",
    "* \"ha\" is in both pos and neg. Does Vader catch this as sarcastic in the neg? This should be an intensifier, not a sentiment.\n",
    "\n",
    "Add negiative score to:\n",
    "* Taliban\n",
    "* unvetted\n",
    "* left behind\n",
    "* crisis\n",
    "\n",
    "Add positive score to:\n",
    "* community\n",
    "* help/ing (and why are these not fied by the lemmatizer?)\n",
    "* family (this is in neutral too, but I think it might help w positive)\n",
    "* resettlement (this is in neg, but really small... and in neu, maybe slightly positive)\n",
    "* Thank\n",
    "* welcome\n",
    "* support\n",
    "* opportunity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams and Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neutral - up to trigrams allowed\n",
    "wc = WordCloud(stopwords=stopwords, width=900, height=500, collocation_threshold = 3, max_words=30).generate(zero_lem)\n",
    "neu_bi_wc = wc.words_  # dictionary of the words used to make the cloud\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = '%&\\()*,./:;<=>[\\\\]^_`{|}~!?#0123456789'\n",
    "\n",
    "# starting from zero_lem, which was tokenized and lematized above, but stopwords were \n",
    "# not removed (used wordcloud's stopword remover). Clean it up for ngrams\n",
    "ngram_text = zero_lem.replace(\"_\", \" \")\n",
    "ngram_text = [word.strip(punct) for word in ngram_text.split()]\n",
    "ngram_text = [word for word in ngram_text if word not in stopwords]  # remove stopwords\n",
    "ngram_text = [s for s in ngram_text if len(s) != 0]  # remove empties\n",
    "ngram_text_neu = ' '.join(ngram_text)\n",
    "\n",
    "# find frequency of the bi/trigrams\n",
    "bi_neu, tri_neu = aa.bi_tri_freq(ngram_text_neu)\n",
    "print(\"Neutral nGrams\")\n",
    "print(bi_neu[:25])\n",
    "print()\n",
    "print(tri_neu[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative, trigrams allowed\n",
    "wc = WordCloud(stopwords=stopwords, width=900, height=500, collocation_threshold = 3, max_words=30).generate(one_lem)\n",
    "neg_bi_wc = wc.words_  # dictionary of the words used to make the cloud\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = '%&\\()*,./:;<=>[\\\\]^_`{|}~!?#0123456789'\n",
    "\n",
    "# starting from zero_lem, which was tokenized and lematized above, but stopwords were \n",
    "# not removed (used wordcloud's stopword remover). Clean it up for ngrams\n",
    "ngram_text = one_lem.replace(\"_\", \" \")\n",
    "ngram_text = [word.strip(punct) for word in ngram_text.split()]\n",
    "ngram_text = [word for word in ngram_text if word not in stopwords]  # remove stopwords\n",
    "ngram_text = [s for s in ngram_text if len(s) != 0]  # remove empties\n",
    "ngram_text_neg = ' '.join(ngram_text)\n",
    "\n",
    "# find frequency of the bi/trigrams\n",
    "bi_neg, tri_neg = aa.bi_tri_freq(ngram_text_neg)\n",
    "print(\"Negative nGrams\")\n",
    "print(bi_neg[:25])\n",
    "print()\n",
    "print(tri_neg[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive, trigrams allowed\n",
    "wc = WordCloud(stopwords=stopwords, width=900, height=500, collocation_threshold = 3, max_words=30).generate(two_lem)\n",
    "pos_bi_wc = wc.words_  # dictionary of the words used to make the cloud\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = '%&\\()*,./:;<=>[\\\\]^_`{|}~!?#0123456789'\n",
    "\n",
    "# starting from zero_lem, which was tokenized and lematized above, but stopwords were \n",
    "# not removed (used wordcloud's stopword remover). Clean it up for ngrams\n",
    "ngram_text = two_lem.replace(\"_\", \" \")\n",
    "ngram_text = [word.strip(punct) for word in ngram_text.split()]\n",
    "ngram_text = [word for word in ngram_text if word not in stopwords]  # remove stopwords\n",
    "ngram_text = [s for s in ngram_text if len(s) != 0]  # remove empties\n",
    "ngram_text_pos = ' '.join(ngram_text)\n",
    "\n",
    "# find frequency of the bi/trigrams\n",
    "bi_pos, tri_pos = aa.bi_tri_freq(ngram_text_pos)\n",
    "print(\"Neutral nGrams\")\n",
    "print(bi_pos[:15])\n",
    "print()\n",
    "print(tri_pos[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of the words used to make the cloud\n",
    "neu_wc\n",
    "neu_words = []\n",
    "for key, val in neu_wc.items():\n",
    "    neu_words.append(key)\n",
    "\n",
    "neu_bi_wc\n",
    "neu_bigs = []\n",
    "for key, val in neu_bi_wc.items():\n",
    "    neu_bigs.append(key)\n",
    "\n",
    "neg_wc\n",
    "neg_words = []\n",
    "for key, val in neg_wc.items():\n",
    "    neg_words.append(key)\n",
    "\n",
    "neg_bi_wc\n",
    "neg_bigs = []\n",
    "for key, val in neg_bi_wc.items():\n",
    "    neg_bigs.append(key)\n",
    "\n",
    "pos_wc\n",
    "pos_words = []\n",
    "for key, val in pos_wc.items():\n",
    "    pos_words.append(key)\n",
    "\n",
    "pos_bi_wc\n",
    "pos_bigs = []\n",
    "for key, val in pos_bi_wc.items():\n",
    "    pos_bigs.append(key)\n",
    "\n",
    "wc_words = pd.DataFrame({\"neu words\":neu_words, \"neg words\":neg_words, \"pos words\":pos_words, \"neu nGrams\":neu_bigs, \"neg nGrams\":neg_bigs, \"pos nGrams\":pos_bigs})\n",
    "wc_words[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Neutral nGrams\")\n",
    "print(bi_neu[:10])\n",
    "print(tri_neu[:10])\n",
    "print()\n",
    "print(\"Negative nGrams\")\n",
    "print(bi_neg[:10])\n",
    "print(tri_neg[:10])\n",
    "print()\n",
    "print(\"Positive nGrams\")\n",
    "print(bi_pos[:10])\n",
    "print(tri_pos[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should have included this in the aardvark function. Oh well.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "words_in_text = list(ngrams(ngram_text_neu.split(), 1))\n",
    "words_in_text = [' '.join(i) for i in words_in_text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "bag_of_words = vectorizer.fit_transform(words_in_text)\n",
    "vectorizer.vocabulary_\n",
    "sum_words = bag_of_words.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_in_text_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "print(\"Frequent Words: Neutral Tweets\")\n",
    "print(words_in_text_freq[:25])\n",
    "print()\n",
    "\n",
    "words_in_text = list(ngrams(ngram_text_neg.split(), 1))\n",
    "words_in_text = [' '.join(i) for i in words_in_text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "bag_of_words = vectorizer.fit_transform(words_in_text)\n",
    "vectorizer.vocabulary_\n",
    "sum_words = bag_of_words.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_in_text_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "print(\"Frequent Words: Negative Tweets\")\n",
    "print(words_in_text_freq[:25])\n",
    "print()\n",
    "\n",
    "words_in_text = list(ngrams(ngram_text_pos.split(), 1))\n",
    "words_in_text = [' '.join(i) for i in words_in_text]\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "bag_of_words = vectorizer.fit_transform(words_in_text)\n",
    "vectorizer.vocabulary_\n",
    "sum_words = bag_of_words.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_in_text_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "print(\"Frequent Words: Positive Tweets\")\n",
    "print(words_in_text_freq[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate approach: easier code, messier results.\n",
    "from nltk.probability import FreqDist\n",
    "pos_tok = ngram_text_pos.split(\" \")\n",
    "fdist = FreqDist(pos_tok)\n",
    "fdist = fdist.most_common(5)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_tweets = pd.read_csv(os.path.join('dataVader', \"master_labelel.csv\"), index_col=0, header=0)\n",
    "check_tweets = pd.read_csv(os.path.join('dataVader', \"master_tweets.csv\"), index_col=0, header=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALTERNATE term check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_count = 0\n",
    "for id, text in zip(check_tweets.id_stable, check_tweets[\"ContentClean\"]):\n",
    "    if \"üîú\" in text.lower():  #osamabin: 6; binladen: 11; ben laden: 1\n",
    "        print(id, \":\", text)\n",
    "        my_count += 1\n",
    "my_count\n",
    "# Orig: left behind: 3992 instances in master_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sent_compound(\"embarrassing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding to VADER\n",
    "### Stop Words \n",
    "VADER takes care of stop word removal. I would to refine what is considered a stopword, but that's surprisingly complicated. So instead we are going to change the lexicon to make the relevant words score = 0.\n",
    "\n",
    "Add: all the ones that were used for WordCloud: \"Afghan\", \"Afghans\", \"Afghanistan\", \"refugee\", \"refugees\", \"U\", \"S\", \"US\", \"people\", \"will\", \"now\", \"UK\", \"wa\", \"ha\", \"say\", \"like\", \"via\"\n",
    "\n",
    "Also: \"asylum\", \"seeker\", \"special\", \"family\", \"country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "change_lex = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_list = [\"asylum\", \"seeker\", \"special\", \"family\", \"country\", \"Afghan\", \"Afghans\", \"Afghanistan\", \"refugee\", \"refugees\", \"U\", \"S\", \"US\", \"people\", \"will\", \"now\", \"UK\", \"wa\", \"ha\", \"say\", \"like\", \"via\"]\n",
    "for i in check_list:\n",
    "    print(i, \":\", vader_sent_compound(i))  #üí©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_lex[\"special\"]=0\n",
    "change_lex[\"like\"] = 0\n",
    "change_lex[\"ha\"] = 0\n",
    "sid.lexicon.update(change_lex)\n",
    "# \"ha\" is in both pos and neg (sarcastic); this should be an intensifier, not a sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Dictionary terms\n",
    "emojis\n",
    "\n",
    "negative: left behind, unvetted, Taliban, Osama bin Laden, crisis\n",
    "\n",
    "Positive: soccer, citizen, help, support, thank, welcome, hope\n",
    "\n",
    "Neutral: resettle, resettlement\n",
    "\n",
    "#thanks: https://stackoverflow.com/questions/40481348/is-it-possible-to-edit-nltks-vader-sentiment-lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_list = [\"left behind\", \"unvetted\", \"Taliban\", \"Laden\", \"crisis\", \"soccer\", \"citizen\", \"help\", \"support\", \"thank\", \"welcome\", \"hope\", \"resettle\", \"resettlement\"]\n",
    "\n",
    "for i in check_list:\n",
    "    print(i, \":\", vader_sent_compound(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_lex[\"left behind\"] = -3\n",
    "change_lex[\"unvetted\"] = -2\n",
    "change_lex[\"taliban\"] = -1\n",
    "change_lex[\"laden\"] = -1  # In the full dataset, there are 123 \" bin laden\"s and 156 \"laden\"s; most of these are made up by just the most obvious misspellings (#osamabin: 6; binladen: 11; ben laden: 1). Good enough.\n",
    "change_lex[\"soccer\"] = 1\n",
    "change_lex[\"citizen\"] = 1\n",
    "sid.lexicon.update(change_lex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"left behind\" needs to be changed into a single word for VADER to score it appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vader_sent_compound(\"left behind\"))\n",
    "change_lex[\"left_behind\"] = 2\n",
    "sid.lexicon.update(change_lex)\n",
    "vader_sent_compound(\"left_behind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_count = 0\n",
    "for id, text in zip(check_tweets.id_stable, x_train[\"ContentClean\"]):\n",
    "    if \"left behind\" in text.lower():  #osamabin: 6; binladen: 11; ben laden: 1\n",
    "        #print(id, \":\", text)\n",
    "        my_count += 1\n",
    "print(my_count)\n",
    "\n",
    "my_count = 0\n",
    "for id, text in zip(check_tweets.id_stable, x_train[\"ContentClean\"]):\n",
    "    if \"left_behind\" in text.lower():  #osamabin: 6; binladen: 11; ben laden: 1\n",
    "        #print(id, \":\", text)\n",
    "        my_count += 1\n",
    "print(my_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in zip(x_train.index, x_train[\"ContentClean\"]):\n",
    "    x_train.loc[i, [\"ContentClean\"]] = text.lower().replace('left behind', 'left_behind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(columns = [\"VADERsid\", \"VADERcompound\", \"VADERpred\"], axis = 1, inplace = True)\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the functions to stick it all into the df\n",
    "x_train[\"VADERsid\"] = x_train[\"Content\"].apply(vader_sid)\n",
    "x_train[\"VADERcompound\"] = x_train[\"Content\"].apply(vader_sent_compound)\n",
    "x_train[\"VADERpred\"] = x_train[\"Content\"].apply(vader_pred)\n",
    "\n",
    "print(\"Ground Truth:\")\n",
    "print(y_train_sent[\"y_sent\"].value_counts())\n",
    "print(\"Pred:\")\n",
    "print(x_train[\"VADERpred\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same \"true\" as above\n",
    "# Get the prediction list\n",
    "lex1_pred = list(x_train[\"VADERpred\"])\n",
    "\n",
    "# Find the microaverage of the F1 scores\n",
    "base_microF1 = f1_score(y_true=true, y_pred=lex1_pred, average='micro', zero_division='warn')\n",
    "base_macroF1 = f1_score(y_true=true, y_pred=lex1_pred, average='macro', zero_division='warn')\n",
    "\n",
    "print(\"Micro and Macro-Average\")\n",
    "print('\\tVADER_lex1 F-score, micro average: {:04.3f}'.format(base_microF1))\n",
    "print('\\tVADER_lex1 F-score, macro average: {:04.3f}'.format(base_macroF1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a little bit better, but really not much. And not over the baseline.\n",
    "* Underpredicting neutral\n",
    "* Underpredicting negative\n",
    "* Overpredicting positive\n",
    "\n",
    "Baseline: Majority Class Prediction\n",
    "* Majority class prediction F-score, micro average: 0.606\n",
    "* Majority class prediction F-score, macro average: 0.252\n",
    "\n",
    "VADER-base, untuned:\n",
    "* VADER-base F-score, micro average: 0.543\n",
    "* VADER-base F-score, macro average: 0.502\n",
    "\n",
    "VADER-base, lexicon with updated sentiment terms\n",
    "* VADER_lex_ F-score, micro average: 0.563\n",
    "* VADER_lex_ F-score, macro average: 0.521\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [x_train, y_train_sent]\n",
    "train_temp = pd.concat(frames, axis=1)\n",
    "train_temp.drop([\"Date\", \"Content\", \"ContentClean\", \"VADERsid\"], axis=1, inplace=True)\n",
    "train_temp = train_temp.iloc [:, [0, 1, 2, 4]]  \n",
    "train_temp.columns = [\"id_stable\", \"VADERcompound\", \"VADERpred\", \"GroundTruth\"]\n",
    "print(train_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp.groupby('GroundTruth')['VADERcompound'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VADER Compound Score grouped by Ground Truth\")\n",
    "train_temp.boxplot(by='GroundTruth', column='VADERcompound', figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAUSE / UNPAUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAUSE\n",
    "x_train.to_csv(os.path.join('dataVader', \"x_train_VADERlex.csv\"))\n",
    "#x_val.to_csv(os.path.join('dataVader', \"x_val_VADERlex.csv\"))   NOT done yet \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNPAUSE\n",
    "x_train = pd.read_csv(os.path.join('dataVader', \"x_train_VADERlex.csv\"), header=0, index_col=0)\n",
    "x_val = pd.read_csv(os.path.join('dataVader', \"x_val_VADERlex.csv\"), header=0, index_col=0)\n",
    "y_train_sent = pd.read_csv(os.path.join('data', \"y_train_sent.csv\"), header=0, index_col=0)\n",
    "y_val_sent = pd.read_csv(os.path.join('data', \"y_val_sent.csv\"), header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new emojis to the lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_df = pd.read_csv(os.path.join('dataVader', \"emoji_score.csv\"), header=0, index_col=0)\n",
    "emoji_lex = emoji_df[emoji_df[\"VADERscore\"]==0].copy()\n",
    "emoji_lex.drop(\"VADERscore\", axis=1, inplace=True)\n",
    "emoji_lex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to do the scoring in Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_lex.to_csv(\"emoji_lex.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_lex2 = pd.read_csv(os.path.join('dataVader', \"emoji_lex_myScore.csv\"), header=0, index_col=0)\n",
    "emoji_lex2.tail()\n",
    "\n",
    "# emoji_lex2 = pd.read_csv(\"emoji_lex.csv\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, apparently VADER transforms emoji to text before extracting sentiment. I'm not exactly sure how this works: since it seems to map emoji to some pretty common words, I'm not sure how updating these sentiments would work. So I'm going to do the word transformation myself, then add those words to the lexicon with my scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del emoji_lex\n",
    "# del emoji_lex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [emoji_lex, emoji_lex2]\n",
    "emoji_lex = pd.concat(frames, axis=1)\n",
    "# emoji_lex.drop(columns=[\"demoji\", \"emosentScore\"], inplace=True)\n",
    "emoji_lex.drop(columns=[\"emoji\", \"demoji\", \"emosentScore\"], inplace=True)\n",
    "emoji_lex = emoji_lex[emoji_lex[\"lexScore\"] != 0]\n",
    "emoji_lex = dict(zip(emoji_lex[\"name\"], emoji_lex[\"lexScore\"]))\n",
    "emoji_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid.lexicon.update(emoji_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vader_sent_compound(\"person_shrugging\"))\n",
    "print(vader_sent_compound(\"clown_face\"))\n",
    "print(vader_sent_compound(\"my_broken_heart\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that works to update VADER.\n",
    "\n",
    "Now to make the transformation in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = emoji_df[emoji_df[\"VADERscore\"]==0].copy()\n",
    "a.drop(\"VADERscore\", axis=1, inplace=True)\n",
    "a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [a, emoji_lex2]\n",
    "emoji_dataUpdate = pd.concat(frames, axis=1)\n",
    "emoji_dataUpdate.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dataUpdate.loc[70, \"emoji\"] = \"üíî\"\n",
    "emoji_dataUpdate.loc[71, \"emoji\"] = \"üòî\"\n",
    "emoji_dataUpdate.loc[72, \"emoji\"] = \"üò•\"\n",
    "emoji_dataUpdate.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dataUpdate.drop(columns=[\"demoji\", \"emosentScore\", \"lexScore\"], inplace=True)\n",
    "emoji_dataUpdate.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAUSE / UNPAUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv(os.path.join('dataVader', \"temp_x_train.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(os.path.join('dataVader', \"temp_x_train.csv\"), index_col=0, header=0)\n",
    "x_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aa.term_check(\"üíÄ\", x_train))  #üíÄ sk_ull\n",
    "print(aa.term_check(\"sk_ull\", x_train))  #üíÄ sk_ull\n",
    "print(aa.term_check(\"üíî\", x_train))\n",
    "print(aa.term_check(\"my_broken_heart\", x_train))\n",
    "\n",
    "aa.term_check(\"person_shrugging\", x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in zip(x_train.index, x_train[\"ContentClean\"]):\n",
    "    if \"‚ÄºÔ∏è\" in text:\n",
    "        x_train.loc[i, [\"ContentClean\"]] = text.replace(\"‚ÄºÔ∏è\", \"!!\")\n",
    "    if \"üëä\" in text:\n",
    "        x_train.loc[i, [\"ContentClean\"]] = text.replace(\"üëä\", \"!\")\n",
    "    for emj, nme in zip(emoji_dataUpdate[\"emoji\"], emoji_dataUpdate[\"name\"]):\n",
    "        if emj in text:\n",
    "            x_train.loc[i, [\"ContentClean\"]] = text.replace(emj, str(\" \"+nme+\" \"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find new scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sid.lexicon.update(change_lex)\n",
    "print(vader_sent_compound(\"left_behind\"))\n",
    "print(vader_sent_compound(\"üíÄ\"))\n",
    "print(vader_sent_compound(\"sk_ull\"))\n",
    "print(vader_sent_compound(\"üíî\"))\n",
    "print(vader_sent_compound(\"my_broken_heart\"))\n",
    "print(vader_sent_compound(\"person_shrugging\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.drop(columns=[\"VADERsid\", \"VADERcompound\", \"VADERpred\"], axis=1, inplace=True)\n",
    "# x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the functions to stick it all into the df\n",
    "x_train[\"VADERsid\"] = x_train[\"Content\"].apply(vader_sid)\n",
    "x_train[\"VADERcompound\"] = x_train[\"Content\"].apply(vader_sent_compound)\n",
    "x_train[\"VADERpred\"] = x_train[\"Content\"].apply(vader_pred)\n",
    "\n",
    "print(\"Ground Truth:\")\n",
    "print(y_train_sent[\"y_sent\"].value_counts())\n",
    "print(\"Pred:\")\n",
    "print(x_train[\"VADERpred\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same \"true\" as above\n",
    "# Get the prediction list\n",
    "lex2_pred = x_train[\"VADERpred\"].tolist()\n",
    "\n",
    "# Find the microaverage of the F1 scores\n",
    "base_microF1 = f1_score(y_true=true, y_pred=lex2_pred, average='micro', zero_division='warn')\n",
    "base_macroF1 = f1_score(y_true=true, y_pred=lex2_pred, average='macro', zero_division='warn')\n",
    "\n",
    "print(\"Micro and Macro-Average\")\n",
    "print('\\tVADER-base w emoji lexicon, F-score, micro average: {:04.3f}'.format(base_microF1))\n",
    "print('\\tVADER-base w emoji lexicon, F-score, macro average: {:04.3f}'.format(base_macroF1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [x_train, y_train_sent]\n",
    "train_temp = pd.concat(frames, axis=1)\n",
    "train_temp.drop([\"Date\", \"Content\", \"ContentClean\", \"VADERsid\"], axis=1, inplace=True)\n",
    "train_temp = train_temp.iloc [:, [0, 1, 2, 4]]  \n",
    "train_temp.columns = [\"id_stable\", \"VADERcompound\", \"VADERpred\", \"GroundTruth\"]\n",
    "print(train_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_temp.groupby('GroundTruth')['VADERcompound'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VADER Compound Score grouped by Ground Truth\")\n",
    "train_temp.boxplot(by='GroundTruth', column='VADERcompound', figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this changes NOTHING. I guess not many rows have emojis, and/or those rows were already predicted correctly.\n",
    "\n",
    "* Underpredicting neutral\n",
    "* Underpredicting negative\n",
    "* Overpredicting positive\n",
    "\n",
    "Baseline: Majority Class Prediction\n",
    "* Majority class prediction F-score, micro average: 0.606\n",
    "* Majority class prediction F-score, macro average: 0.252\n",
    "\n",
    "VADER-base, untuned:\n",
    "* VADER-base F-score, micro average: 0.543\n",
    "* VADER-base F-score, macro average: 0.502\n",
    "\n",
    "VADER-base, lexicon with updated sentiment terms\n",
    "* VADER_lex_ F-score, micro average: 0.563\n",
    "* VADER_lex_ F-score, macro average: 0.521\n",
    "\n",
    "VADER-base w emoji lexicon\n",
    "* VADER-base w emoji lexicon, F-score, micro average: 0.563\n",
    "* VADER-base w emoji lexicon, F-score, macro average: 0.521\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and Remove more News\n",
    "Ok, so we discovered when dealing with the emojis that several of them are reliable indicators of news articles or other irrelevant rows:\n",
    "* üéôÔ∏è: audio broadcasts, esp. podcasts\n",
    "* üÜï: new infomration\n",
    "* üì°: on the radar\n",
    "* üìä: data given\n",
    "* üìÖ: event schedule   #DO THIS ONE LATER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IN THE FULL DATASET\n",
    "print(check_tweets.shape)\n",
    "my_count = 0\n",
    "for id, text in zip(check_tweets.id_stable, check_tweets[\"ContentClean\"]):\n",
    "    if \"üÜï\" in text.lower():  #osamabin: 6; binladen: 11; ben laden: 1\n",
    "        print(id, \":\", text)\n",
    "        my_count += 1\n",
    "my_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_count=0\n",
    "print(x_train.shape)\n",
    "for id, text in zip(x_train.id_stable, x_train[\"ContentClean\"]):\n",
    "    if \"new_button\" in text.lower():  #osamabin: 6; binladen: 11; ben laden: 1\n",
    "        my_count += 1\n",
    "my_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [\"studio_microphone\", \"NEW_button\", \"satellite_antenna\", \"bar_chart\"]\n",
    "indx_list = []\n",
    "# for i, text in zip(x_train.index, x_train[\"ContentClean\"]):\n",
    "#     for emj in list:\n",
    "#         if emj in text:\n",
    "#             indx_list.append(i)\n",
    "for id, text in zip(x_train.index, x_train[\"ContentClean\"]):\n",
    "    if \"bar_chart\" in text:\n",
    "        print(i)\n",
    "\n",
    "indx_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not in enough rows to be worth it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset the category thresholds\n",
    "I think the VADER people wanted to keep \"neutral\" as small as possible. That makes sense when you are talking about a simple subject. It's less useful when topics are complex (lots of pros and cons) and undecided or neutral is a viable stance to take on the subject.\n",
    "\n",
    "So let's widen the thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_pred_var(tweet):\n",
    "    scores = sid.polarity_scores(tweet)\n",
    "    comp = scores[\"compound\"]\n",
    "    if comp >= 0.1:\n",
    "        return 2\n",
    "    elif comp <= -.01:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the functions to stick it all into the df\n",
    "x_train[\"VADERsid\"] = x_train[\"Content\"].apply(vader_sid)\n",
    "x_train[\"VADERcompound\"] = x_train[\"Content\"].apply(vader_sent_compound)\n",
    "x_train[\"VADERpred\"] = x_train[\"Content\"].apply(vader_pred_var)\n",
    "\n",
    "print(\"Ground Truth:\")\n",
    "print(y_train_sent[\"y_sent\"].value_counts())\n",
    "print(\"Pred:\")\n",
    "print(x_train[\"VADERpred\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same \"true\" as above\n",
    "# Get the prediction list\n",
    "threshold_pred = x_train[\"VADERpred\"].tolist()\n",
    "\n",
    "# Find the microaverage of the F1 scores\n",
    "base_microF1 = f1_score(y_true=true, y_pred=threshold_pred, average='micro', zero_division='warn')\n",
    "base_macroF1 = f1_score(y_true=true, y_pred=threshold_pred, average='macro', zero_division='warn')\n",
    "\n",
    "print(\"Micro and Macro-Average\")\n",
    "print('\\tVADER-threshold F-score, micro average: {:04.3f}'.format(base_microF1))\n",
    "print('\\tVADER-threshold F-score, macro average: {:04.3f}'.format(base_macroF1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, disappointingly, this also does very little. Because there is so much overlap, moving the threshold may help one class, but it will about equally hurt another. There has to be better separation betwteen classes in order for this to work.\n",
    "\n",
    "NOTE: no need for boxplots, as the distribution hasn't changed.\n",
    "\n",
    "Unfortunately, I think I have to leave the analysis there and move on to writeup. I don't have time to keep working on this now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now make the selected transformations on the validate data and the full dataset.\n",
    "* sid.lexicon.update(change_lex)\n",
    "* replace \"left behind\" with \"left_behind\"\n",
    "* replace new emojis with the text equivalent in "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO CONSIDER, esp. for BERT\n",
    "* expand contractions\n",
    "* remove links, URLs\n",
    "* Replace emoji w standard text\n",
    "* What to do with hashtags\n",
    "* remove capitalization \n",
    "* What to do with punctuation: ! or ? should be useful for sentiment. Maybe \" \" for sarcasm?\n",
    "* remove whitespaces\n",
    "* Bertmoticon package, which is fine-tuned to the BERT model.\n",
    "* remove stop words beyond the standard NLTK stop words\n",
    "    * Create WordClouds to find prominant but useless words\n",
    "    * Ex: days of the week and their abbreviations, month names, and the word ‚ÄúTwitter‚Äù \n",
    "* deal w negations\n",
    "    * create a dictionary of negations so that negated words could be effectively handled\n",
    "* tokenize \n",
    "* stemming (via PorterStemmer)\n",
    "* REMEMBER:\n",
    "    * Hashtags is filled with \"No hashtags\"\n",
    "    * Location is filled with \"English-speaking\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2522cab69aef9135531abc74cfe3f2456cb406a72442e0865122b8d4f66eb9dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
