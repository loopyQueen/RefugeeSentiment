{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) <2022>, <Regina Nockerts>\n",
    "All rights reserved.\n",
    "\n",
    "This source code is licensed under the BSD-style license found in the\n",
    "LICENSE file in the root directory of this source tree. \n",
    "\n",
    "__NOTE__ to the user: In first use, this notebook cannot be run top to bottom. It assumes that you have a bunch of csv files that are created at different points in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from nlpUtils import aardvark as aa \n",
    "from sklearn.metrics import f1_score # auc if I get embeddings\n",
    "import emoji  # https://pypi.org/project/emoji/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Assumes that you have completed dataCleaningB and dataSplitBalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA\n",
      "x-TEST: (182, 3) y-TEST: (182, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji                    demoji  VaderEmojiScore  emosentScore\n",
       "0     üö®        :police_car_light:           0.0000         0.673\n",
       "1     üôè            :folded_hands:           0.0000         0.418\n",
       "2     ü§∑        :person_shrugging:           0.0000           NaN\n",
       "3     üôÑ  :face_with_rolling_eyes:           0.0000           NaN\n",
       "4     üòÇ  :face_with_tears_of_joy:           0.4404         0.221"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the files\n",
    "x_test = pd.read_csv(\"dataBalancedSets/x_test.csv\", header=0, index_col=0)\n",
    "y_test = pd.read_csv(\"dataBalancedSets/y_test_sent.csv\", header=0, index_col=0)\n",
    "tweets_clean  = pd.read_csv(\"archiveData/cleanB_tweets_clean.csv\", header=0, index_col=0) \n",
    "emoji_df_full = pd.read_csv(\"data/emoji_full.csv\", header=0, index_col=0) \n",
    "print(\"TEST DATA\")\n",
    "print(\"x-TEST:\", x_test.shape, \"y-TEST:\", y_test.shape)\n",
    "emoji_df_full.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_stable', 'Date', 'ContentClean']\n",
      "['id_stable', 'label_sent', 'y_sent', 'label_stance', 'y_stance']\n",
      "['id_stable', 'Date', 'Content', 'ContentClean', 'Labels', 'label_sent', 'y_sent', 'label_stance', 'y_stance', 'Flag']\n"
     ]
    }
   ],
   "source": [
    "print(list(x_test.columns))\n",
    "print(list(y_test.columns))\n",
    "\n",
    "print(list(tweets_clean.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>y_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170314</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192623</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106982</td>\n",
       "      <td>@pfrpeppermint @CawthornforNC Not only did Tru...</td>\n",
       "      <td>Not only did Trump stop processing asylum &amp; re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31609</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152666</td>\n",
       "      <td>@RepHerrell One moment you hate refugees and t...</td>\n",
       "      <td>One moment you hate refugees and the next you ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_stable                                            Content  \\\n",
       "0     170314  Per a White House official: Biden and Harris m...   \n",
       "1     192623  Afghan Refugee kid educated in Iran wins this ...   \n",
       "2     106982  @pfrpeppermint @CawthornforNC Not only did Tru...   \n",
       "3      31609  An Afghan refugee demands the US not forget he...   \n",
       "4     152666  @RepHerrell One moment you hate refugees and t...   \n",
       "\n",
       "                                        ContentClean  y_sent  \n",
       "0  Per a White House official: Biden and Harris m...       1  \n",
       "1  Afghan Refugee kid educated in Iran wins this ...       2  \n",
       "2  Not only did Trump stop processing asylum & re...       0  \n",
       "3  An Afghan refugee demands the US not forget he...       0  \n",
       "4  One moment you hate refugees and the next you ...       2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop_cols = ['Date', 'Labels', 'label_sent', 'label_stance', 'y_stance', 'n_CapLetters', 'CapsRatio', 'AllCapWords', 'https', 'Mentions', 'Location', 'ReplyCount', 'RetweetCount', 'LikeCount', 'QuoteCount', 'Hashtags', 'Flag']\n",
    "drop_cols = ['Date', 'Labels', 'label_sent', 'label_stance', 'y_stance', 'Flag']\n",
    "tweets_clean.drop(drop_cols, inplace=True, axis=1 )\n",
    "tweets_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________ FUNCTIONS ____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sentiment intensity dictionary object\n",
    "# sid = SentimentIntensityAnalyzer()  #NOTE: this NEEDS to stay outside of the functions. I will be modifying it.\n",
    "\n",
    "# FROM aardvark\n",
    "# creates the sentiment intensity dictionary: aa.vader_sid(tweet)\n",
    "# gets the compound score: aa.vader_sent_compound(tweet)\n",
    "# gets the classification of the compund score using the authors' suggested cutoff points: aa.vader_pred(tweet, pos_cut, neg_cut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emoji Strategies\n",
    "There are a few ways we could deal with this.\n",
    "1. Take the emojized version and transform it so üëç --> Thumbs up!  (or just \"!\", it's the same score)\n",
    "2. Translate to keyboard emoji, so üëç --> :)\n",
    "3. Add the emoji to the dictionary and give them our own score.\n",
    "4. Add the emoji to the dictionary, but give them emosent scores (https://pypi.org/project/emosent-py/)\n",
    "\n",
    "Trying a fw out on just the labeled dataset.\n",
    "\n",
    "### First\n",
    "Find scores for the emoji data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro and Macro-Average\n",
      "\tVADER F-score, micro average: 0.542\n",
      "\tVADER F-score, macro average: 0.496\n"
     ]
    }
   ],
   "source": [
    "tweets_clean[\"VADERsid\"] = tweets_clean[\"ContentClean\"].apply(aa.vader_sid)\n",
    "tweets_clean[\"VADERcompound\"] = tweets_clean[\"ContentClean\"].apply(aa.vader_sent_compound)\n",
    "tweets_clean[\"VADERpred\"] = tweets_clean[\"ContentClean\"].apply(aa.vader_pred)\n",
    "\n",
    "# Get the prediction and the grounttruth as lists\n",
    "demoji_pred = list(tweets_clean[\"VADERpred\"])\n",
    "true = list(tweets_clean[\"y_sent\"])\n",
    "\n",
    "# Find the microaverage of the F1 scores\n",
    "base_microF1 = f1_score(y_true=true, y_pred=demoji_pred, average='micro', zero_division='warn')\n",
    "base_macroF1 = f1_score(y_true=true, y_pred=demoji_pred, average='macro', zero_division='warn')\n",
    "\n",
    "print(\"Micro and Macro-Average\")\n",
    "print('\\tVADER F-score, micro average: {:04.3f}'.format(base_microF1))\n",
    "print('\\tVADER F-score, macro average: {:04.3f}'.format(base_macroF1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is a difference/improvement with exclamation point version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I strongly support üëçyour relocation from Afgh.üëç\n",
      "0.5859\n",
      "\n",
      "I strongly support !your relocation from Afgh.!\n",
      "0.658\n"
     ]
    }
   ],
   "source": [
    "text = \"I strongly support üëçyour relocation from Afgh.üëç\"\n",
    "print(text)\n",
    "print(aa.vader_sent_compound(text))\n",
    "\n",
    "text = aa.emojiToExcl(text)\n",
    "print()\n",
    "print(text)\n",
    "print(aa.vader_sent_compound(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean['ContentCleanEx'] = tweets_clean['ContentClean'].apply(aa.emojiToExcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('‚ù§Ô∏è', 3)\n",
      "('‚ù§Ô∏è', 0)\n",
      "('!', 4)\n",
      "('!', 38)\n"
     ]
    }
   ],
   "source": [
    "print(aa.term_check(\"‚ù§Ô∏è\", tweets_clean, text_col=\"ContentClean\"))\n",
    "print(aa.term_check(\"‚ù§Ô∏è\", tweets_clean, text_col=\"ContentCleanEx\"))\n",
    "print(aa.term_check(\"!\", tweets_clean, text_col=\"ContentClean\"))\n",
    "print(aa.term_check(\"!\", tweets_clean, text_col=\"ContentCleanEx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro and Macro-Average\n",
      "\tVADER-excl F-score, micro average: 0.540\n",
      "\tVADER-excl F-score, macro average: 0.495\n"
     ]
    }
   ],
   "source": [
    "tweets_clean[\"VADERsidEx\"] = tweets_clean[\"ContentCleanEx\"].apply(aa.vader_sid)\n",
    "tweets_clean[\"VADERcompoundEx\"] = tweets_clean[\"ContentCleanEx\"].apply(aa.vader_sent_compound)\n",
    "tweets_clean[\"VADERpredEx\"] = tweets_clean[\"ContentCleanEx\"].apply(aa.vader_pred)\n",
    "\n",
    "# Get the prediction and the grounttruth as lists\n",
    "demoji_pred_ex = list(tweets_clean[\"VADERpredEx\"])\n",
    "true = list(tweets_clean[\"y_sent\"])\n",
    "\n",
    "# Find the microaverage of the F1 scores\n",
    "ex_microF1 = f1_score(y_true=true, y_pred=demoji_pred_ex, average='micro', zero_division='warn')\n",
    "ex_macroF1 = f1_score(y_true=true, y_pred=demoji_pred_ex, average='macro', zero_division='warn')\n",
    "\n",
    "print(\"Micro and Macro-Average\")\n",
    "print('\\tVADER-excl F-score, micro average: {:04.3f}'.format(ex_microF1))\n",
    "print('\\tVADER-excl F-score, macro average: {:04.3f}'.format(ex_macroF1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that actually made it a tiny bit worse.\n",
    "\n",
    "Micro and Macro-Average\n",
    "\n",
    "VADER-base, untuned\n",
    "* VADER F-score, micro average: 0.542\n",
    "* VADER F-score, macro average: 0.496\n",
    "\n",
    "Emoji to Exclamation\n",
    "* VADER-excl F-score, micro average: 0.540\n",
    "* VADER-excl F-score, macro average: 0.495\n",
    "\n",
    "I'm guessing that is because the way I have done it, the exclamation point just pushes the score a bit further in the direction it was going anyway. Since the neutral category is so small to begin with, this just doesn't do much. \n",
    "\n",
    "But at the same time, I did this for ALL emojis, so it lost the validated score on the few emojis that VADER did know.\n",
    "\n",
    "This is not a good approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>y_sent</th>\n",
       "      <th>VADERsid</th>\n",
       "      <th>VADERcompound</th>\n",
       "      <th>VADERpred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170314</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>1</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.888, 'pos': 0.112, 'comp...</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192623</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>2</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.778, 'pos': 0.222, 'comp...</td>\n",
       "      <td>0.5719</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106982</td>\n",
       "      <td>@pfrpeppermint @CawthornforNC Not only did Tru...</td>\n",
       "      <td>Not only did Trump stop processing asylum &amp; re...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.064, 'neu': 0.936, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.4184</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31609</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.923, 'pos': 0.077, 'comp...</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152666</td>\n",
       "      <td>@RepHerrell One moment you hate refugees and t...</td>\n",
       "      <td>One moment you hate refugees and the next you ...</td>\n",
       "      <td>2</td>\n",
       "      <td>{'neg': 0.179, 'neu': 0.757, 'pos': 0.064, 'co...</td>\n",
       "      <td>-0.6167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_stable                                            Content  \\\n",
       "0     170314  Per a White House official: Biden and Harris m...   \n",
       "1     192623  Afghan Refugee kid educated in Iran wins this ...   \n",
       "2     106982  @pfrpeppermint @CawthornforNC Not only did Tru...   \n",
       "3      31609  An Afghan refugee demands the US not forget he...   \n",
       "4     152666  @RepHerrell One moment you hate refugees and t...   \n",
       "\n",
       "                                        ContentClean  y_sent  \\\n",
       "0  Per a White House official: Biden and Harris m...       1   \n",
       "1  Afghan Refugee kid educated in Iran wins this ...       2   \n",
       "2  Not only did Trump stop processing asylum & re...       0   \n",
       "3  An Afghan refugee demands the US not forget he...       0   \n",
       "4  One moment you hate refugees and the next you ...       2   \n",
       "\n",
       "                                            VADERsid  VADERcompound  VADERpred  \n",
       "0  {'neg': 0.0, 'neu': 0.888, 'pos': 0.112, 'comp...         0.5859          2  \n",
       "1  {'neg': 0.0, 'neu': 0.778, 'pos': 0.222, 'comp...         0.5719          2  \n",
       "2  {'neg': 0.064, 'neu': 0.936, 'pos': 0.0, 'comp...        -0.4184          0  \n",
       "3  {'neg': 0.0, 'neu': 0.923, 'pos': 0.077, 'comp...         0.1695          2  \n",
       "4  {'neg': 0.179, 'neu': 0.757, 'pos': 0.064, 'co...        -0.6167          0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean.drop([\"ContentCleanEx\", 'VADERsidEx', \"VADERcompoundEx\", \"VADERpredEx\"], axis=1, inplace=True)\n",
    "tweets_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emosent\n",
    "Will the emosent package work for me?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>demoji</th>\n",
       "      <th>VaderEmojiScore</th>\n",
       "      <th>emosentScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üö®</td>\n",
       "      <td>:police_car_light:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üôè</td>\n",
       "      <td>:folded_hands:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ü§∑</td>\n",
       "      <td>:person_shrugging:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üôÑ</td>\n",
       "      <td>:face_with_rolling_eyes:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üòÇ</td>\n",
       "      <td>:face_with_tears_of_joy:</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>ü¶æ</td>\n",
       "      <td>:mechanical_arm:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>üèÉüèæ‚Äç‚ôÇÔ∏è</td>\n",
       "      <td>:man_running_medium-dark_skin_tone:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>üöë</td>\n",
       "      <td>:ambulance:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>üéÉ</td>\n",
       "      <td>:jack-o-lantern:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>¬ÆÔ∏è</td>\n",
       "      <td>:registered:</td>\n",
       "      <td>0.0000</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1106 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emoji                               demoji  VaderEmojiScore emosentScore\n",
       "0         üö®                   :police_car_light:           0.0000        0.673\n",
       "1         üôè                       :folded_hands:           0.0000        0.418\n",
       "2         ü§∑                   :person_shrugging:           0.0000             \n",
       "3         üôÑ             :face_with_rolling_eyes:           0.0000             \n",
       "4         üòÇ             :face_with_tears_of_joy:           0.4404        0.221\n",
       "...     ...                                  ...              ...          ...\n",
       "1101      ü¶æ                     :mechanical_arm:           0.0000             \n",
       "1102  üèÉüèæ‚Äç‚ôÇÔ∏è  :man_running_medium-dark_skin_tone:           0.0000             \n",
       "1103      üöë                          :ambulance:           0.0000        0.091\n",
       "1104      üéÉ                     :jack-o-lantern:           0.0000        0.617\n",
       "1105     ¬ÆÔ∏è                         :registered:           0.0000             \n",
       "\n",
       "[1106 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_df_full[\"emosentScore\"] = emoji_df_full[\"emoji\"].apply(aa.emosent_score)\n",
    "emoji_df_full\n",
    "\n",
    "# CITE: Sentiment of Emojis, Nova et. al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          638\n",
      "0.0        21\n",
      "1.0        18\n",
      "0.333      16\n",
      "0.5         9\n",
      "         ... \n",
      "0.063       1\n",
      "0.179       1\n",
      "0.581       1\n",
      "-0.314      1\n",
      "0.617       1\n",
      "Name: emosentScore, Length: 283, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(emoji_df_full[\"emosentScore\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kinda. It has about half (missing 638) . But it seems to miss some of the important ones that I need. \n",
    "* ü§∑, ü§Æ, etc.\n",
    "\n",
    "And for the symbols where they overlap, the VADER and emosent scores do necessarilly agree and are sometimes very far off:\n",
    "* üíî (broken_heart): 0.2732 v. -0.122\n",
    "* üò≠ (loudly_crying_face): -0.4767 v. -0.093\n",
    "\n",
    "And some of the values are just off for __this__ dataset. For example, the stack of dollars (üíµ) has a emosent score of 0.423 - very high. Which makes sense normally: money is good. But in this dataset, it shows up when people are stressing the overly high cost of refugee or ilitary operations, or are talking about corruption. \n",
    "\n",
    "As this tool has been validated, I'll consider the values they have. But I'll still have to assign my own values to the remaining half. So: first VADER; if not, then emosent; if not, then my ranking; and my own ranking for emojis that are used differently than normal in my dataset.\n",
    "\n",
    "NOTE: I will have to add the emosent and my emojis to the dictionary. \n",
    "* For more insight on ranking: http://kt.ijs.si/data/Emoji_sentiment_ranking/\n",
    "\n",
    "NOTE: There is a LOT more that could be done with emojis in terms of: \n",
    "* setting sentiment scores for all emoji that appear in the dataet, not just in my labeled subset.\n",
    "* identifying news articles and other irrelevant rows in the data.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2522cab69aef9135531abc74cfe3f2456cb406a72442e0865122b8d4f66eb9dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
