{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copyright\n",
    "Copyright (c) <2022>, <Regina Nockerts>\n",
    "All rights reserved.\n",
    "\n",
    "This source code is licensed under the BSD-style license found in the\n",
    "LICENSE file in the root directory of this source tree. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nlpUtils import aardvark as aa \n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the full dataset\n",
    "tweets_data = pd.read_csv(os.path.join('archiveData', 'tweets_caps_27b_04.csv'), header=0, index_col=0)\n",
    "\n",
    "print(tweets_data.shape)\n",
    "tweets_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strategy for non-relevant rows in the main dataframe\n",
    "I did not want to further complicate the twitter search, so I gathered everything related to all refugees. Now it's time to get rid of rows that are not about Afghani refugees. So, find rows that relate to other refugee situations AND not Afghanistan, and remove them.\n",
    "\n",
    "First, I need a list of safe words: words that will **keep** a tweet in the dataset by default (list made via the iterations of searching below)\n",
    "\n",
    "SEND these rows to a keep_df. Then...\n",
    "\n",
    "Then, **remove** anything else that has one of the following terms (list made via the iterations of searching below)\n",
    "\n",
    "SEE what's left.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find likely terms for exclusion\n",
    "Start by looking for likely terms by reviewing a random subset of the full scrape. \n",
    "\n",
    "The below have been identified as likely:<br>\n",
    "('arkham', 6), \n",
    "('gotham', 3), \n",
    "('batman', 3), \n",
    "('rohinga', 5), \n",
    "('rohingya', 466), \n",
    "('syrian', 2823), \n",
    "('syria', 1753), \n",
    "('tamil', 297), \n",
    "('tigray', 271), \n",
    "('sudan', 230), \n",
    "('sudanese', 112), \n",
    "('somalia', 255), \n",
    "('somali', 238), \n",
    "('congo', 72), \n",
    "('congalese', 1), \n",
    "('congolese', 59), \n",
    "('eritrea', 125), \n",
    "('eritrean', 479), \n",
    "('apo', 2054), \n",
    "('nigeria', 226), \n",
    "('nigerian', 146), \n",
    "('uganda', 444), \n",
    "('ugandan', 206), \n",
    "('rwamwanja', 3), \n",
    "('kirwa', 0), \n",
    "('biloela', 468), \n",
    "('iraq', 2178), \n",
    "('iraqi', 20083), \n",
    "('yemen', 462), \n",
    "('yemeni', 195), \n",
    "('rwanda', 1065), \n",
    "('rwandan', 88), \n",
    "('kenya', 212), \n",
    "('kenyan', 73), \n",
    "('kashmir', 1091), \n",
    "('kashmiri', 1850), \n",
    "('palestine', 331), \n",
    "('palestinian', 514), \n",
    "('haiti', 352), \n",
    "('haitian', 646), \n",
    "('nigerian', 110), \n",
    "('tesla', 2), \n",
    "('tsla', 1).\n",
    "\n",
    "Be careful, but look at these, too:\n",
    "('patience', 123), \n",
    "('continued patience', 0), \n",
    "('rental', 100), \n",
    "('tenant', 27), \n",
    "('tenants', 56), \n",
    "('buddhist', 25), \n",
    "('hindu', 584), \n",
    "\n",
    "('vietnam', 402)\n",
    "('vietnamese', 653)\n",
    "('cambodia', 66)\n",
    "('cambodian', 52)\n",
    "('indonesia', 5813), \n",
    "('indonesian', 280), \n",
    "\n",
    "('fire', 809), \n",
    "('flood', 440), \n",
    "('landslide', 49)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arkham', 1),\n",
       " ('gotham', 2),\n",
       " ('batman', 1),\n",
       " ('rohinga', 1),\n",
       " ('rohingya', 316),\n",
       " ('syrian', 1379),\n",
       " ('syria', 431),\n",
       " ('tamil', 280),\n",
       " ('tigray', 259),\n",
       " ('sudan', 115),\n",
       " ('sudanese', 71),\n",
       " ('somalia', 82),\n",
       " ('somali', 158),\n",
       " ('congo', 43),\n",
       " ('congalese', 1),\n",
       " ('congolese', 49),\n",
       " ('eritrea', 61),\n",
       " ('eritrean', 465),\n",
       " ('apo', 2054),\n",
       " ('nigeria', 157),\n",
       " ('nigerian', 127),\n",
       " ('uganda', 225),\n",
       " ('ugandan', 132),\n",
       " ('rwamwanja', 2),\n",
       " ('kirwa', 0),\n",
       " ('biloela', 446),\n",
       " ('iraq', 951),\n",
       " ('iraqi', 18548),\n",
       " ('yemen', 88),\n",
       " ('yemeni', 66),\n",
       " ('rwanda', 894),\n",
       " ('rwandan', 83),\n",
       " ('kenya', 180),\n",
       " ('kenyan', 66),\n",
       " ('kashmir', 1027),\n",
       " ('kashmiri', 1805),\n",
       " ('palestine', 256),\n",
       " ('palestinian', 453),\n",
       " ('haiti', 117),\n",
       " ('haitian', 251),\n",
       " ('tesla', 1),\n",
       " ('tsla', 1),\n",
       " ('ukraine', 1353),\n",
       " ('ukrainian', 2403),\n",
       " ('your patience', 0),\n",
       " ('your continued patience', 0),\n",
       " ('rental', 60),\n",
       " ('tenant', 20),\n",
       " ('tenants', 47),\n",
       " ('buddhist', 16),\n",
       " ('hindu', 328)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_list = [\n",
    "    #EXCLUSION\n",
    "    \"arkham\", \"gotham\", \"batman\",\n",
    "    \"rohinga\", \"rohingya\",\n",
    "    \"syrian\", \"syria\",\n",
    "    \"tamil\",\n",
    "    \"tigray\",\n",
    "    \"sudan\", \"sudanese\",\n",
    "    \"somalia\", \"somali\",\n",
    "    \"congo\", \"congalese\", \"congolese\",\n",
    "    \"eritrea\", \"eritrean\",\n",
    "    \"apo\",\n",
    "    \"nigeria\", \"nigerian\",\n",
    "    \"uganda\", \"ugandan\",\n",
    "    \"rwamwanja\",\n",
    "    \"kirwa\", \n",
    "    \"biloela\",\n",
    "    \"iraq\", \"iraqi\",\n",
    "    \"yemen\", \"yemeni\",\n",
    "    \"rwanda\", \"rwandan\",\n",
    "    \"kenya\", \"kenyan\",\n",
    "    \"kashmir\", \"kashmiri\",\n",
    "    \"palestine\", \"palestinian\",\n",
    "    \"haiti\", \"haitian\",\n",
    "    \"tesla\", \"TSLA\",\n",
    "    \"ukraine\", \"ukrainian\",\n",
    "    \"your patience\", \"your continued patience\",\n",
    "    \"rental\", \"tenant\", \"tenants\",\n",
    "    \"buddhist\", \"hindu\"]\n",
    "\n",
    "# Second exclusion round\n",
    "    # \"Australia\"\n",
    "    # \"vietnam\", \"vietnamese\",\n",
    "    # \"cambodia\", \"cambodian\",\n",
    "    # \"indonesia\", \"indonesian\",\n",
    "    # \"fire\", \"flood\", \"landslide\", \"cyclone\"]\n",
    "\n",
    "results = []\n",
    "for i in term_list:\n",
    "    results.append(aa.term_check(i, tweets_data))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR THE FULL DATASET\n",
    "\n",
    "So, most of these are uncommon: fewer than 1,000 rows (~0.3%). Which is good: my search terms are being pretty precise.\n",
    "\n",
    "But some seem uncomfortably high: \n",
    "('syria/n', 1753 + 2823), \n",
    "('apo', 2054), \n",
    "('iraq/i', 2178 + 20,083), \n",
    "('rwanda/n', 1,065 + 88), \n",
    "('kashmir/i', 1,091 + 1,850), \n",
    "NOTE: Palestine and Ukraine should be here too, but the terms were identified later.\n",
    "\n",
    "\n",
    "And some just need a closer look in general:\n",
    "('patience', 123), \n",
    "('continued patience', 0), \n",
    "('rental', 100), \n",
    "('tenant', 27), \n",
    "('tenants', 56), \n",
    "('buddhist', 25), \n",
    "('hindu', 584), \n",
    "('vietnam/ese', 402 + 653)\n",
    "('indonesia/n', 5,813 + 280), \n",
    "('fire', 809), \n",
    "('fire', 809), \n",
    "('flood', 440), \n",
    "('landslide', 49).\n",
    "\n",
    "FOR THE EVAL DATASET:\n",
    "\n",
    "About half the data, so looking for terms with more than 500 rows...\n",
    "\n",
    " ('syrian', 1379),\n",
    " ('syria', 431),\n",
    " ('eritrea', 61),\n",
    " ('eritrean', 465),\n",
    " ('apo', 2054),\n",
    " ('iraq', 951),\n",
    " ('iraqi', 18548),\n",
    " ('rwanda', 894),\n",
    " ('rwandan', 83),\n",
    " ('kashmir', 1027),\n",
    " ('kashmiri', 1805),\n",
    " ('palestine', 256),\n",
    " ('palestinian', 453),\n",
    " ('ukraine', 1353),\n",
    " ('ukrainian', 2403),\n",
    "\n",
    "\n",
    "### Examine non-Afghan rows\n",
    "So. I need a better look at the potentially irrelevant rows. Let's make a subset of the df with all the rows with afgha* removed, and then see what is left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384241, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Flag</th>\n",
       "      <th>n_CapLetters</th>\n",
       "      <th>CapsRatio</th>\n",
       "      <th>AllCapWords</th>\n",
       "      <th>https</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Location</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384236</th>\n",
       "      <td>2021-01-01 01:55:12+00:00</td>\n",
       "      <td>@StayFierce1973 @Lala43463561 @Raufmustafaye10...</td>\n",
       "      <td>it is not we who prove this, but the R...</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@StayFierce1973, @Lala43463561, @Raufmustafaye...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384237</th>\n",
       "      <td>2021-01-01 01:07:04+00:00</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>UN\"</td>\n",
       "      <td>https://t.co/UzF1CVFfgV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384238</th>\n",
       "      <td>2021-01-01 00:43:07+00:00</td>\n",
       "      <td>@joemcafield Yep, just spent 40 mins (and coun...</td>\n",
       "      <td>Yep, just spent 40 mins (and counting) tryin...</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@joemcafield</td>\n",
       "      <td>Wakefield, England</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384239</th>\n",
       "      <td>2021-01-01 00:10:26+00:00</td>\n",
       "      <td>@StayFierce1973 @Raufmustafaye10 @alliemark5 @...</td>\n",
       "      <td>excuse me?  how do you explain the doc...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/9NvC8mkf6r</td>\n",
       "      <td>@StayFierce1973, @Raufmustafaye10, @alliemark5...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384240</th>\n",
       "      <td>2021-01-01 00:06:57+00:00</td>\n",
       "      <td>@postcovid_CH @WHO @pahowho @WHOWPRO @WHOAFRO ...</td>\n",
       "      <td>Also, there are many c...</td>\n",
       "      <td>no</td>\n",
       "      <td>7</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@postcovid_CH, @WHO, @pahowho, @WHOWPRO, @WHOA...</td>\n",
       "      <td>English-speaking</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date  \\\n",
       "384236  2021-01-01 01:55:12+00:00   \n",
       "384237  2021-01-01 01:07:04+00:00   \n",
       "384238  2021-01-01 00:43:07+00:00   \n",
       "384239  2021-01-01 00:10:26+00:00   \n",
       "384240  2021-01-01 00:06:57+00:00   \n",
       "\n",
       "                                                  Content  \\\n",
       "384236  @StayFierce1973 @Lala43463561 @Raufmustafaye10...   \n",
       "384237  20201230: Bryony Lau: Canada now resettles mor...   \n",
       "384238  @joemcafield Yep, just spent 40 mins (and coun...   \n",
       "384239  @StayFierce1973 @Raufmustafaye10 @alliemark5 @...   \n",
       "384240  @postcovid_CH @WHO @pahowho @WHOWPRO @WHOAFRO ...   \n",
       "\n",
       "                                             ContentClean Flag  n_CapLetters  \\\n",
       "384236          it is not we who prove this, but the R...   no             3   \n",
       "384237  20201230: Bryony Lau: Canada now resettles mor...   no             8   \n",
       "384238    Yep, just spent 40 mins (and counting) tryin...   no             6   \n",
       "384239          excuse me?  how do you explain the doc...   no             4   \n",
       "384240                          Also, there are many c...   no             7   \n",
       "\n",
       "        CapsRatio  AllCapWords                    https  \\\n",
       "384236   0.023438          NaN                      NaN   \n",
       "384237   0.029412          UN\"  https://t.co/UzF1CVFfgV   \n",
       "384238   0.056075  üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY                      NaN   \n",
       "384239   0.022989          NaN  https://t.co/9NvC8mkf6r   \n",
       "384240   0.023333            I                      NaN   \n",
       "\n",
       "                                                 Mentions            Location  \\\n",
       "384236  @StayFierce1973, @Lala43463561, @Raufmustafaye...      Toronto - Baku   \n",
       "384237                                                NaN             Toronto   \n",
       "384238                                       @joemcafield  Wakefield, England   \n",
       "384239  @StayFierce1973, @Raufmustafaye10, @alliemark5...      Toronto - Baku   \n",
       "384240  @postcovid_CH, @WHO, @pahowho, @WHOWPRO, @WHOA...    English-speaking   \n",
       "\n",
       "        ReplyCount  RetweetCount  LikeCount  QuoteCount     Hashtags  \n",
       "384236           0             0          1           0  No hashtags  \n",
       "384237           0             0          0           0  No hashtags  \n",
       "384238           1             0          0           0  No hashtags  \n",
       "384239           1             0          0           0  No hashtags  \n",
       "384240           0             0          3           0  No hashtags  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: This should pull from the cleanest possible .csv into a NEW df that we can flag and delete from\n",
    "tweets_nonAfg = pd.read_csv('tweets_caps_27b_04.csv', header=0, index_col=0)\n",
    "tweets_nonAfg.insert(loc=3, column='Flag', value=\"no\")\n",
    "print(tweets_nonAfg.shape)\n",
    "tweets_nonAfg.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I checked https://www.thefreedictionary.com/words-containing-afgh - it looks like there are no words containing \"afgh\" that we need to worry about; we can just kick out these rows.\n",
    "\n",
    "Same with \"kabul\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes    227112\n",
      "no     157129\n",
      "Name: Flag, dtype: int64\n",
      "yes    227728\n",
      "no     156513\n",
      "Name: Flag, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Flag</th>\n",
       "      <th>n_CapLetters</th>\n",
       "      <th>CapsRatio</th>\n",
       "      <th>AllCapWords</th>\n",
       "      <th>https</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Location</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384236</th>\n",
       "      <td>2021-01-01 01:55:12+00:00</td>\n",
       "      <td>@StayFierce1973 @Lala43463561 @Raufmustafaye10...</td>\n",
       "      <td>it is not we who prove this, but the R...</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@StayFierce1973, @Lala43463561, @Raufmustafaye...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384237</th>\n",
       "      <td>2021-01-01 01:07:04+00:00</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>UN\"</td>\n",
       "      <td>https://t.co/UzF1CVFfgV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384238</th>\n",
       "      <td>2021-01-01 00:43:07+00:00</td>\n",
       "      <td>@joemcafield Yep, just spent 40 mins (and coun...</td>\n",
       "      <td>Yep, just spent 40 mins (and counting) tryin...</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@joemcafield</td>\n",
       "      <td>Wakefield, England</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384239</th>\n",
       "      <td>2021-01-01 00:10:26+00:00</td>\n",
       "      <td>@StayFierce1973 @Raufmustafaye10 @alliemark5 @...</td>\n",
       "      <td>excuse me?  how do you explain the doc...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/9NvC8mkf6r</td>\n",
       "      <td>@StayFierce1973, @Raufmustafaye10, @alliemark5...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384240</th>\n",
       "      <td>2021-01-01 00:06:57+00:00</td>\n",
       "      <td>@postcovid_CH @WHO @pahowho @WHOWPRO @WHOAFRO ...</td>\n",
       "      <td>Also, there are many c...</td>\n",
       "      <td>yes</td>\n",
       "      <td>7</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@postcovid_CH, @WHO, @pahowho, @WHOWPRO, @WHOA...</td>\n",
       "      <td>English-speaking</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date  \\\n",
       "384236  2021-01-01 01:55:12+00:00   \n",
       "384237  2021-01-01 01:07:04+00:00   \n",
       "384238  2021-01-01 00:43:07+00:00   \n",
       "384239  2021-01-01 00:10:26+00:00   \n",
       "384240  2021-01-01 00:06:57+00:00   \n",
       "\n",
       "                                                  Content  \\\n",
       "384236  @StayFierce1973 @Lala43463561 @Raufmustafaye10...   \n",
       "384237  20201230: Bryony Lau: Canada now resettles mor...   \n",
       "384238  @joemcafield Yep, just spent 40 mins (and coun...   \n",
       "384239  @StayFierce1973 @Raufmustafaye10 @alliemark5 @...   \n",
       "384240  @postcovid_CH @WHO @pahowho @WHOWPRO @WHOAFRO ...   \n",
       "\n",
       "                                             ContentClean Flag  n_CapLetters  \\\n",
       "384236          it is not we who prove this, but the R...   no             3   \n",
       "384237  20201230: Bryony Lau: Canada now resettles mor...   no             8   \n",
       "384238    Yep, just spent 40 mins (and counting) tryin...   no             6   \n",
       "384239          excuse me?  how do you explain the doc...   no             4   \n",
       "384240                          Also, there are many c...  yes             7   \n",
       "\n",
       "        CapsRatio  AllCapWords                    https  \\\n",
       "384236   0.023438          NaN                      NaN   \n",
       "384237   0.029412          UN\"  https://t.co/UzF1CVFfgV   \n",
       "384238   0.056075  üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY                      NaN   \n",
       "384239   0.022989          NaN  https://t.co/9NvC8mkf6r   \n",
       "384240   0.023333            I                      NaN   \n",
       "\n",
       "                                                 Mentions            Location  \\\n",
       "384236  @StayFierce1973, @Lala43463561, @Raufmustafaye...      Toronto - Baku   \n",
       "384237                                                NaN             Toronto   \n",
       "384238                                       @joemcafield  Wakefield, England   \n",
       "384239  @StayFierce1973, @Raufmustafaye10, @alliemark5...      Toronto - Baku   \n",
       "384240  @postcovid_CH, @WHO, @pahowho, @WHOWPRO, @WHOA...    English-speaking   \n",
       "\n",
       "        ReplyCount  RetweetCount  LikeCount  QuoteCount     Hashtags  \n",
       "384236           0             0          1           0  No hashtags  \n",
       "384237           0             0          0           0  No hashtags  \n",
       "384238           1             0          0           0  No hashtags  \n",
       "384239           1             0          0           0  No hashtags  \n",
       "384240           0             0          3           0  No hashtags  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: This function only flags positive instances; it may be run multiple times with different terms\n",
    "# NOTE: This function starts with an input: to reset the index\n",
    "aa.flag_term(\"afg\", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\"kabul\", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "\n",
    "tweets_nonAfg.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAUSE / UNPAUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAUSE\n",
    "tweets_nonAfg.to_csv(os.path.join('archiveData', \"tweet_flagged_afg_27b_04.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpause\n",
    "\n",
    "# From this notebook's process, this is flagged but not separated (see below):\n",
    "tweets_nonAfg = pd.read_csv(os.path.join('archiveData', \"tweet_flagged_afg_27b_04.csv\"), header=0, index_col=0)\n",
    "\n",
    "# Or from the keep rows of the dataCleaning notebook, separated:\n",
    "# tweets_nonAfg = pd.read_csv(os.path.join('archiveData', 'tweets_eval_temp.csv'), header=0, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_nonAfg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate the df by flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the rows that were NOT just flagged with \"yes\" in the nonAfg df\n",
    "# ONLY RUN the first function ONCE!!\n",
    "tweets_keep = tweets_nonAfg[tweets_nonAfg[\"Flag\"] == 'yes'].copy() \n",
    "tweets_nonAfg = tweets_nonAfg[tweets_nonAfg[\"Flag\"] == 'no'].copy()\n",
    "\n",
    "# And reset the flag column\n",
    "tweets_keep.Flag = \"no\"\n",
    "tweets_nonAfg.Flag = \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep: (227728, 15)\n",
      "eval: (156513, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Flag</th>\n",
       "      <th>n_CapLetters</th>\n",
       "      <th>CapsRatio</th>\n",
       "      <th>AllCapWords</th>\n",
       "      <th>https</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Location</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384235</th>\n",
       "      <td>2021-01-01 02:55:56+00:00</td>\n",
       "      <td>Gee's Bend was a part of Federal Government's ...</td>\n",
       "      <td>Gee's Bend was a part of Federal Government's ...</td>\n",
       "      <td>no</td>\n",
       "      <td>9</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/caOdAb9xOq, https://t.co/UJfSC4S59p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384236</th>\n",
       "      <td>2021-01-01 01:55:12+00:00</td>\n",
       "      <td>@StayFierce1973 @Lala43463561 @Raufmustafaye10...</td>\n",
       "      <td>it is not we who prove this, but the R...</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@StayFierce1973, @Lala43463561, @Raufmustafaye...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384237</th>\n",
       "      <td>2021-01-01 01:07:04+00:00</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>UN\"</td>\n",
       "      <td>https://t.co/UzF1CVFfgV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384238</th>\n",
       "      <td>2021-01-01 00:43:07+00:00</td>\n",
       "      <td>@joemcafield Yep, just spent 40 mins (and coun...</td>\n",
       "      <td>Yep, just spent 40 mins (and counting) tryin...</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@joemcafield</td>\n",
       "      <td>Wakefield, England</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384239</th>\n",
       "      <td>2021-01-01 00:10:26+00:00</td>\n",
       "      <td>@StayFierce1973 @Raufmustafaye10 @alliemark5 @...</td>\n",
       "      <td>excuse me?  how do you explain the doc...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/9NvC8mkf6r</td>\n",
       "      <td>@StayFierce1973, @Raufmustafaye10, @alliemark5...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date  \\\n",
       "384235  2021-01-01 02:55:56+00:00   \n",
       "384236  2021-01-01 01:55:12+00:00   \n",
       "384237  2021-01-01 01:07:04+00:00   \n",
       "384238  2021-01-01 00:43:07+00:00   \n",
       "384239  2021-01-01 00:10:26+00:00   \n",
       "\n",
       "                                                  Content  \\\n",
       "384235  Gee's Bend was a part of Federal Government's ...   \n",
       "384236  @StayFierce1973 @Lala43463561 @Raufmustafaye10...   \n",
       "384237  20201230: Bryony Lau: Canada now resettles mor...   \n",
       "384238  @joemcafield Yep, just spent 40 mins (and coun...   \n",
       "384239  @StayFierce1973 @Raufmustafaye10 @alliemark5 @...   \n",
       "\n",
       "                                             ContentClean Flag  n_CapLetters  \\\n",
       "384235  Gee's Bend was a part of Federal Government's ...   no             9   \n",
       "384236          it is not we who prove this, but the R...   no             3   \n",
       "384237  20201230: Bryony Lau: Canada now resettles mor...   no             8   \n",
       "384238    Yep, just spent 40 mins (and counting) tryin...   no             6   \n",
       "384239          excuse me?  how do you explain the doc...   no             4   \n",
       "\n",
       "        CapsRatio  AllCapWords  \\\n",
       "384235   0.075630          NaN   \n",
       "384236   0.023438          NaN   \n",
       "384237   0.029412          UN\"   \n",
       "384238   0.056075  üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY   \n",
       "384239   0.022989          NaN   \n",
       "\n",
       "                                                   https  \\\n",
       "384235  https://t.co/caOdAb9xOq, https://t.co/UJfSC4S59p   \n",
       "384236                                               NaN   \n",
       "384237                           https://t.co/UzF1CVFfgV   \n",
       "384238                                               NaN   \n",
       "384239                           https://t.co/9NvC8mkf6r   \n",
       "\n",
       "                                                 Mentions            Location  \\\n",
       "384235                                                NaN             Alabama   \n",
       "384236  @StayFierce1973, @Lala43463561, @Raufmustafaye...      Toronto - Baku   \n",
       "384237                                                NaN             Toronto   \n",
       "384238                                       @joemcafield  Wakefield, England   \n",
       "384239  @StayFierce1973, @Raufmustafaye10, @alliemark5...      Toronto - Baku   \n",
       "\n",
       "        ReplyCount  RetweetCount  LikeCount  QuoteCount     Hashtags  \n",
       "384235           0             1          1           0  No hashtags  \n",
       "384236           0             0          1           0  No hashtags  \n",
       "384237           0             0          0           0  No hashtags  \n",
       "384238           1             0          0           0  No hashtags  \n",
       "384239           1             0          0           0  No hashtags  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"keep:\", tweets_keep.shape)  # 227,728\n",
    "print(\"eval:\", tweets_nonAfg.shape)\n",
    "tweets_nonAfg.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick peek at the kept rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('afghanistan', 40654)\n",
      "('afghanistan', 0)\n"
     ]
    }
   ],
   "source": [
    "print(aa.term_check(\"afghanistan\", tweets_keep))\n",
    "print(aa.term_check(\"afghanistan\", tweets_nonAfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dataframe and temp_subset_gen.csv of length 25 have been created\n",
      "To end the session, enter 'ESC'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y    23\n",
       "n     1\n",
       "Name: ContentLabel, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peek = aa.subset_gen(tweets_keep, 25)\n",
    "aa.labeler(peek, col=\"ContentClean\", lab=\"ContentLabel\", verby=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Overwhelmingly relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pause/Unpause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAUSE\n",
    "tweets_keep.to_csv(os.path.join('archiveData', \"tweet_flagged_keep_27b_04.csv\"))\n",
    "tweets_nonAfg.to_csv(os.path.join('archiveData', \"tweet_flagged_nonAfg_27b_04.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227728, 15)\n",
      "(156513, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Flag</th>\n",
       "      <th>n_CapLetters</th>\n",
       "      <th>CapsRatio</th>\n",
       "      <th>AllCapWords</th>\n",
       "      <th>https</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Location</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384235</th>\n",
       "      <td>2021-01-01 02:55:56+00:00</td>\n",
       "      <td>Gee's Bend was a part of Federal Government's ...</td>\n",
       "      <td>Gee's Bend was a part of Federal Government's ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/caOdAb9xOq, https://t.co/UJfSC4S59p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384236</th>\n",
       "      <td>2021-01-01 01:55:12+00:00</td>\n",
       "      <td>@StayFierce1973 @Lala43463561 @Raufmustafaye10...</td>\n",
       "      <td>it is not we who prove this, but the R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@StayFierce1973, @Lala43463561, @Raufmustafaye...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384237</th>\n",
       "      <td>2021-01-01 01:07:04+00:00</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>UN\"</td>\n",
       "      <td>https://t.co/UzF1CVFfgV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384238</th>\n",
       "      <td>2021-01-01 00:43:07+00:00</td>\n",
       "      <td>@joemcafield Yep, just spent 40 mins (and coun...</td>\n",
       "      <td>Yep, just spent 40 mins (and counting) tryin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@joemcafield</td>\n",
       "      <td>Wakefield, England</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384239</th>\n",
       "      <td>2021-01-01 00:10:26+00:00</td>\n",
       "      <td>@StayFierce1973 @Raufmustafaye10 @alliemark5 @...</td>\n",
       "      <td>excuse me?  how do you explain the doc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/9NvC8mkf6r</td>\n",
       "      <td>@StayFierce1973, @Raufmustafaye10, @alliemark5...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date  \\\n",
       "384235  2021-01-01 02:55:56+00:00   \n",
       "384236  2021-01-01 01:55:12+00:00   \n",
       "384237  2021-01-01 01:07:04+00:00   \n",
       "384238  2021-01-01 00:43:07+00:00   \n",
       "384239  2021-01-01 00:10:26+00:00   \n",
       "\n",
       "                                                  Content  \\\n",
       "384235  Gee's Bend was a part of Federal Government's ...   \n",
       "384236  @StayFierce1973 @Lala43463561 @Raufmustafaye10...   \n",
       "384237  20201230: Bryony Lau: Canada now resettles mor...   \n",
       "384238  @joemcafield Yep, just spent 40 mins (and coun...   \n",
       "384239  @StayFierce1973 @Raufmustafaye10 @alliemark5 @...   \n",
       "\n",
       "                                             ContentClean  Flag  n_CapLetters  \\\n",
       "384235  Gee's Bend was a part of Federal Government's ...   NaN             9   \n",
       "384236          it is not we who prove this, but the R...   NaN             3   \n",
       "384237  20201230: Bryony Lau: Canada now resettles mor...   NaN             8   \n",
       "384238    Yep, just spent 40 mins (and counting) tryin...   NaN             6   \n",
       "384239          excuse me?  how do you explain the doc...   NaN             4   \n",
       "\n",
       "        CapsRatio  AllCapWords  \\\n",
       "384235   0.075630          NaN   \n",
       "384236   0.023438          NaN   \n",
       "384237   0.029412          UN\"   \n",
       "384238   0.056075  üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY   \n",
       "384239   0.022989          NaN   \n",
       "\n",
       "                                                   https  \\\n",
       "384235  https://t.co/caOdAb9xOq, https://t.co/UJfSC4S59p   \n",
       "384236                                               NaN   \n",
       "384237                           https://t.co/UzF1CVFfgV   \n",
       "384238                                               NaN   \n",
       "384239                           https://t.co/9NvC8mkf6r   \n",
       "\n",
       "                                                 Mentions            Location  \\\n",
       "384235                                                NaN             Alabama   \n",
       "384236  @StayFierce1973, @Lala43463561, @Raufmustafaye...      Toronto - Baku   \n",
       "384237                                                NaN             Toronto   \n",
       "384238                                       @joemcafield  Wakefield, England   \n",
       "384239  @StayFierce1973, @Raufmustafaye10, @alliemark5...      Toronto - Baku   \n",
       "\n",
       "        ReplyCount  RetweetCount  LikeCount  QuoteCount     Hashtags  \n",
       "384235           0             1          1           0  No hashtags  \n",
       "384236           0             0          1           0  No hashtags  \n",
       "384237           0             0          0           0  No hashtags  \n",
       "384238           1             0          0           0  No hashtags  \n",
       "384239           1             0          0           0  No hashtags  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# UNPAUSE\n",
    "tweets_keep = pd.read_csv(os.path.join('archiveData', \"tweet_flagged_keep_27b_04.csv\"), header=0, index_col=0)\n",
    "tweets_nonAfg = pd.read_csv(os.path.join('archiveData', \"tweet_flagged_nonAfg_27b_04.csv\"), header=0, index_col=0)\n",
    "\n",
    "print(tweets_keep.shape)\n",
    "print(tweets_nonAfg.shape)\n",
    "tweets_nonAfg.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Kabul?\n",
    "There are still 190 tweets that have \"kab\" (this is a partial match, so can't do it through the term checker - flag it instead and look at flag value_counts). I want to look at those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     156323\n",
      "yes       190\n",
      "Name: Flag, dtype: int64\n",
      "df shape: (156513, 15)\n",
      "rows with term no     156323\n",
      "yes       190\n",
      "Name: Flag, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "tweets_nonAfg.Flag = \"no\"\n",
    "\n",
    "## This function starts with an input: index box\n",
    "aa.flag_term(\"kab\", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "print(\"df shape:\", tweets_nonAfg.shape)\n",
    "print(\"rows with term\", tweets_nonAfg.Flag.value_counts())\n",
    "#tweets_keep.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Flag</th>\n",
       "      <th>n_CapLetters</th>\n",
       "      <th>CapsRatio</th>\n",
       "      <th>AllCapWords</th>\n",
       "      <th>https</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Location</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151569</th>\n",
       "      <td>2021-01-18 21:27:30+00:00</td>\n",
       "      <td>So honored to work with the Cases, the Huckabe...</td>\n",
       "      <td>So honored to work with the Cases, the Huckabe...</td>\n",
       "      <td>yes</td>\n",
       "      <td>10</td>\n",
       "      <td>0.045249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/Ta7MTO0dll, https://t.co/nIfbrrWTa0</td>\n",
       "      <td>@arktimes</td>\n",
       "      <td>English-speaking</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151723</th>\n",
       "      <td>2021-01-18 16:39:49+00:00</td>\n",
       "      <td>Post Edited: Former Gov. Mike Huckabee to rese...</td>\n",
       "      <td>Post Edited: Former Gov. Mike Huckabee to rese...</td>\n",
       "      <td>yes</td>\n",
       "      <td>8</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/Lo5AjoAfoD, https://t.co/mTqqY3a9ib</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HeartOfAmerica</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151726</th>\n",
       "      <td>2021-01-18 16:31:28+00:00</td>\n",
       "      <td>Former Gov. Mike Huckabee to resettle on five-...</td>\n",
       "      <td>Former Gov. Mike Huckabee to resettle on five-...</td>\n",
       "      <td>yes</td>\n",
       "      <td>6</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/vDvQrAGNWM</td>\n",
       "      <td>@arktimes</td>\n",
       "      <td>maxbrantley@arktimes.com</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153115</th>\n",
       "      <td>2021-01-13 17:01:41+00:00</td>\n",
       "      <td>It will be recalled that Akufo-Addo in 2019 he...</td>\n",
       "      <td>It will be recalled that Akufo-Addo in 2019 he...</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>0.043321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153268</th>\n",
       "      <td>2021-01-13 11:45:55+00:00</td>\n",
       "      <td>Two locations to invest in Abuja for near futu...</td>\n",
       "      <td>Two locations to invest in Abuja for near futu...</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.029197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abuja -Nigeria</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date  \\\n",
       "151569  2021-01-18 21:27:30+00:00   \n",
       "151723  2021-01-18 16:39:49+00:00   \n",
       "151726  2021-01-18 16:31:28+00:00   \n",
       "153115  2021-01-13 17:01:41+00:00   \n",
       "153268  2021-01-13 11:45:55+00:00   \n",
       "\n",
       "                                                  Content  \\\n",
       "151569  So honored to work with the Cases, the Huckabe...   \n",
       "151723  Post Edited: Former Gov. Mike Huckabee to rese...   \n",
       "151726  Former Gov. Mike Huckabee to resettle on five-...   \n",
       "153115  It will be recalled that Akufo-Addo in 2019 he...   \n",
       "153268  Two locations to invest in Abuja for near futu...   \n",
       "\n",
       "                                             ContentClean Flag  n_CapLetters  \\\n",
       "151569  So honored to work with the Cases, the Huckabe...  yes            10   \n",
       "151723  Post Edited: Former Gov. Mike Huckabee to rese...  yes             8   \n",
       "151726  Former Gov. Mike Huckabee to resettle on five-...  yes             6   \n",
       "153115  It will be recalled that Akufo-Addo in 2019 he...  yes            12   \n",
       "153268  Two locations to invest in Abuja for near futu...  yes             4   \n",
       "\n",
       "        CapsRatio AllCapWords  \\\n",
       "151569   0.045249         NaN   \n",
       "151723   0.083333         NaN   \n",
       "151726   0.068966         NaN   \n",
       "153115   0.043321         NaN   \n",
       "153268   0.029197         NaN   \n",
       "\n",
       "                                                   https   Mentions  \\\n",
       "151569  https://t.co/Ta7MTO0dll, https://t.co/nIfbrrWTa0  @arktimes   \n",
       "151723  https://t.co/Lo5AjoAfoD, https://t.co/mTqqY3a9ib        NaN   \n",
       "151726                           https://t.co/vDvQrAGNWM  @arktimes   \n",
       "153115                                               NaN        NaN   \n",
       "153268                                               NaN        NaN   \n",
       "\n",
       "                        Location  ReplyCount  RetweetCount  LikeCount  \\\n",
       "151569          English-speaking           0             0          0   \n",
       "151723            HeartOfAmerica           0             0          0   \n",
       "151726  maxbrantley@arktimes.com          12             1          7   \n",
       "153115            Lagos, Nigeria           1             0          0   \n",
       "153268            Abuja -Nigeria           0             0          2   \n",
       "\n",
       "        QuoteCount     Hashtags  \n",
       "151569           0  No hashtags  \n",
       "151723           0  No hashtags  \n",
       "151726           4  No hashtags  \n",
       "153115           0  No hashtags  \n",
       "153268           0  No hashtags  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BUILD a df with just those tweets so we can look at them.\n",
    "\n",
    "temp_df = tweets_nonAfg[tweets_nonAfg[\"Flag\"] == 'yes'].copy()\n",
    "print(temp_df.shape)\n",
    "temp_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_subset = aa.subset_gen(temp_df, 20, seed=1080)\n",
    "\n",
    "# NOTE: This function starts with an input: to reset the index\n",
    "aa.labeler(temp_subset, col=\"ContentClean\", lab=\"ContentLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"kab\" tweets are not all ir/relevant: 11 / 20 checked (I stopped at that point because the trend was clear) were unrelated and so cannot be easily kicked out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the non-Afg rows for inclusion terms\n",
    "So, let's move on. Take a look at a subset of the df in the labeler and see what we see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dataframe and temp_subset_gen.csv of length 50 have been created\n",
      "To end the session, enter 'ESC'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n      32\n",
       "unk     9\n",
       "y       8\n",
       "Name: ContentLabel, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_subset = aa.subset_gen(tweets_nonAfg, 50, seed=1080)\n",
    "\n",
    "# NOTE: This function starts with an input: to reset the index\n",
    "aa.labeler(temp_subset, col=\"ContentClean\", lab=\"ContentLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 8 of 50 tweets checked were relevant. 32 were not. The last 9 were unclear/unknowable. \n",
    "\n",
    "Check the following terms for inclusion criteria:\n",
    "* \"airport\" -> 209 instances\n",
    "* \"interpreter\", \"interpreters\" -> 50 and 235 instances\n",
    "* \"evacuation\" -> 3,295 instances\n",
    "* \"allies\" -> 400 instances\n",
    "* \"parole\" -> 1,502 instances\n",
    "* \"SIV\" (\"special immigrant visa\") -> 1,724\n",
    "\n",
    "Many tweets had to do with Iraqi asylum seekers / refugees. This is an easy delete from the main df.\n",
    "\n",
    "But the rest were very scattered with only a few on the same topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('siv', 1724)\n"
     ]
    }
   ],
   "source": [
    "print(aa.term_check(\"SIV\", tweets_nonAfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET ONLY\n",
    "tweets_nonAfg[\"Flag\"] = \"\"\n",
    "tweets_nonAfg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 60000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Flag</th>\n",
       "      <th>n_CapLetters</th>\n",
       "      <th>CapsRatio</th>\n",
       "      <th>AllCapWords</th>\n",
       "      <th>https</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Location</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156508</th>\n",
       "      <td>2021-01-01 02:55:56+00:00</td>\n",
       "      <td>Gee's Bend was a part of Federal Government's ...</td>\n",
       "      <td>Gee's Bend was a part of Federal Government's ...</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/caOdAb9xOq, https://t.co/UJfSC4S59p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156509</th>\n",
       "      <td>2021-01-01 01:55:12+00:00</td>\n",
       "      <td>@StayFierce1973 @Lala43463561 @Raufmustafaye10...</td>\n",
       "      <td>it is not we who prove this, but the R...</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@StayFierce1973, @Lala43463561, @Raufmustafaye...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156510</th>\n",
       "      <td>2021-01-01 01:07:04+00:00</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>UN\"</td>\n",
       "      <td>https://t.co/UzF1CVFfgV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156511</th>\n",
       "      <td>2021-01-01 00:43:07+00:00</td>\n",
       "      <td>@joemcafield Yep, just spent 40 mins (and coun...</td>\n",
       "      <td>Yep, just spent 40 mins (and counting) tryin...</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@joemcafield</td>\n",
       "      <td>Wakefield, England</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156512</th>\n",
       "      <td>2021-01-01 00:10:26+00:00</td>\n",
       "      <td>@StayFierce1973 @Raufmustafaye10 @alliemark5 @...</td>\n",
       "      <td>excuse me?  how do you explain the doc...</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/9NvC8mkf6r</td>\n",
       "      <td>@StayFierce1973, @Raufmustafaye10, @alliemark5...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date  \\\n",
       "156508  2021-01-01 02:55:56+00:00   \n",
       "156509  2021-01-01 01:55:12+00:00   \n",
       "156510  2021-01-01 01:07:04+00:00   \n",
       "156511  2021-01-01 00:43:07+00:00   \n",
       "156512  2021-01-01 00:10:26+00:00   \n",
       "\n",
       "                                                  Content  \\\n",
       "156508  Gee's Bend was a part of Federal Government's ...   \n",
       "156509  @StayFierce1973 @Lala43463561 @Raufmustafaye10...   \n",
       "156510  20201230: Bryony Lau: Canada now resettles mor...   \n",
       "156511  @joemcafield Yep, just spent 40 mins (and coun...   \n",
       "156512  @StayFierce1973 @Raufmustafaye10 @alliemark5 @...   \n",
       "\n",
       "                                             ContentClean Flag  n_CapLetters  \\\n",
       "156508  Gee's Bend was a part of Federal Government's ...                  9   \n",
       "156509          it is not we who prove this, but the R...                  3   \n",
       "156510  20201230: Bryony Lau: Canada now resettles mor...                  8   \n",
       "156511    Yep, just spent 40 mins (and counting) tryin...                  6   \n",
       "156512          excuse me?  how do you explain the doc...                  4   \n",
       "\n",
       "        CapsRatio  AllCapWords  \\\n",
       "156508   0.075630          NaN   \n",
       "156509   0.023438          NaN   \n",
       "156510   0.029412          UN\"   \n",
       "156511   0.056075  üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY   \n",
       "156512   0.022989          NaN   \n",
       "\n",
       "                                                   https  \\\n",
       "156508  https://t.co/caOdAb9xOq, https://t.co/UJfSC4S59p   \n",
       "156509                                               NaN   \n",
       "156510                           https://t.co/UzF1CVFfgV   \n",
       "156511                                               NaN   \n",
       "156512                           https://t.co/9NvC8mkf6r   \n",
       "\n",
       "                                                 Mentions            Location  \\\n",
       "156508                                                NaN             Alabama   \n",
       "156509  @StayFierce1973, @Lala43463561, @Raufmustafaye...      Toronto - Baku   \n",
       "156510                                                NaN             Toronto   \n",
       "156511                                       @joemcafield  Wakefield, England   \n",
       "156512  @StayFierce1973, @Raufmustafaye10, @alliemark5...      Toronto - Baku   \n",
       "\n",
       "        ReplyCount  RetweetCount  LikeCount  QuoteCount     Hashtags  \n",
       "156508           0             1          1           0  No hashtags  \n",
       "156509           0             0          1           0  No hashtags  \n",
       "156510           0             0          0           0  No hashtags  \n",
       "156511           1             0          0           0  No hashtags  \n",
       "156512           1             0          0           0  No hashtags  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.flag_term(\"airport\", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\"interpreter\", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\"translator\", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\"allies\", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\" siv \", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\" sivs \", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\" siv's \", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\"special immigrant visa\", tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "tweets_nonAfg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       153009\n",
       "yes      3504\n",
       "Name: Flag, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_nonAfg.Flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3504, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Flag</th>\n",
       "      <th>n_CapLetters</th>\n",
       "      <th>CapsRatio</th>\n",
       "      <th>AllCapWords</th>\n",
       "      <th>https</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Location</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153515</th>\n",
       "      <td>2021-01-12 03:38:44+00:00</td>\n",
       "      <td>Chinese-owned firm Siem Reap-Angkor Internatio...</td>\n",
       "      <td>Chinese-owned firm Siem Reap-Angkor Internatio...</td>\n",
       "      <td>yes</td>\n",
       "      <td>12</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/nUx1Qx4INi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English-speaking</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153956</th>\n",
       "      <td>2021-01-10 10:06:29+00:00</td>\n",
       "      <td>@dw2essex @Hammer_doc @butlerrichard2 @VeuveK ...</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>15</td>\n",
       "      <td>0.042980</td>\n",
       "      <td>NOT, REAL</td>\n",
       "      <td>https://t.co/10C8Z1HptJ</td>\n",
       "      <td>@dw2essex, @Hammer_doc, @butlerrichard2, @Veuv...</td>\n",
       "      <td>North West, England</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154902</th>\n",
       "      <td>2021-01-07 08:12:08+00:00</td>\n",
       "      <td>This mrg 7/01, the #Mai Mai &amp;amp; Allies attac...</td>\n",
       "      <td>This mrg 7/01, the #Mai Mai &amp;amp; Allies attac...</td>\n",
       "      <td>yes</td>\n",
       "      <td>14</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>#FARDC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@fatshi13, @MonuscoS, @RFIAfrique.</td>\n",
       "      <td>Kinshasa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>['Mai', 'Kangwe', 'Kamombo', 'FARDC']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155217</th>\n",
       "      <td>2021-01-06 00:54:56+00:00</td>\n",
       "      <td>@jypersian @evanishistory There was pressure o...</td>\n",
       "      <td>There was pressure on all participating Al...</td>\n",
       "      <td>yes</td>\n",
       "      <td>7</td>\n",
       "      <td>0.025830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jypersian, @evanishistory, @AdamSeipp</td>\n",
       "      <td>Melbourne, Victoria</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155899</th>\n",
       "      <td>2021-01-03 18:05:31+00:00</td>\n",
       "      <td>@ScottEshom @n1leftbehind @michaelgwaltz An in...</td>\n",
       "      <td>An interpreter shouldn't have to have th...</td>\n",
       "      <td>yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022472</td>\n",
       "      <td>SIV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@ScottEshom, @n1leftbehind, @michaelgwaltz</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date  \\\n",
       "153515  2021-01-12 03:38:44+00:00   \n",
       "153956  2021-01-10 10:06:29+00:00   \n",
       "154902  2021-01-07 08:12:08+00:00   \n",
       "155217  2021-01-06 00:54:56+00:00   \n",
       "155899  2021-01-03 18:05:31+00:00   \n",
       "\n",
       "                                                  Content  \\\n",
       "153515  Chinese-owned firm Siem Reap-Angkor Internatio...   \n",
       "153956  @dw2essex @Hammer_doc @butlerrichard2 @VeuveK ...   \n",
       "154902  This mrg 7/01, the #Mai Mai &amp; Allies attac...   \n",
       "155217  @jypersian @evanishistory There was pressure o...   \n",
       "155899  @ScottEshom @n1leftbehind @michaelgwaltz An in...   \n",
       "\n",
       "                                             ContentClean Flag  n_CapLetters  \\\n",
       "153515  Chinese-owned firm Siem Reap-Angkor Internatio...  yes            12   \n",
       "153956                                                ...  yes            15   \n",
       "154902  This mrg 7/01, the #Mai Mai &amp; Allies attac...  yes            14   \n",
       "155217      There was pressure on all participating Al...  yes             7   \n",
       "155899        An interpreter shouldn't have to have th...  yes             4   \n",
       "\n",
       "        CapsRatio AllCapWords                    https  \\\n",
       "153515   0.047059         NaN  https://t.co/nUx1Qx4INi   \n",
       "153956   0.042980   NOT, REAL  https://t.co/10C8Z1HptJ   \n",
       "154902   0.054902      #FARDC                      NaN   \n",
       "155217   0.025830         NaN                      NaN   \n",
       "155899   0.022472         SIV                      NaN   \n",
       "\n",
       "                                                 Mentions  \\\n",
       "153515                                                NaN   \n",
       "153956  @dw2essex, @Hammer_doc, @butlerrichard2, @Veuv...   \n",
       "154902                 @fatshi13, @MonuscoS, @RFIAfrique.   \n",
       "155217             @jypersian, @evanishistory, @AdamSeipp   \n",
       "155899         @ScottEshom, @n1leftbehind, @michaelgwaltz   \n",
       "\n",
       "                   Location  ReplyCount  RetweetCount  LikeCount  QuoteCount  \\\n",
       "153515     English-speaking           0             1          1           0   \n",
       "153956  North West, England           1             0          0           0   \n",
       "154902             Kinshasa           0             0          3           0   \n",
       "155217  Melbourne, Victoria           1             0          1           0   \n",
       "155899           Dallas, TX           0             0          1           0   \n",
       "\n",
       "                                     Hashtags  \n",
       "153515                            No hashtags  \n",
       "153956                            No hashtags  \n",
       "154902  ['Mai', 'Kangwe', 'Kamombo', 'FARDC']  \n",
       "155217                            No hashtags  \n",
       "155899                            No hashtags  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_flags = tweets_nonAfg[tweets_nonAfg[\"Flag\"] == 'yes'].copy()\n",
    "print(new_flags.shape)\n",
    "new_flags.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dataframe and temp_subset_gen.csv of length 50 have been created\n",
      "To end the session, enter 'ESC'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y                40\n",
       "n - airport       3\n",
       "n                 2\n",
       "n - ?             2\n",
       "n - translate     1\n",
       "n - allies        1\n",
       "unk               1\n",
       "Name: ContentLabel, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_subset = aa.subset_gen(new_flags, 50, seed=1080)\n",
    "\n",
    "# NOTE: This function starts with an input: to reset the index\n",
    "aa.labeler(temp_subset, col=\"ContentClean\", lab=\"ContentLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this had mixed results. For 50 tweets and terms (\"airport\", \"interpreter\", \"evacuation\", \"allies\", \"humanitarian parole\", \" siv \", \"special immigrant visa\"):\n",
    "\n",
    "y                 20 <br>\n",
    "n - evac          11 <br>\n",
    "unk               11 <br>\n",
    "n - hum parole     5 <br>\n",
    "n - airport        2 <br>\n",
    "n - ?              1 <br>\n",
    "\n",
    "So, \"evacuation\" and \"humanitarian parole\" or not good safewords. The rest seem ok.\n",
    "\n",
    "Try this again with a few different terms (\"airport\", \"interpreter\", \"translator\", \"allies\", \" siv \", \" sivs \", \" siv's \", \"special immigrant visa\"):\n",
    "\n",
    "y                40 <br>\n",
    "n - airport       3<br>\n",
    "n                 2<br>\n",
    "n - ?             2<br>\n",
    "n - translate     1<br>\n",
    "n - allies        1<br>\n",
    "unk               1<br>\n",
    "\n",
    "That's better, but not great. The variations on \"SIV\" work well. But I think I can take airport out. Also, maybe better to delete some rows first... But all this is over only 3,504 rows. Which hardly makes a dent.\n",
    "\n",
    "Try excluding first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excluding rows\n",
    "## First round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_nonAfg.Flag = \"no\"\n",
    "#tweets_nonAfg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     156508\n",
      "yes         5\n",
      "Name: Flag, dtype: int64\n",
      "no     156504\n",
      "yes         9\n",
      "Name: Flag, dtype: int64\n",
      "no     156503\n",
      "yes        10\n",
      "Name: Flag, dtype: int64\n",
      "no     156500\n",
      "yes        13\n",
      "Name: Flag, dtype: int64\n",
      "no     155985\n",
      "yes       528\n",
      "Name: Flag, dtype: int64\n",
      "no     154208\n",
      "yes      2305\n",
      "Name: Flag, dtype: int64\n",
      "no     153361\n",
      "yes      3152\n",
      "Name: Flag, dtype: int64\n",
      "no     153021\n",
      "yes      3492\n",
      "Name: Flag, dtype: int64\n",
      "no     151906\n",
      "yes      4607\n",
      "Name: Flag, dtype: int64\n",
      "no     151683\n",
      "yes      4830\n",
      "Name: Flag, dtype: int64\n",
      "no     151683\n",
      "yes      4830\n",
      "Name: Flag, dtype: int64\n",
      "no     151511\n",
      "yes      5002\n",
      "Name: Flag, dtype: int64\n",
      "no     151273\n",
      "yes      5240\n",
      "Name: Flag, dtype: int64\n",
      "no     151151\n",
      "yes      5362\n",
      "Name: Flag, dtype: int64\n",
      "no     151151\n",
      "yes      5362\n",
      "Name: Flag, dtype: int64\n",
      "no     151151\n",
      "yes      5362\n",
      "Name: Flag, dtype: int64\n",
      "no     150505\n",
      "yes      6008\n",
      "Name: Flag, dtype: int64\n",
      "no     150505\n",
      "yes      6008\n",
      "Name: Flag, dtype: int64\n",
      "no     147518\n",
      "yes      8995\n",
      "Name: Flag, dtype: int64\n",
      "no     146990\n",
      "yes      9523\n",
      "Name: Flag, dtype: int64\n",
      "no     146990\n",
      "yes      9523\n",
      "Name: Flag, dtype: int64\n",
      "no     146461\n",
      "yes     10052\n",
      "Name: Flag, dtype: int64\n",
      "no     146461\n",
      "yes     10052\n",
      "Name: Flag, dtype: int64\n",
      "no     146461\n",
      "yes     10052\n",
      "Name: Flag, dtype: int64\n",
      "no     146461\n",
      "yes     10052\n",
      "Name: Flag, dtype: int64\n",
      "no     145922\n",
      "yes     10591\n",
      "Name: Flag, dtype: int64\n",
      "no     119183\n",
      "yes     37330\n",
      "Name: Flag, dtype: int64\n",
      "no     119183\n",
      "yes     37330\n",
      "Name: Flag, dtype: int64\n",
      "no     118898\n",
      "yes     37615\n",
      "Name: Flag, dtype: int64\n",
      "no     118898\n",
      "yes     37615\n",
      "Name: Flag, dtype: int64\n",
      "no     117353\n",
      "yes     39160\n",
      "Name: Flag, dtype: int64\n",
      "no     117353\n",
      "yes     39160\n",
      "Name: Flag, dtype: int64\n",
      "no     116966\n",
      "yes     39547\n",
      "Name: Flag, dtype: int64\n",
      "no     116966\n",
      "yes     39547\n",
      "Name: Flag, dtype: int64\n",
      "no     114068\n",
      "yes     42445\n",
      "Name: Flag, dtype: int64\n",
      "no     114068\n",
      "yes     42445\n",
      "Name: Flag, dtype: int64\n",
      "no     113592\n",
      "yes     42921\n",
      "Name: Flag, dtype: int64\n",
      "no     112697\n",
      "yes     43816\n",
      "Name: Flag, dtype: int64\n",
      "no     112069\n",
      "yes     44444\n",
      "Name: Flag, dtype: int64\n",
      "no     112069\n",
      "yes     44444\n",
      "Name: Flag, dtype: int64\n",
      "no     112065\n",
      "yes     44448\n",
      "Name: Flag, dtype: int64\n",
      "no     112062\n",
      "yes     44451\n",
      "Name: Flag, dtype: int64\n",
      "no     109481\n",
      "yes     47032\n",
      "Name: Flag, dtype: int64\n",
      "no     106285\n",
      "yes     50228\n",
      "Name: Flag, dtype: int64\n",
      "no     106190\n",
      "yes     50323\n",
      "Name: Flag, dtype: int64\n",
      "no     105993\n",
      "yes     50520\n",
      "Name: Flag, dtype: int64\n",
      "no     105923\n",
      "yes     50590\n",
      "Name: Flag, dtype: int64\n",
      "no     105848\n",
      "yes     50665\n",
      "Name: Flag, dtype: int64\n",
      "no     105848\n",
      "yes     50665\n",
      "Name: Flag, dtype: int64\n",
      "no     105834\n",
      "yes     50679\n",
      "Name: Flag, dtype: int64\n",
      "no     105485\n",
      "yes     51028\n",
      "Name: Flag, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Flag</th>\n",
       "      <th>n_CapLetters</th>\n",
       "      <th>CapsRatio</th>\n",
       "      <th>AllCapWords</th>\n",
       "      <th>https</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Location</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156508</th>\n",
       "      <td>2021-01-01 02:55:56+00:00</td>\n",
       "      <td>Gee's Bend was a part of Federal Government's ...</td>\n",
       "      <td>Gee's Bend was a part of Federal Government's ...</td>\n",
       "      <td>no</td>\n",
       "      <td>9</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/caOdAb9xOq, https://t.co/UJfSC4S59p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156509</th>\n",
       "      <td>2021-01-01 01:55:12+00:00</td>\n",
       "      <td>@StayFierce1973 @Lala43463561 @Raufmustafaye10...</td>\n",
       "      <td>it is not we who prove this, but the R...</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@StayFierce1973, @Lala43463561, @Raufmustafaye...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156510</th>\n",
       "      <td>2021-01-01 01:07:04+00:00</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>20201230: Bryony Lau: Canada now resettles mor...</td>\n",
       "      <td>no</td>\n",
       "      <td>8</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>UN\"</td>\n",
       "      <td>https://t.co/UzF1CVFfgV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156511</th>\n",
       "      <td>2021-01-01 00:43:07+00:00</td>\n",
       "      <td>@joemcafield Yep, just spent 40 mins (and coun...</td>\n",
       "      <td>Yep, just spent 40 mins (and counting) tryin...</td>\n",
       "      <td>no</td>\n",
       "      <td>6</td>\n",
       "      <td>0.056075</td>\n",
       "      <td>üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@joemcafield</td>\n",
       "      <td>Wakefield, England</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156512</th>\n",
       "      <td>2021-01-01 00:10:26+00:00</td>\n",
       "      <td>@StayFierce1973 @Raufmustafaye10 @alliemark5 @...</td>\n",
       "      <td>excuse me?  how do you explain the doc...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/9NvC8mkf6r</td>\n",
       "      <td>@StayFierce1973, @Raufmustafaye10, @alliemark5...</td>\n",
       "      <td>Toronto - Baku</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Date  \\\n",
       "156508  2021-01-01 02:55:56+00:00   \n",
       "156509  2021-01-01 01:55:12+00:00   \n",
       "156510  2021-01-01 01:07:04+00:00   \n",
       "156511  2021-01-01 00:43:07+00:00   \n",
       "156512  2021-01-01 00:10:26+00:00   \n",
       "\n",
       "                                                  Content  \\\n",
       "156508  Gee's Bend was a part of Federal Government's ...   \n",
       "156509  @StayFierce1973 @Lala43463561 @Raufmustafaye10...   \n",
       "156510  20201230: Bryony Lau: Canada now resettles mor...   \n",
       "156511  @joemcafield Yep, just spent 40 mins (and coun...   \n",
       "156512  @StayFierce1973 @Raufmustafaye10 @alliemark5 @...   \n",
       "\n",
       "                                             ContentClean Flag  n_CapLetters  \\\n",
       "156508  Gee's Bend was a part of Federal Government's ...   no             9   \n",
       "156509          it is not we who prove this, but the R...   no             3   \n",
       "156510  20201230: Bryony Lau: Canada now resettles mor...   no             8   \n",
       "156511    Yep, just spent 40 mins (and counting) tryin...   no             6   \n",
       "156512          excuse me?  how do you explain the doc...   no             4   \n",
       "\n",
       "        CapsRatio  AllCapWords  \\\n",
       "156508   0.075630          NaN   \n",
       "156509   0.023438          NaN   \n",
       "156510   0.029412          UN\"   \n",
       "156511   0.056075  üôÑü§¶‚Äç‚ôÄÔ∏èüòÅ\\nHNY   \n",
       "156512   0.022989          NaN   \n",
       "\n",
       "                                                   https  \\\n",
       "156508  https://t.co/caOdAb9xOq, https://t.co/UJfSC4S59p   \n",
       "156509                                               NaN   \n",
       "156510                           https://t.co/UzF1CVFfgV   \n",
       "156511                                               NaN   \n",
       "156512                           https://t.co/9NvC8mkf6r   \n",
       "\n",
       "                                                 Mentions            Location  \\\n",
       "156508                                                NaN             Alabama   \n",
       "156509  @StayFierce1973, @Lala43463561, @Raufmustafaye...      Toronto - Baku   \n",
       "156510                                                NaN             Toronto   \n",
       "156511                                       @joemcafield  Wakefield, England   \n",
       "156512  @StayFierce1973, @Raufmustafaye10, @alliemark5...      Toronto - Baku   \n",
       "\n",
       "        ReplyCount  RetweetCount  LikeCount  QuoteCount     Hashtags  \n",
       "156508           0             1          1           0  No hashtags  \n",
       "156509           0             0          1           0  No hashtags  \n",
       "156510           0             0          0           0  No hashtags  \n",
       "156511           1             0          0           0  No hashtags  \n",
       "156512           1             0          0           0  No hashtags  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excluded = [\"arkham\", \"gotham\", \"batman\", \"rohinga\", \"rohingya\",\n",
    "    \"syrian\", \"syria\", \"tamil\", \"tigray\", \"sudan\", \"sudanese\", \"somalia\", \"somali\",\n",
    "    \"congo\", \"congalese\", \"congolese\", \"eritrea\", \"eritrean\", \"apo\", \"nigeria\", \"nigerian\",\n",
    "    \"uganda\", \"ugandan\", \"rwamwanja\", \"kirwa\", \"biloela\", \"iraq\", \"iraqi\",\n",
    "    \"yemen\", \"yemeni\", \"rwanda\", \"rwandan\", \"kenya\", \"kenyan\", \"kashmir\", \"kashmiri\",\n",
    "    \"palestine\", \"palestinian\", \"haiti\", \"haitian\", \"tesla\", \"TSLA\", \"ukraine\", \"ukrainian\",\n",
    "    \"your patience\", \"your continued patience\", \"rental\", \"tenant\", \"tenants\", \"buddhist\", \"hindu\"]\n",
    "\n",
    "for term in excluded:\n",
    "    aa.flag_term(term, tweets_nonAfg, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False, verby=False)\n",
    "\n",
    "tweets_nonAfg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105485, 15)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep just the rows that have not been flagged\n",
    "tweets_nonAfg_excl = tweets_nonAfg[tweets_nonAfg[\"Flag\"] == 'no'].copy()\n",
    "tweets_nonAfg_excl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dataframe and temp_subset_gen.csv of length 25 have been created\n",
      "To end the session, enter 'ESC'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "unk    17\n",
       "n       5\n",
       "y       3\n",
       "Name: ContentLabel, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peek = aa.subset_gen(tweets_nonAfg_excl, 25)\n",
    "aa.labeler(peek)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overwhelmingly unknowable, but probably relevant. Other than that, split between relevant and not relevant for this project. This is discouraging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check a few more terms\n",
    "Given the reduced list, now check a few more terms:\n",
    "\n",
    "\"Australia\"\n",
    "\"vietnam\", \"vietnamese\",\n",
    "\"cambodia\", \"cambodian\",\n",
    "\"indonesia\", \"indonesian\",\n",
    "\"fire\", \"flood\", \"landslide\", \"cyclone\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET ONLY\n",
    "tweets_nonAfg_excl[\"Flag\"] = \"no\"\n",
    "#tweets_nonAfg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     105371\n",
      "yes       114\n",
      "Name: Flag, dtype: int64\n",
      "(114, 15)\n"
     ]
    }
   ],
   "source": [
    "tweets_nonAfg_excl[\"Flag\"] = \"no\"\n",
    "aa.flag_term(\"landslide\", tweets_nonAfg_excl, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "\n",
    "new_flags = tweets_nonAfg_excl[tweets_nonAfg_excl[\"Flag\"] == 'yes'].copy()\n",
    "print(new_flags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dataframe and temp_subset_gen.csv of length 25 have been created\n",
      "To end the session, enter 'ESC'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n     24\n",
       "nn     1\n",
       "Name: ContentLabel, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_subset = aa.subset_gen(new_flags, 25, seed=1080)\n",
    "\n",
    "# NOTE: This function starts with an input: to reset the index\n",
    "aa.labeler(temp_subset, col=\"ContentClean\", lab=\"ContentLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude: \"Australia\", \"vietnam\", \"cambodia\", \"indonesia\", \"fire\", \"flood\", \"landslide\", \"cyclone\"\n",
    "\n",
    "\"Australia\": most (18 / 25) are unknowable, but I am failrly confident that these are about detained people from Nauru and PNG. In fact, add those to the exclude list. The rest were excludable. \n",
    "\n",
    "\"vietnam\", \"vietnamese\": most of these rows talk just about the resettlement of Vietnamese after the war; I'm pretty certain that the context of the postings has to do with the situation in Afgh, but that is not provable given my methodology. So, unfortunately, these rows will be excluded.\n",
    "\n",
    "\"cambodia\", \"cambodian\": mostly about either war refugees from 60s/70s or the Australia/Cambodia refugee resettlment deals today. Can be ommitted.\n",
    "\n",
    "\"indonesia\", \"indonesian\": This is mainly pleas by refugees currently detained in Indonesia (or refugee groups) asking to be resetteled elsewhere.\n",
    "<br> -> found: Hazara: a Persian-speaking ethnic group native to, and primarily residing in the Hazarajat region in central Afghanistan and generally scattered throughout Afghanistan.\n",
    "\n",
    "\"fire\", \"flood\", \"landslide\", \"cyclone\": although very occasionally these are used to refer to political events, they are overwhelmingly referring to natural disasters. Can be removed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     102042\n",
      "yes      3443\n",
      "Name: Flag, dtype: int64\n",
      "no     101515\n",
      "yes      3970\n",
      "Name: Flag, dtype: int64\n",
      "no     101426\n",
      "yes      4059\n",
      "Name: Flag, dtype: int64\n",
      "no     96004\n",
      "yes     9481\n",
      "Name: Flag, dtype: int64\n",
      "no     95504\n",
      "yes     9981\n",
      "Name: Flag, dtype: int64\n",
      "no     95029\n",
      "yes    10456\n",
      "Name: Flag, dtype: int64\n",
      "no     94926\n",
      "yes    10559\n",
      "Name: Flag, dtype: int64\n",
      "no     94875\n",
      "yes    10610\n",
      "Name: Flag, dtype: int64\n",
      "(105485, 15)\n"
     ]
    }
   ],
   "source": [
    "flag_list = [\"australia\", \"vietnam\", \"cambodia\", \"indonesia\", \"fire\", \"flood\", \"landslide\", \"cyclone\"]\n",
    "\n",
    "tweets_nonAfg_excl[\"Flag\"] = \"no\"\n",
    "\n",
    "for term in flag_list:\n",
    "    # NOTE: resets the index\n",
    "    aa.flag_term(term, tweets_nonAfg_excl, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "\n",
    "print(tweets_nonAfg_excl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(94875, 15)\n"
     ]
    }
   ],
   "source": [
    "tweets_nonAfg_excl = tweets_nonAfg_excl[tweets_nonAfg_excl[\"Flag\"] == 'no'].copy()\n",
    "print(tweets_nonAfg_excl.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a subset and see how representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dataframe and temp_subset_gen.csv of length 25 have been created\n",
      "To end the session, enter 'ESC'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n      12\n",
       "unk     9\n",
       "y       4\n",
       "Name: ContentLabel, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_subset = aa.subset_gen(tweets_nonAfg_excl, 25, seed=1080)\n",
    "\n",
    "# NOTE: This function starts with an input: to reset the index\n",
    "aa.labeler(temp_subset, col=\"ContentClean\", lab=\"ContentLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half are not relevant; most of the rest are unknowable. So this is pretty... dunno.\n",
    "\n",
    "Let's try muslim, arab, islam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     94019\n",
      "yes      856\n",
      "Name: Flag, dtype: int64\n",
      "no     93365\n",
      "yes     1510\n",
      "Name: Flag, dtype: int64\n",
      "no     93154\n",
      "yes     1721\n",
      "Name: Flag, dtype: int64\n",
      "(1721, 15)\n",
      "no     1716\n",
      "yes       5\n",
      "Name: Flag, dtype: int64\n",
      "no     1715\n",
      "yes       6\n",
      "Name: Flag, dtype: int64\n",
      "no     1715\n",
      "yes       6\n",
      "Name: Flag, dtype: int64\n",
      "(1715, 15)\n"
     ]
    }
   ],
   "source": [
    "tweets_nonAfg_excl[\"Flag\"] = \"no\"\n",
    "aa.flag_term(\"muslim\", tweets_nonAfg_excl, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\"arab\", tweets_nonAfg_excl, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "aa.flag_term(\"islam\", tweets_nonAfg_excl, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "\n",
    "new_flags = tweets_nonAfg_excl[tweets_nonAfg_excl[\"Flag\"] == 'yes'].copy()\n",
    "print(new_flags.shape)\n",
    "\n",
    "new_flags[\"Flag\"] = \"no\"\n",
    "aa.flag_term(\" siv \", new_flags, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\" sivs \", new_flags, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "aa.flag_term(\" siv's \", new_flags, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "\n",
    "new_flags = new_flags[new_flags[\"Flag\"] == 'no'].copy()\n",
    "print(new_flags.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dataframe and temp_subset_gen.csv of length 25 have been created\n",
      "To end the session, enter 'ESC'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n      16\n",
       "y       6\n",
       "unk     3\n",
       "Name: ContentLabel, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_subset = aa.subset_gen(new_flags, 25, seed=1080)\n",
    "\n",
    "# NOTE: This function starts with an input: to reset the index\n",
    "aa.labeler(temp_subset, col=\"ContentClean\", lab=\"ContentLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No good. Mostly about Armenia, Azerbijan, China. \n",
    "\n",
    "Let's take one last look at interpreter and translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     94533\n",
      "yes      342\n",
      "Name: Flag, dtype: int64\n",
      "no     94032\n",
      "yes      843\n",
      "Name: Flag, dtype: int64\n",
      "(843, 15)\n",
      "no     778\n",
      "yes     65\n",
      "Name: Flag, dtype: int64\n",
      "no     770\n",
      "yes     73\n",
      "Name: Flag, dtype: int64\n",
      "no     770\n",
      "yes     73\n",
      "Name: Flag, dtype: int64\n",
      "(770, 15)\n"
     ]
    }
   ],
   "source": [
    "tweets_nonAfg_excl[\"Flag\"] = \"no\"\n",
    "aa.flag_term(\"interpreter\", tweets_nonAfg_excl, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\"translator\", tweets_nonAfg_excl, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "\n",
    "new_flags = tweets_nonAfg_excl[tweets_nonAfg_excl[\"Flag\"] == 'yes'].copy()\n",
    "print(new_flags.shape)\n",
    "\n",
    "new_flags[\"Flag\"] = \"no\"\n",
    "aa.flag_term(\" siv \", new_flags, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\" sivs \", new_flags, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "aa.flag_term(\" siv's \", new_flags, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "\n",
    "new_flags = new_flags[new_flags[\"Flag\"] == 'no'].copy()\n",
    "print(new_flags.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dataframe and temp_subset_gen.csv of length 25 have been created\n",
      "To end the session, enter 'ESC'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y      21\n",
       "unk     3\n",
       "n       1\n",
       "Name: ContentLabel, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_subset = aa.subset_gen(new_flags, 25, seed=1080)\n",
    "\n",
    "# NOTE: This function starts with an input: to reset the index\n",
    "aa.labeler(temp_subset, col=\"ContentClean\", lab=\"ContentLabel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no     94293\n",
      "yes      582\n",
      "Name: Flag, dtype: int64\n",
      "(582, 15)\n",
      "no     436\n",
      "yes    146\n",
      "Name: Flag, dtype: int64\n",
      "no     433\n",
      "yes    149\n",
      "Name: Flag, dtype: int64\n",
      "no     432\n",
      "yes    150\n",
      "Name: Flag, dtype: int64\n",
      "(432, 15)\n"
     ]
    }
   ],
   "source": [
    "tweets_nonAfg_excl[\"Flag\"] = \"no\"\n",
    "aa.flag_term(\"allies\", tweets_nonAfg_excl, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "\n",
    "new_flags = tweets_nonAfg_excl[tweets_nonAfg_excl[\"Flag\"] == 'yes'].copy()\n",
    "print(new_flags.shape)\n",
    "\n",
    "new_flags[\"Flag\"] = \"no\"\n",
    "aa.flag_term(\" siv \", new_flags, clean_col=\"ContentClean\", flag_col=\"Flag\")\n",
    "aa.flag_term(\" sivs \", new_flags, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "aa.flag_term(\" siv's \", new_flags, clean_col=\"ContentClean\", flag_col=\"Flag\", indx_warning=False)\n",
    "\n",
    "new_flags = new_flags[new_flags[\"Flag\"] == 'no'].copy()\n",
    "print(new_flags.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dataframe and temp_subset_gen.csv of length 25 have been created\n",
      "To end the session, enter 'ESC'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "y     16\n",
       "n      7\n",
       "yb     2\n",
       "Name: ContentLabel, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_subset = aa.subset_gen(new_flags, 25, seed=1080)\n",
    "\n",
    "# NOTE: This function starts with an input: to reset the index\n",
    "aa.labeler(temp_subset, col=\"ContentClean\", lab=\"ContentLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, the relevance of the resulting dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Translator\" and \"interpreter\" look usable.\n",
    "\n",
    "\"Allies\" is marginal.\n",
    "\n",
    "# Summary\n",
    "This could go on forever. I could look for more exclusion terms (\"israel\") or more secondary inclusion terms (\"humanitarian parole\"). I could look for tweets that have 2+ of a wider set of inclusion terms. But all of this is just fighting for a rough handful of rows. I have a sufficient dataset that I am confident consists of mostly relevant rows. There does not appear to be any bias in the rows that are relevant but cannot be systematically included. \n",
    "\n",
    "Good enough."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d5a672f32d72b7000e11999081d09a97571b10f2df9aaee5f232791dc820369"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
