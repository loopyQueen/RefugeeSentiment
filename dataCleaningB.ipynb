{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) <2022>, <Regina Nockerts>\n",
    "All rights reserved.\n",
    "\n",
    "This source code is licensed under the BSD-style license found in the\n",
    "LICENSE file in the root directory of this source tree. \n",
    "\n",
    "Sources:\n",
    "- https://skimai.com/fine-tuning-bert-for-sentiment-analysis/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from nlpUtils import aardvark as aa \n",
    "import emoji  # https://pypi.org/project/emoji/\n",
    "\n",
    "#from numpy import random as rand\n",
    "# from sklearn.utils import resample\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "First load the data from csv that was created in the labelData notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_labeled_01b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_01b.csv\"), header=0, index_col=0)\n",
    "data_labeled_02b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_02b.csv\"), header=0, index_col=0)\n",
    "data_labeled_03b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_03b.csv\"), header=0, index_col=0)\n",
    "data_labeled_04b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_04b.csv\"), header=0, index_col=0)\n",
    "data_labeled_05b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_05b.csv\"), header=0, index_col=0)\n",
    "data_labeled_06b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_06b.csv\"), header=0, index_col=0)\n",
    "data_labeled_07b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_07b.csv\"), header=0, index_col=0)\n",
    "data_labeled_08b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_08b.csv\"), header=0, index_col=0)\n",
    "data_labeled_09b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_09b.csv\"), header=0, index_col=0)\n",
    "data_labeled_10b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_10b.csv\"), header=0, index_col=0)\n",
    "data_labeled_11b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_11b.csv\"), header=0, index_col=0)\n",
    "data_labeled_12b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_12b.csv\"), header=0, index_col=0)\n",
    "data_labeled_13b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_13b.csv\"), header=0, index_col=0)\n",
    "data_labeled_14b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_14b.csv\"), header=0, index_col=0)\n",
    "data_labeled_15b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_15b.csv\"), header=0, index_col=0)\n",
    "data_labeled_16b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_16b.csv\"), header=0, index_col=0)\n",
    "data_labeled_17b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_17b.csv\"), header=0, index_col=0)\n",
    "data_labeled_18b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_18b.csv\"), header=0, index_col=0)\n",
    "data_labeled_19b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_19b.csv\"), header=0, index_col=0)\n",
    "data_labeled_20b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_20b.csv\"), header=0, index_col=0)\n",
    "data_labeled_21b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_21b.csv\"), header=0, index_col=0)\n",
    "data_labeled_22b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_22b.csv\"), header=0, index_col=0)\n",
    "data_labeled_23b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_23b.csv\"), header=0, index_col=0)\n",
    "data_labeled_24b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_24b.csv\"), header=0, index_col=0)\n",
    "data_labeled_25b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_25b.csv\"), header=0, index_col=0)\n",
    "data_labeled_26b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_26b.csv\"), header=0, index_col=0)\n",
    "data_labeled_27b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_27b.csv\"), header=0, index_col=0)\n",
    "data_labeled_28b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_28b.csv\"), header=0, index_col=0)\n",
    "data_labeled_29b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_29b.csv\"), header=0, index_col=0)\n",
    "data_labeled_30b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_30b.csv\"), header=0, index_col=0)\n",
    "data_labeled_31b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_31b.csv\"), header=0, index_col=0)\n",
    "data_labeled_32b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_32b.csv\"), header=0, index_col=0)\n",
    "data_labeled_33b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_33b.csv\"), header=0, index_col=0)\n",
    "data_labeled_34b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_34b.csv\"), header=0, index_col=0)\n",
    "data_labeled_35b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_35b.csv\"), header=0, index_col=0)\n",
    "data_labeled_36b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_36b.csv\"), header=0, index_col=0)\n",
    "data_labeled_37b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_37b.csv\"), header=0, index_col=0)\n",
    "data_labeled_38b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_38b.csv\"), header=0, index_col=0)\n",
    "data_labeled_39b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_39b.csv\"), header=0, index_col=0)\n",
    "data_labeled_40b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_40b.csv\"), header=0, index_col=0)\n",
    "data_labeled_41b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_41b.csv\"), header=0, index_col=0)\n",
    "data_labeled_42b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_42b.csv\"), header=0, index_col=0)\n",
    "data_labeled_43b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_43b.csv\"), header=0, index_col=0)\n",
    "data_labeled_44b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_44b.csv\"), header=0, index_col=0)\n",
    "data_labeled_45b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_45b.csv\"), header=0, index_col=0)\n",
    "data_labeled_46b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_46b.csv\"), header=0, index_col=0)\n",
    "data_labeled_47b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_47b.csv\"), header=0, index_col=0)\n",
    "data_labeled_48b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_48b.csv\"), header=0, index_col=0)\n",
    "data_labeled_49b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_49b.csv\"), header=0, index_col=0)\n",
    "data_labeled_50b = pd.read_csv(os.path.join('dataLabelSets', \"data_labeled_50b.csv\"), header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1211, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [data_labeled_01b, data_labeled_02b, data_labeled_03b, data_labeled_04b, data_labeled_05b, data_labeled_06b, data_labeled_07b, data_labeled_08b, data_labeled_09b, data_labeled_10b, data_labeled_11b, data_labeled_12b, data_labeled_13b, data_labeled_14b, data_labeled_15b, data_labeled_16b, data_labeled_17b, data_labeled_18b, data_labeled_19b, data_labeled_20b, data_labeled_21b, data_labeled_22b, data_labeled_23b, data_labeled_24b, data_labeled_25b, data_labeled_26b, data_labeled_27b, data_labeled_28b, data_labeled_29b, data_labeled_30b, data_labeled_31b, data_labeled_32b, data_labeled_33b, data_labeled_34b, data_labeled_35b, data_labeled_36b, data_labeled_37b, data_labeled_38b, data_labeled_39b, data_labeled_40b, data_labeled_41b, data_labeled_42b, data_labeled_43b, data_labeled_44b, data_labeled_45b, data_labeled_46b, data_labeled_47b, data_labeled_48b, data_labeled_49b, data_labeled_50b]\n",
    "tweets_clean= pd.concat(frames)\n",
    "tweets_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the unlabeled data. Sometimes will need to make parallel changes there, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200084, 16)\n"
     ]
    }
   ],
   "source": [
    "tweets_unlabeled = pd.read_csv(os.path.join('data', \"data_unlabeled2_05_09.csv\"), header=0, index_col=0)\n",
    "print(tweets_unlabeled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_stable', 'Date', 'Content', 'ContentClean', 'Labels', 'n_CapLetters', 'CapsRatio', 'AllCapWords', 'https', 'Mentions', 'Location', 'ReplyCount', 'RetweetCount', 'LikeCount', 'QuoteCount', 'Hashtags', 'Flag']\n",
      "['id_stable', 'Date', 'Content', 'ContentClean', 'n_CapLetters', 'CapsRatio', 'AllCapWords', 'https', 'Mentions', 'Location', 'ReplyCount', 'RetweetCount', 'LikeCount', 'QuoteCount', 'Hashtags', 'Flag']\n"
     ]
    }
   ],
   "source": [
    "print(list(tweets_clean.columns))\n",
    "print(list(tweets_unlabeled.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_cols = ['n_CapLetters', 'CapsRatio', 'AllCapWords', 'https', 'Mentions', 'Location', 'ReplyCount', 'RetweetCount', 'LikeCount', 'QuoteCount', 'Hashtags']\n",
    "tweets_clean.drop(bad_cols, axis=1, inplace=True)\n",
    "tweets_unlabeled.drop(bad_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id_stable', 'Date', 'Content', 'ContentClean', 'Labels', 'Flag']\n",
      "['id_stable', 'Date', 'Content', 'ContentClean', 'Flag']\n"
     ]
    }
   ],
   "source": [
    "print(list(tweets_clean.columns))\n",
    "print(list(tweets_unlabeled.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit more ContentClean cleaning\n",
    "We should have done this earlier, but... Let's remove \"&amp\" and trailing whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('&amp;', 119)\n",
      "('&amp;', 20950)\n"
     ]
    }
   ],
   "source": [
    "print(aa.term_check(\"&amp;\", df=tweets_clean, text_col=\"ContentClean\"))\n",
    "print(aa.term_check(\"&amp;\", df=tweets_unlabeled, text_col=\"ContentClean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.last_clean (tweets_clean, text_col=\"ContentClean\", indx_warning=False, verby=True)\n",
    "aa.last_clean (tweets_unlabeled, text_col=\"ContentClean\", indx_warning=False, verby=True)  # run twice\n",
    "#df.loc[i, clean_col] = re.sub(r'https:\\/\\/\\S+', r' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('&amp;', 0)\n",
      "('&amp;', 0)\n"
     ]
    }
   ],
   "source": [
    "print(aa.term_check(\"&amp;\", df=tweets_clean, text_col=\"ContentClean\"))\n",
    "print(aa.term_check(\"&amp;\", df=tweets_unlabeled, text_col=\"ContentClean\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeled Data\n",
    "## Get labels into a usable format\n",
    "Break the result from the labeler function into two separate columns: one for the sentiment label and one for the stance label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ySent, yStance = [], []\n",
    "\n",
    "for id_s, codes in zip(tweets_clean[\"id_stable\"], tweets_clean[\"Labels\"]):\n",
    "    if \"/\" not in codes:   #This section of the code is untested.\n",
    "        print(\"Error: missing code at id:\", id_s)\n",
    "        ySent.append(np.nan)\n",
    "        yStance.append(np.nan)\n",
    "        continue\n",
    "    a = codes.split(\"/\")\n",
    "    ySent.append(a[0].strip())\n",
    "    yStance.append(a[1].strip())\n",
    "\n",
    "tweets_clean.insert(loc=5, column=\"label_sent\", value=ySent)\n",
    "tweets_clean.insert(loc=6, column=\"label_stance\", value=yStance)\n",
    "\n",
    "# print(ySent)\n",
    "# print(yStance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Labels</th>\n",
       "      <th>label_sent</th>\n",
       "      <th>label_stance</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170314</td>\n",
       "      <td>2021-08-15 17:53:06+00:00</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>neutral / neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192623</td>\n",
       "      <td>2021-06-02 17:31:25+00:00</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>happy / na</td>\n",
       "      <td>happy</td>\n",
       "      <td>na</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106982</td>\n",
       "      <td>2021-08-28 07:53:12+00:00</td>\n",
       "      <td>@pfrpeppermint @CawthornforNC Not only did Tru...</td>\n",
       "      <td>Not only did Trump stop processing asylum &amp; re...</td>\n",
       "      <td>disgust / neutral</td>\n",
       "      <td>disgust</td>\n",
       "      <td>neutral</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31609</td>\n",
       "      <td>2021-12-23 18:00:41+00:00</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>plea - disgust / refugee - agree</td>\n",
       "      <td>plea - disgust</td>\n",
       "      <td>refugee - agree</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152666</td>\n",
       "      <td>2021-08-17 20:06:41+00:00</td>\n",
       "      <td>@RepHerrell One moment you hate refugees and t...</td>\n",
       "      <td>One moment you hate refugees and the next you ...</td>\n",
       "      <td>hopeful / agree</td>\n",
       "      <td>hopeful</td>\n",
       "      <td>agree</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_stable                       Date  \\\n",
       "0     170314  2021-08-15 17:53:06+00:00   \n",
       "1     192623  2021-06-02 17:31:25+00:00   \n",
       "2     106982  2021-08-28 07:53:12+00:00   \n",
       "3      31609  2021-12-23 18:00:41+00:00   \n",
       "4     152666  2021-08-17 20:06:41+00:00   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Per a White House official: Biden and Harris m...   \n",
       "1  Afghan Refugee kid educated in Iran wins this ...   \n",
       "2  @pfrpeppermint @CawthornforNC Not only did Tru...   \n",
       "3  An Afghan refugee demands the US not forget he...   \n",
       "4  @RepHerrell One moment you hate refugees and t...   \n",
       "\n",
       "                                        ContentClean  \\\n",
       "0  Per a White House official: Biden and Harris m...   \n",
       "1  Afghan Refugee kid educated in Iran wins this ...   \n",
       "2  Not only did Trump stop processing asylum & re...   \n",
       "3  An Afghan refugee demands the US not forget he...   \n",
       "4  One moment you hate refugees and the next you ...   \n",
       "\n",
       "                             Labels      label_sent     label_stance Flag  \n",
       "0                 neutral / neutral         neutral          neutral  yes  \n",
       "1                        happy / na           happy               na  yes  \n",
       "2                 disgust / neutral         disgust          neutral  yes  \n",
       "3  plea - disgust / refugee - agree  plea - disgust  refugee - agree  yes  \n",
       "4                   hopeful / agree         hopeful            agree  yes  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for NANs\n",
    "If you find any, go back to labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTIMENT\n",
      "disgust           391\n",
      "neutral           184\n",
      "happy             142\n",
      "angry              95\n",
      "fear               90\n",
      "plea - disgust     62\n",
      "hopeful            58\n",
      "plea - neutral     50\n",
      "sad                38\n",
      "plea - fear        38\n",
      "na                 21\n",
      "plea - sad         15\n",
      "plea - hopeful     12\n",
      "plea - happy       11\n",
      "plea - angry        3\n",
      "surprise            1\n",
      "Name: label_sent, dtype: int64\n",
      "Number of NANs: 0\n",
      "\n",
      "STANCE\n",
      "agree              489\n",
      "neutral            480\n",
      "disagree           122\n",
      "na                  81\n",
      "refugee             37\n",
      "refugee - agree      1\n",
      "refugee - na         1\n",
      "Name: label_stance, dtype: int64\n",
      "Number of NANs: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"SENTIMENT\")\n",
    "print(tweets_clean[\"label_sent\"].value_counts())\n",
    "print(\"Number of NANs:\", tweets_clean[\"label_sent\"].isna().sum())\n",
    "print()\n",
    "print(\"STANCE\")\n",
    "print(tweets_clean[\"label_stance\"].value_counts())\n",
    "print(\"Number of NANs:\", tweets_clean[\"label_stance\"].isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the sentiment label to numeric\n",
    "First find all the possible ways a row can be labeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['angry',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'happy',\n",
       " 'hopeful',\n",
       " 'na',\n",
       " 'neutral',\n",
       " 'plea - angry',\n",
       " 'plea - disgust',\n",
       " 'plea - fear',\n",
       " 'plea - happy',\n",
       " 'plea - hopeful',\n",
       " 'plea - neutral',\n",
       " 'plea - sad',\n",
       " 'sad',\n",
       " 'surprise']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sent_labels = list(tweets_clean[\"label_sent\"].unique())\n",
    "pos_stance_labels = list(tweets_clean[\"label_stance\"].unique())\n",
    "pos_labels = list(set(pos_sent_labels + pos_stance_labels))\n",
    "pos_sent_labels.sort()\n",
    "print(len(pos_sent_labels))\n",
    "pos_sent_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column for the label transformed to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Labels</th>\n",
       "      <th>label_sent</th>\n",
       "      <th>y_sent</th>\n",
       "      <th>label_stance</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170314</td>\n",
       "      <td>2021-08-15 17:53:06+00:00</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>neutral / neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192623</td>\n",
       "      <td>2021-06-02 17:31:25+00:00</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>happy / na</td>\n",
       "      <td>happy</td>\n",
       "      <td>2</td>\n",
       "      <td>na</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106982</td>\n",
       "      <td>2021-08-28 07:53:12+00:00</td>\n",
       "      <td>@pfrpeppermint @CawthornforNC Not only did Tru...</td>\n",
       "      <td>Not only did Trump stop processing asylum &amp; re...</td>\n",
       "      <td>disgust / neutral</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31609</td>\n",
       "      <td>2021-12-23 18:00:41+00:00</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>plea - disgust / refugee - agree</td>\n",
       "      <td>plea - disgust</td>\n",
       "      <td>0</td>\n",
       "      <td>refugee - agree</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152666</td>\n",
       "      <td>2021-08-17 20:06:41+00:00</td>\n",
       "      <td>@RepHerrell One moment you hate refugees and t...</td>\n",
       "      <td>One moment you hate refugees and the next you ...</td>\n",
       "      <td>hopeful / agree</td>\n",
       "      <td>hopeful</td>\n",
       "      <td>2</td>\n",
       "      <td>agree</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_stable                       Date  \\\n",
       "0     170314  2021-08-15 17:53:06+00:00   \n",
       "1     192623  2021-06-02 17:31:25+00:00   \n",
       "2     106982  2021-08-28 07:53:12+00:00   \n",
       "3      31609  2021-12-23 18:00:41+00:00   \n",
       "4     152666  2021-08-17 20:06:41+00:00   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Per a White House official: Biden and Harris m...   \n",
       "1  Afghan Refugee kid educated in Iran wins this ...   \n",
       "2  @pfrpeppermint @CawthornforNC Not only did Tru...   \n",
       "3  An Afghan refugee demands the US not forget he...   \n",
       "4  @RepHerrell One moment you hate refugees and t...   \n",
       "\n",
       "                                        ContentClean  \\\n",
       "0  Per a White House official: Biden and Harris m...   \n",
       "1  Afghan Refugee kid educated in Iran wins this ...   \n",
       "2  Not only did Trump stop processing asylum & re...   \n",
       "3  An Afghan refugee demands the US not forget he...   \n",
       "4  One moment you hate refugees and the next you ...   \n",
       "\n",
       "                             Labels      label_sent  y_sent     label_stance  \\\n",
       "0                 neutral / neutral         neutral       1          neutral   \n",
       "1                        happy / na           happy       2               na   \n",
       "2                 disgust / neutral         disgust       0          neutral   \n",
       "3  plea - disgust / refugee - agree  plea - disgust       0  refugee - agree   \n",
       "4                   hopeful / agree         hopeful       2            agree   \n",
       "\n",
       "  Flag  \n",
       "0  yes  \n",
       "1  yes  \n",
       "2  yes  \n",
       "3  yes  \n",
       "4  yes  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DEL: label_dict_sent = {'neutral':0, 'na':0, 'angry':1, 'fear':1, 'disgust':1, 'sad':1, 'hopeful':2, 'happy':2, 'surprise':2, 'plea - angry':1, 'plea - disgust':1, 'plea - fear':1, 'plea - happy':2, 'plea - hopeful':2, 'plea - neutral':0, 'plea - sad':1}\n",
    "label_dict_sent = {'neutral':1, 'na':1, 'angry':0, 'fear':0, 'disgust':0, 'sad':0, 'hopeful':2, 'happy':2, 'surprise':2, 'plea - angry':0, 'plea - disgust':0, 'plea - fear':0, 'plea - happy':2, 'plea - hopeful':2, 'plea - neutral':1, 'plea - sad':0}\n",
    "tweets_clean.insert(loc=6, column=\"y_sent\", value=tweets_clean.label_sent.replace(label_dict_sent))\n",
    "tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "['neutral', 'na', 'refugee - agree', 'agree', 'disagree', 'refugee - na', 'refugee']\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_stance_labels))\n",
    "print(pos_stance_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>Labels</th>\n",
       "      <th>label_sent</th>\n",
       "      <th>y_sent</th>\n",
       "      <th>label_stance</th>\n",
       "      <th>y_stance</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>170314</td>\n",
       "      <td>2021-08-15 17:53:06+00:00</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>Per a White House official: Biden and Harris m...</td>\n",
       "      <td>neutral / neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192623</td>\n",
       "      <td>2021-06-02 17:31:25+00:00</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>Afghan Refugee kid educated in Iran wins this ...</td>\n",
       "      <td>happy / na</td>\n",
       "      <td>happy</td>\n",
       "      <td>2</td>\n",
       "      <td>na</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106982</td>\n",
       "      <td>2021-08-28 07:53:12+00:00</td>\n",
       "      <td>@pfrpeppermint @CawthornforNC Not only did Tru...</td>\n",
       "      <td>Not only did Trump stop processing asylum &amp; re...</td>\n",
       "      <td>disgust / neutral</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31609</td>\n",
       "      <td>2021-12-23 18:00:41+00:00</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>An Afghan refugee demands the US not forget he...</td>\n",
       "      <td>plea - disgust / refugee - agree</td>\n",
       "      <td>plea - disgust</td>\n",
       "      <td>0</td>\n",
       "      <td>refugee - agree</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152666</td>\n",
       "      <td>2021-08-17 20:06:41+00:00</td>\n",
       "      <td>@RepHerrell One moment you hate refugees and t...</td>\n",
       "      <td>One moment you hate refugees and the next you ...</td>\n",
       "      <td>hopeful / agree</td>\n",
       "      <td>hopeful</td>\n",
       "      <td>2</td>\n",
       "      <td>agree</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_stable                       Date  \\\n",
       "0     170314  2021-08-15 17:53:06+00:00   \n",
       "1     192623  2021-06-02 17:31:25+00:00   \n",
       "2     106982  2021-08-28 07:53:12+00:00   \n",
       "3      31609  2021-12-23 18:00:41+00:00   \n",
       "4     152666  2021-08-17 20:06:41+00:00   \n",
       "\n",
       "                                             Content  \\\n",
       "0  Per a White House official: Biden and Harris m...   \n",
       "1  Afghan Refugee kid educated in Iran wins this ...   \n",
       "2  @pfrpeppermint @CawthornforNC Not only did Tru...   \n",
       "3  An Afghan refugee demands the US not forget he...   \n",
       "4  @RepHerrell One moment you hate refugees and t...   \n",
       "\n",
       "                                        ContentClean  \\\n",
       "0  Per a White House official: Biden and Harris m...   \n",
       "1  Afghan Refugee kid educated in Iran wins this ...   \n",
       "2  Not only did Trump stop processing asylum & re...   \n",
       "3  An Afghan refugee demands the US not forget he...   \n",
       "4  One moment you hate refugees and the next you ...   \n",
       "\n",
       "                             Labels      label_sent  y_sent     label_stance  \\\n",
       "0                 neutral / neutral         neutral       1          neutral   \n",
       "1                        happy / na           happy       2               na   \n",
       "2                 disgust / neutral         disgust       0          neutral   \n",
       "3  plea - disgust / refugee - agree  plea - disgust       0  refugee - agree   \n",
       "4                   hopeful / agree         hopeful       2            agree   \n",
       "\n",
       "   y_stance Flag  \n",
       "0         1  yes  \n",
       "1         1  yes  \n",
       "2         1  yes  \n",
       "3         3  yes  \n",
       "4         2  yes  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DEL: label_dict_stance = {'neutral':0, 'na':0, 'agree':2, 'refugee':3, 'disagree':1, '?':0, 'refugee - agree':3, 'refugee - na':3}\n",
    "label_dict_stance = {'neutral':1, 'na':1, 'agree':2, 'refugee':3, 'disagree':0, '?':1, 'refugee - agree':3, 'refugee - na':3}\n",
    "tweets_clean.insert(loc=8, column=\"y_stance\", value=tweets_clean.label_stance.replace(label_dict_stance))\n",
    "tweets_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save what you have done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAUSE\n",
    "tweets_clean.to_csv(os.path.join('archiveData', \"cleanB_tweets_clean.csv\"))  # USED IN FUTURE NOTEBOOKS\n",
    "tweets_unlabeled.to_csv(os.path.join('archiveData', \"cleanB_tweets_unlabeled.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAUSE\n",
    "# tweets_clean.to_csv(os.path.join('archiveData', \"cleanB_labeled_tweets.csv\"))\n",
    "# tweets_unlabeled.to_csv(os.path.join('archiveData', \"cleanB_unlabeled_tweets.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --> Go to dataEmoj"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2522cab69aef9135531abc74cfe3f2456cb406a72442e0865122b8d4f66eb9dc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
