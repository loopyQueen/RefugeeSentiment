{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nlpUtils import aardvark as aa \n",
    "from numpy import random as rand\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "# from transformers import BertForSequenceClassification\n",
    "# from transformers import BertTokenizer\n",
    "\n",
    "#from transformers import AutoTokenizer, AutoModelForSequenceClassification  # Check that these are the models I want\n",
    "from transformers import DistilBertModel\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()  # Turns off the warning when you load the model without training\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 15)\n",
      "(125, 15)\n",
      "(390, 2)\n",
      "(125, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>n_CapLetters</th>\n",
       "      <th>CapsRatio</th>\n",
       "      <th>AllCapWords</th>\n",
       "      <th>https</th>\n",
       "      <th>Mentions</th>\n",
       "      <th>Location</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>31194</td>\n",
       "      <td>2021-12-25 19:33:12+00:00</td>\n",
       "      <td>Afghan citizens resettlement scheme to open in...</td>\n",
       "      <td>Afghan citizens resettlement scheme to open in...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.060403</td>\n",
       "      <td>(ACRS)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>38187</td>\n",
       "      <td>2021-12-02 13:00:00+00:00</td>\n",
       "      <td>According to the U.N. refugee agency (UNHCR), ...</td>\n",
       "      <td>According to the U.N. refugee agency (UNHCR), ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.060976</td>\n",
       "      <td>U.N., (UNHCR),</td>\n",
       "      <td>https://t.co/wSuWG2yAjL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>English-speaking</td>\n",
       "      <td>24</td>\n",
       "      <td>189</td>\n",
       "      <td>2221</td>\n",
       "      <td>4</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>95575</td>\n",
       "      <td>2021-09-01 19:02:05+00:00</td>\n",
       "      <td>INDIANAPOLIS — An estimated 5,000 Afghan evacu...</td>\n",
       "      <td>INDIANAPOLIS — An estimated 5,000 Afghan evacu...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.103604</td>\n",
       "      <td>INDIANAPOLIS —, COVID</td>\n",
       "      <td>https://t.co/IwV9dqmV9J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anderson, Indiana.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>31287</td>\n",
       "      <td>2021-12-24 21:57:28+00:00</td>\n",
       "      <td>All Afghan refugees at Quantico have been rese...</td>\n",
       "      <td>All Afghan refugees at Quantico have been rese...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/O6cRFlmMcZ</td>\n",
       "      <td>@newsintheburg</td>\n",
       "      <td>Stafford, VA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No hashtags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>109598</td>\n",
       "      <td>2021-08-27 13:11:06+00:00</td>\n",
       "      <td>20,000 #Afghan #refugees will be coming to #Ca...</td>\n",
       "      <td>20,000 #Afghan #refugees will be coming to #Ca...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.052885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://t.co/MI6gM1wZFD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>['Afghan', 'refugees', 'Canada', 'Brampton', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_stable                       Date  \\\n",
       "395      31194  2021-12-25 19:33:12+00:00   \n",
       "295      38187  2021-12-02 13:00:00+00:00   \n",
       "248      95575  2021-09-01 19:02:05+00:00   \n",
       "119      31287  2021-12-24 21:57:28+00:00   \n",
       "174     109598  2021-08-27 13:11:06+00:00   \n",
       "\n",
       "                                               Content  \\\n",
       "395  Afghan citizens resettlement scheme to open in...   \n",
       "295  According to the U.N. refugee agency (UNHCR), ...   \n",
       "248  INDIANAPOLIS — An estimated 5,000 Afghan evacu...   \n",
       "119  All Afghan refugees at Quantico have been rese...   \n",
       "174  20,000 #Afghan #refugees will be coming to #Ca...   \n",
       "\n",
       "                                          ContentClean  n_CapLetters  \\\n",
       "395  Afghan citizens resettlement scheme to open in...             9   \n",
       "295  According to the U.N. refugee agency (UNHCR), ...            10   \n",
       "248  INDIANAPOLIS — An estimated 5,000 Afghan evacu...            23   \n",
       "119  All Afghan refugees at Quantico have been rese...             3   \n",
       "174  20,000 #Afghan #refugees will be coming to #Ca...            11   \n",
       "\n",
       "     CapsRatio            AllCapWords                    https  \\\n",
       "395   0.060403                 (ACRS)                      NaN   \n",
       "295   0.060976         U.N., (UNHCR),  https://t.co/wSuWG2yAjL   \n",
       "248   0.103604  INDIANAPOLIS —, COVID  https://t.co/IwV9dqmV9J   \n",
       "119   0.050847                    NaN  https://t.co/O6cRFlmMcZ   \n",
       "174   0.052885                    NaN  https://t.co/MI6gM1wZFD   \n",
       "\n",
       "           Mentions                 Location  ReplyCount  RetweetCount  \\\n",
       "395             NaN  England, United Kingdom           0             0   \n",
       "295             NaN         English-speaking          24           189   \n",
       "248             NaN       Anderson, Indiana.           0             0   \n",
       "119  @newsintheburg             Stafford, VA           0             0   \n",
       "174             NaN                   Canada           0             2   \n",
       "\n",
       "     LikeCount  QuoteCount                                           Hashtags  \n",
       "395          1           0                                        No hashtags  \n",
       "295       2221           4                                        No hashtags  \n",
       "248          1           0                                        No hashtags  \n",
       "119          0           0                                        No hashtags  \n",
       "174          2           0  ['Afghan', 'refugees', 'Canada', 'Brampton', '...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv(\"x_train.csv\", header=0, index_col=0)\n",
    "x_val = pd.read_csv(\"x_val.csv\", header=0, index_col=0)\n",
    "y_train_sent = pd.read_csv(\"y_train_sent.csv\", header=0, index_col=0)\n",
    "y_val_sent = pd.read_csv(\"y_val_sent.csv\", header=0, index_col=0)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train_sent.shape)\n",
    "print(y_val_sent.shape)\n",
    "x_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>y_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>31194</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>38187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>95575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>31287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>109598</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_stable  y_sent\n",
       "395      31194       3\n",
       "295      38187       0\n",
       "248      95575       0\n",
       "119      31287       0\n",
       "174     109598       3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_sent.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for BERT\n",
    "Thanks to: https://medium.com/mlearning-ai/twitter-sentiment-analysis-with-deep-learning-using-bert-and-hugging-face-830005bcdbbf, https://www.youtube.com/watch?v=szczpgOEdXs\n",
    "\n",
    "Using the distilbert-base-uncased version.\n",
    "\n",
    "Setup\n",
    "1. get just the columns we will use\n",
    "2. add some new columns we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, 4)\n",
      "(125, 4)\n",
      "(390, 2)\n",
      "(125, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>tokenIDs</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>31194</td>\n",
       "      <td>Afghan citizens resettlement scheme to open in...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>38187</td>\n",
       "      <td>According to the U.N. refugee agency (UNHCR), ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>95575</td>\n",
       "      <td>INDIANAPOLIS — An estimated 5,000 Afghan evacu...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>31287</td>\n",
       "      <td>All Afghan refugees at Quantico have been rese...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>109598</td>\n",
       "      <td>20,000 #Afghan #refugees will be coming to #Ca...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_stable                                       ContentClean tokenIDs  \\\n",
       "395      31194  Afghan citizens resettlement scheme to open in...            \n",
       "295      38187  According to the U.N. refugee agency (UNHCR), ...            \n",
       "248      95575  INDIANAPOLIS — An estimated 5,000 Afghan evacu...            \n",
       "119      31287  All Afghan refugees at Quantico have been rese...            \n",
       "174     109598  20,000 #Afghan #refugees will be coming to #Ca...            \n",
       "\n",
       "    mask  \n",
       "395       \n",
       "295       \n",
       "248       \n",
       "119       \n",
       "174       "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols = [\"id_stable\", \"ContentClean\"]\n",
    "x_train = x_train[x_cols]\n",
    "x_val = x_val[x_cols]\n",
    "\n",
    "x_train[\"tokenIDs\"] = \"\"\n",
    "x_val[\"tokenIDs\"] = \"\"\n",
    "\n",
    "x_train[\"mask\"] = \"\"\n",
    "x_val[\"mask\"] = \"\"\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_train_sent.shape)\n",
    "print(y_val_sent.shape)\n",
    "x_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at tweet length\n",
    "Because BERT requires equal length sentences and we need to know where we want to cut/pad to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot([len(s) for s in x_train[\"ContentClean\"]], bins=25)\n",
    "plt.title('Sentence Length')\n",
    "plt.figtext(.2, .8, \"Max content length: {}\".format(max([len(s) for s in x_train[\"ContentClean\"]])))\n",
    "plt.style.use('ggplot') \n",
    "#plt.style.use('Solarize_Light2') \n",
    "plt.style.use('seaborn-white') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tweet_len = max([len(s) for s in x_train[\"ContentClean\"]])\n",
    "max_tweet_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are a lot of tweets that run long. I think I will pad to the max tweet length: 280."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup the BERT Tokenizer and Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# model = BertModel.from_pretrained(\"distilbert-base-uncased\", output_hidden_states = True)\n",
    "\n",
    "#model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-uncased')\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states = True)\n",
    "\n",
    "# tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased')    # Download vocabulary from S3 and cache.\n",
    "# model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')    # Download model and configuration from S3 and cache.\n",
    "\n",
    "# tokenizer = None\n",
    "# model = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102,     0,     0],\n",
      "        [  101,  7592,  1012,  2293,  2009,  1012,  6077,  2024,  2307,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\r_noc\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "inputs = tokenizer([\"Hello, my dog is cute\", \"Hello. Love it. Dogs are great\"], padding=True, max_length=75, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-specific preprocessing\n",
    "For the training data:\n",
    "1. Tokenize the sentence\n",
    "2. Add special tokens and pad\n",
    "3. Create the attention mask and token ids\n",
    "4. Convert the attention mask and token ids to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>tokenIDs</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>140615</td>\n",
       "      <td>Tragic news: Boy who died falling from hotel w...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26440</td>\n",
       "      <td>Sorry that may not be clear. Many of our allie...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>91190</td>\n",
       "      <td>State Department Official Makes Shocking Admis...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_stable                                       ContentClean tokenIDs  \\\n",
       "60      140615  Tragic news: Boy who died falling from hotel w...            \n",
       "26       26440  Sorry that may not be clear. Many of our allie...            \n",
       "378      91190  State Department Official Makes Shocking Admis...            \n",
       "\n",
       "    mask  \n",
       "60        \n",
       "26        \n",
       "378       "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for testing, take a smaller df\n",
    "my_df = x_val[0:3]\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___________ BOOKMARK - START HERE ___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101, 13800,  2739,  1024,  2879,  2040,  2351,  4634,  2013,  3309,\n",
      "          3332,  1999,  8533,  2001, 12632, 13141,  1010,  4311,  2360,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,  3374,  2008,  2089,  2025,  2022,  3154,  1012,  2116,  1997,\n",
      "          2256,  6956,  2024,  1999,  9275,  1999,  4501,  1998,  2634,  1998,\n",
      "          1045,  2228,  2060,  2353,  3032,  2421, 12577,  1998, 23538,  1012,\n",
      "          2035, 15497,  1996,  2345, 17397,  2000,  4875,  2000,  1996,  2866,\n",
      "          1012,  2057,  1005,  2310,  2170,  2256,  3169,  2000, 25141,  9286,\n",
      "         12632,  2015,  1999,  1996,  2866,  1000,  3169,  4010,  6160,  1000,\n",
      "           102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[  101,  2110,  2533,  2880,  3084, 16880,  9634,  1011,  1037,  2110,\n",
      "          2533,  2880,  2038,  3555,  2008,  1037,  3484,  1997,  1996,  2569,\n",
      "         11560,  9425, 17362,  2020,  2187,  2369,  1999,  7041,  1012,  3081,\n",
      "           102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\r_noc\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2279: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def bert_preprocess(df, text_col=\"ContentClean\", tokenID_col=\"tokenIDs\", mask_col=\"mask\"):\n",
    "    # Define: how long we want the final vectors to be, based on max (pad only), the end punctuation that we want to seperate at.\n",
    "    goal_len = max([len(i) for i in df[text_col]])\n",
    "    end_punct = \".!?\"\n",
    "\n",
    "    # Create two lists to hold the token ids and masks that will eventually become columns\n",
    "    tokenID_list = []\n",
    "    mask_list = []\n",
    "\n",
    "    for row_idx, text in zip(df.index, df[text_col]):\n",
    "        # tokenize the basic sentence\n",
    "        tokens = tokenizer(text, padding=True, max_length=goal_len, return_tensors=\"pt\") #, return_tensors='pt'\n",
    "        print(tokens)\n",
    "\n",
    "    #     # Add the CLS token to signify the beginning of the text\n",
    "    #     finished_tokens = [\"[CLS]\"] + tokens\n",
    "    #     # Add the SEP token in place of end punctuation to indicate seperations in the text\n",
    "    #     for i, t in enumerate(finished_tokens):\n",
    "    #         if t in end_punct:\n",
    "    #             finished_tokens[i] = \"[SEP]\"\n",
    "    #     # Make sure the final SEP token is in place\n",
    "    #     if finished_tokens[-1] != \"[SEP]\":\n",
    "    #         finished_tokens.append(\"[SEP]\")\n",
    "    #     # Find out how many PAD tokens we need to make all texts the desired length, and add them.\n",
    "    #     pad_num = goal_len - len(finished_tokens)\n",
    "    #     finished_tokens = finished_tokens + (pad_num * [\"[PAD]\"])\n",
    "\n",
    "    #     # Create the attnetion mask, making sure PAD tokens are not given attention.\n",
    "    #     attention_mask = [1 if i!= '[PAD]' else 0 for i in finished_tokens]\n",
    "    #     token_ids = tokenizer.convert_tokens_to_ids(finished_tokens)\n",
    "\n",
    "    #     # Converts token_id and attention mask to tensors\n",
    "    #     token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "    #     attention_mask = torch.tensor(attention_mask).unsqueeze(0)\n",
    "\n",
    "    #     # Add token_id and attention mask to appropriate columns\n",
    "    #     # tokenID_list.append(token_ids)\n",
    "    #     # mask_list.append(attention_mask)\n",
    "    #     tokenID_list.append([row_idx, token_ids])\n",
    "    #     mask_list.append([row_idx, attention_mask])\n",
    "\n",
    "    # ########### START HERE ###########\n",
    "    # # I need to figure out what exactly should be appended from the list to the df. \n",
    "    # # It should be something that looks kina like:\n",
    "    #     # tensor([[ 101, 7078, 1996, 5409,  102, 5223, 2009,  102,    0,    0,    0]])\n",
    "    #     # tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n",
    "    # print(tokenID_list[0][1])\n",
    "    # #print(mask_list[1][1])\n",
    "    # # take the lists and add them as columns to the df\n",
    "    # df[tokenID_col] = tokenID_list[1][1]\n",
    "    # df[mask_col] = mask_list[1][1]\n",
    "\n",
    "    # return \"Yay!\"\n",
    "\n",
    "bert_preprocess(my_df, text_col=\"ContentClean\", tokenID_col=\"tokenIDs\", mask_col=\"mask\")\n",
    "# Thanks to \"Getting Started with Google BERT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_stable</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>tokenIDs</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>140615</td>\n",
       "      <td>Tragic news: Boy who died falling from hotel w...</td>\n",
       "      <td>[[tensor(101), tensor(13800), tensor(2739), te...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26440</td>\n",
       "      <td>Sorry that may not be clear. Many of our allie...</td>\n",
       "      <td>[[tensor(101), tensor(3374), tensor(2008), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>91190</td>\n",
       "      <td>State Department Official Makes Shocking Admis...</td>\n",
       "      <td>[[tensor(101), tensor(2110), tensor(2533), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_stable                                       ContentClean  \\\n",
       "60      140615  Tragic news: Boy who died falling from hotel w...   \n",
       "26       26440  Sorry that may not be clear. Many of our allie...   \n",
       "378      91190  State Department Official Makes Shocking Admis...   \n",
       "\n",
       "                                              tokenIDs  \\\n",
       "60   [[tensor(101), tensor(13800), tensor(2739), te...   \n",
       "26   [[tensor(101), tensor(3374), tensor(2008), ten...   \n",
       "378  [[tensor(101), tensor(2110), tensor(2533), ten...   \n",
       "\n",
       "                                                  mask  \n",
       "60   [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "26   [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "378  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely', 'the', 'worst', '.', 'hate', 'it']\n",
      "['[CLS]', 'absolutely', 'the', 'worst', '[SEP]', 'hate', 'it', '[SEP]', '[PAD]', '[PAD]', '[PAD]']\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      "[101, 7078, 1996, 5409, 102, 5223, 2009, 102, 0, 0, 0]\n",
      "\n",
      "tensor([[ 101, 7078, 1996, 5409,  102, 5223, 2009,  102,    0,    0,    0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Define a text, how long we want the evential padded token list to be, and what are end punctuation that we want to seperate at.\n",
    "text = \"Absolutely the worst. Hate it\"\n",
    "goal_len = 11\n",
    "end_punct = \".!?\"\n",
    "\n",
    "# tokenize the basic sentence\n",
    "tokens = tokenizer.tokenize(text) #, return_tensors='pt'\n",
    "\n",
    "# Add the CLS token to signify the beginning of the text\n",
    "finished_tokens = [\"[CLS]\"] + tokens\n",
    "# Add the SEP token in place of end punctuation to indicate seperations in the text\n",
    "for i, t in enumerate(finished_tokens):\n",
    "    if t in end_punct:\n",
    "        finished_tokens[i] = \"[SEP]\"\n",
    "# Make sure the final SEP token is in place\n",
    "if finished_tokens[-1] != \"[SEP]\":\n",
    "    finished_tokens.append(\"[SEP]\")\n",
    "# Find out how many PAD tokens we need to make all texts the desired length, and add them.\n",
    "pad_num = goal_len - len(finished_tokens)\n",
    "finished_tokens = finished_tokens + (pad_num * [\"[PAD]\"])\n",
    "\n",
    "# Create the attnetion mask, making sure PAD tokens are not given attention.\n",
    "attention_mask = [1 if i!= '[PAD]' else 0 for i in finished_tokens]\n",
    "token_ids = tokenizer.convert_tokens_to_ids(finished_tokens)\n",
    "\n",
    "print(tokens)\n",
    "print(finished_tokens)\n",
    "print(attention_mask)\n",
    "print(token_ids)\n",
    "\n",
    "# Converts token_id and attention mask to tensors\n",
    "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "attention_mask = torch.tensor(attention_mask).unsqueeze(0)\n",
    "\n",
    "print()\n",
    "print(token_ids)\n",
    "print(attention_mask)\n",
    "\n",
    "# result = model(tokens)\n",
    "# result\n",
    "# Thanks to \"Getting Started with Google BERT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the word/token embeddings\n",
    "NOTE: torch.Size([1, 7, 768]) indicates [batch_size, sequence_length, hidden_size], where 'hidden size' is the model-based representation size, 768 for BERT-base\n",
    "\n",
    "Note: \"instead of taking embeddings only from the final encoder layer (final hidden layer), we can also use embeddings from the other encoder layers,\" which may give better results (eg. concatenating the last four hidden). -\"Getting Started with Google BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR output_hidden_states = False\n",
    "# hidden_rep, cls_head = model(token_ids, attention_mask = attention_mask)\n",
    "# print(hidden_rep.shape) \n",
    "\n",
    "# FOR output_hidden_states = True\n",
    "last_hidden_state, pooler_output, hidden_states = model(token_ids, attention_mask = attention_mask)\n",
    "# returns: [last_hidden_state, pooler_output, hidden_states]\n",
    "#   last_hidden_state[0][n]: returns the representation of the nth token in the final encoder layer\n",
    "#   pooler_output: the representation of the [CLS] token, which holds the aggregate representation of the sentence.\n",
    "#   hidden_states: a tuple containing 13 values holding the representation of all encoder layers (hidden layers), from the input embedding layer  to the final encoder layer \n",
    "#      hidden_states[n]: representations of all tokens from the nth encoder layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rCLS = pooler_output\n",
    "rCLS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "output = model(**encoded_input)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39c2229591b4ec9ca260d3f249b9b0f6eb23a8220ef0c3d318c236a623f78e8c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
