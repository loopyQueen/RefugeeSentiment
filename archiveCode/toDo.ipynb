{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installs:\n",
    "# import pandas as pd\n",
    "pip install numpy\n",
    "pip install matplotlib\n",
    "pip install regex\n",
    "pip install snscrape\n",
    "pip install nltk\n",
    "pip install vaderSentiment\n",
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _______________ BOOKMARK _____________\n",
    "So, I still have to \n",
    "* make \"ha\" an in/detensifier.\n",
    "* Consider hashtags: VADER treats them as just another word; do I want to consider them an \"!\" or ALL CAPS?\n",
    "* Think abt stopwords again: add all words that are in Wordcloud both pos and neg top 30 to wc stopwords, then see what are the top words in the word cloud\n",
    "* Remove more news tweets via emoji - this might not have enough rows to be worthwhile.\n",
    "\n",
    "\n",
    "Consider as !:\n",
    "* \"ha\"\n",
    "\n",
    "1. We can plot how Trump’s sentiment in his tweets fluctuates over time by first converting the date column to a datetime value and then making it the index of the DataFrame, which makes it easier to work with time series data.  Then we will group the tweets by month using .resample(), a special method for datetime indices, and calculate the average (.mean()) compound score for each month. We can also .resample() by day (‘D’), week (‘W’), or year (‘Y’). Finally, we will plot these averages.\n",
    "    1. trump_df = trump_df.set_index('date')\n",
    "    2. trump_df.resample('M')['sentiment_score'].mean().plot(title=\"Trump's Tweet Sentiment by Month\");\n",
    "\n",
    "\n",
    "### Divide sentences\n",
    "Note that the average sentiment scores of two sentences independently is NOT the same as the sentiment score of the two considered together which is NOT the same as the average of the two sentences' scores. VADER should do better if we divide each tweet text up into a list of sentences, then feed the lists through VADER.\n",
    "\n",
    "This is not needed for VADER's sentiment scoring the SID does it for you. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VADER_tokenize (text):\n",
    "    tknzr = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True, match_phone_numbers=True)\n",
    "    return [tknzr.tokenize(i) for i in sent_tokenize(text)]\n",
    "\n",
    "sentences = \"Hello my wonderful friend. You suck.\"\n",
    "print(vader_sent_compound(sentences))\n",
    "\n",
    "a = VADER_tokenize (sentences)\n",
    "print(vader_sent_compound(a))\n",
    "def VADER_sid_tokenized (df, text_col=\"ContentClean\", token_col=\"VADERsid\", indx_warning=True):\n",
    "    tknzr = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True, match_phone_numbers=True)\n",
    "    my_tokens = []\n",
    "    Vsid_list = []\n",
    "\n",
    "    if indx_warning == True:\n",
    "        q = input(\"This function resets the index. To proceed, type: 'Y':\")\n",
    "        if q.lower() != \"y\":\n",
    "            return \"Error: Dataframe cannot be reindexed.\"\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    for i, text in enumerate(df[text_col]):\n",
    "#        etext = emoji.demojize(text)\n",
    "        my_tokens.append([tknzr.tokenize(i) for i in sent_tokenize(etext)])\n",
    "\n",
    "\n",
    "    #tweets_vader.insert(loc=5, column=\"VADERsid\", value=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WTF\n",
    "\n",
    "importlib.reload(module)\n",
    "\n",
    "importlib.reload(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory and Concept\n",
    "Still to do:\n",
    "* Exclude news sources?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "* Count the number of capital letters per tweet to a new column before \"lower\"ing.\n",
    "* Should I keep sentence information/segmentation?\n",
    "    * from nltk.tokenize import sent_tokenize\n",
    "    * my_sentences = sent_tokenize(mytext)\n",
    "* Should emojis be retained in the text? Or given their own column and replaced with a word?\n",
    "    * Replaced with standard text via: https://pypi.org/project/emoji/ and https://www.webfx.com/tools/emoji-cheat-sheet/\n",
    "    * cf: https://mdpi-res.com/d_attachment/information/information-12-00409/article_deploy/information-12-00409-v2.pdf?version=1634174919 \n",
    "* If cleaning removes all text:\n",
    "    * Impute the missing value with some placeholder text like *[no_text]*\n",
    "    * Word2Vec: use the average of all vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "## Target data: Labled dataset\n",
    "* Visualize lable classes to check for balanced classes\n",
    "> sns.factorplot(x=\"airline_sentiment\", data=df, kind=\"count\", size=6, aspect=1.5, palette=\"PuBuGn_d\")\n",
    "> plt.show()\n",
    "* Visualize each variable per target class; this should give some indication of which variables may be significant; or safely discarded.\n",
    "\n",
    "### Identifying @mentions\n",
    "NOTE: Consider replacing the @mention with a code (ex: entity) if it falls within a sentence, as it might be part of the logic of the sentence when labeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "* count_words: number of words in the tweet\n",
    "* count_mentions: referrals to other Twitter accounts start with a @\n",
    "* count_hashtags: number of tag words, preceded by a #\n",
    "* count_capital_words: number of uppercase words are sometimes used to “shout” and express (negative) emotions\n",
    "* count_excl_quest_marks: number of question or exclamation marks\n",
    "* count_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Search\n",
    "\n",
    "GridSearchCV: classification_report (to get F1, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stance Detection\n",
    "\n",
    "Detecting if the tweet agrees or disagrees with the proposition: <br> \n",
    "* \"The United States government should resettle Afghan refugees in the United States.\"\n",
    "* Possible labels:\n",
    "    * agree\n",
    "        * uncertain agree\n",
    "    * disagree\n",
    "        * uncertain disagree\n",
    "    * neutral\n",
    "    * unrelated / other\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\r_noc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#import snscrape.modules.twitter as sntwitter\n",
    "import nltk\n",
    "nltk.download(['stopwords'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import bigrams\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>ContentLabel</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom</td>\n",
       "      <td>This #Afghanistan is</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dick</td>\n",
       "      <td>not the afg that</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry</td>\n",
       "      <td>i think is afghanistany</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moe</td>\n",
       "      <td>Yes, #Afghaninstany</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Nope. No AF.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name             ContentClean ContentLabel Flag\n",
       "0    Tom     This #Afghanistan is                  \n",
       "1   Dick         not the afg that                  \n",
       "2  Harry  i think is afghanistany                  \n",
       "3    Moe      Yes, #Afghaninstany                  \n",
       "4    Bob             Nope. No AF.                  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({\"Name\": [\"Tom\", \"Dick\", \"Harry\", \"Moe\", \"Bob\"], \n",
    "    \"ContentClean\":[\"This #Afghanistan is\", \"not the afg that\", \"i think is afghanistany\", \"Yes, #Afghaninstany\", \"Nope. No AF.\"],\n",
    "    \"ContentLabel\": [\"\", \"\", \"\", \"\", \"\"], \"Flag\": [\"\", \"\", \"\", \"\", \"\"]})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nlpUtils import aardvark as aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'aardvark' from 'c:\\\\Users\\\\r_noc\\\\Desktop\\\\Python\\\\THESIS\\\\aardvark.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = [\"is\", \"the\"]\n",
    "\n",
    "for term in terms:\n",
    "    aa.flag_term(term, test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ContentClean</th>\n",
       "      <th>ContentLabel</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tom</td>\n",
       "      <td>This #Afghanistan is</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dick</td>\n",
       "      <td>not the afg that</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry</td>\n",
       "      <td>i think is afghanistany</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moe</td>\n",
       "      <td>Yes, #Afghaninstany</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Nope. No AF.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name             ContentClean ContentLabel Flag\n",
       "0    Tom     This #Afghanistan is                  \n",
       "1   Dick         not the afg that                  \n",
       "2  Harry  i think is afghanistany                  \n",
       "3    Moe      Yes, #Afghaninstany                  \n",
       "4    Bob             Nope. No AF.                  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d5a672f32d72b7000e11999081d09a97571b10f2df9aaee5f232791dc820369"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
